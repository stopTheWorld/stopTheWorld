---
layout: post
title: "《MySQL技术内幕》- 学习笔记"
date: 2017-11-25 11:35:00 +0800
categories: mysql
tag: [mysql,innodb]
---
* content
{:toc}

《MySQL技术内幕》学习笔记，方便回忆。

---

<!-- more -->
1. Mysql体系结构和存储引擎
   1. 定义数据库和实例
   2. MySQL体系结构
   3. MySQL存储引擎
2. InnoDB存储引擎
   1. InnoDB体系架构
   2. Checkpoint
   3. Master Thread工作方式
   4. InnoDB关键特性
3. 文件
   1. 参数文件
   2. 日志文件
   3. 套接字文件
   4. pid文件
   5. 表结构定义文件
   6. InnoDB存储引擎文件
4. 表
   1. 索引组织表
   2. InnoDB逻辑存储结构
   3. InnoDB行记录格式
   4. InnoDB数据页结构
   5. Named File Formats机制
   6. 约束
   7. 视图
   8. 分区表
5. 索引与算法
   1. 数据结构与算法
   2. B+树
   3. B+树索引
   4. Cardinality值
   5. B+树索引的使用
   6. 哈希算法
   7. 全文检索
6. 锁
   1. lock与latch
   2. InnoDB存储引擎中的锁
   3. 锁的算法
   4. 锁问题
   5. 阻塞
   6. 死锁
   7. 锁升级
7. 事务
   1. 认识事务
   2. 事务的实现
   3. 事务控制语句
   4. 隐式提交的SQL语句
   5. 对于事务操作的统计
   6. 事务的隔离级别
   7. 分布式事务
   8. 不好的事务习惯
8. 备份与恢复
   1. 冷备
   2. 逻辑备份
   3. 二进制日志的备份与恢复
   4. 热备
   5. 快照备份
   6. 复制
9. 性能调优
10. InnoDB存储引擎源代码编译与调试

---

1. Mysql体系结构和存储引擎

1.1定义数据库和实例

数据库(database)：

* 物理操作系统文件或其他形式文件类型的集合。

实例(instance)：

* 由后台线程以及一个共享内存区组成。
* 数据库实例才是真正用于操作数据库文件的。
* MySQL被设计为单进程多线程架构的数据库，MySQL数据库实例在系统上的表现就是一个进程。

---

1.2 MySQL体系结构

* 连接池组件
* 管理服务与工具组件
* SQL接口组件
* 查询分析器组件
* 优化器组件
* 缓冲组件
* **插件式存储引擎**（基于表的）
* 物理文件

---

1.3 MySQL存储引擎

| 存储引擎      | 特点                                       |
| --------- | ---------------------------------------- |
| InnoDB    | 行锁；支持外键；非锁定读；MVCC；事务（next-key）；高性能高可用（插入缓冲；二次写；自适应哈希；预读）；聚集（6字节ROWID）；idb |
| MyISAM    | 表锁；不支持事务；全文索引；只缓存索引文件；MYD(数据文件)和MYI(索引文件) |
| NDB       | 集群存储引擎；share nothing；数据放在内存中；            |
| Memory    | 表锁；数据放在内存中；哈希索引；不支持TEXT和BLOB，变长字段按定长字段方式；作为临时表存放查询的中间结果集，若超容量，会转换到MyISAM，有查询性能损失 |
| Archive   | 行锁；不是事务安全；只支持INSERT和SELECT；zlib算法按行压缩，压缩比可达1:10；适合存储归档数据 |
| Federated | 不存放数据，指向一台远程MySQL服务器上的                   |
| Maria     | 用于取代原有的MyISAM；支持缓存数据和索引文件；行锁；MVCC        |
| 其他        | Merge、CSV、Sphinx、Infobright              |

---

1.4 连接MySQL

* 连接MySQL操作是一个连接进程和MySQL书数据库实例进行通信，本质上是进程通信
* TCP/IP
* 命名管道和共享内存：--enable-named-pipe   —shared-memory
* UNIX域套接字

---

2. InnoDB存储引擎

2.1 InnoDB存储引擎版本

| 版本                          | MySQL版本 | 功能                     |
| --------------------------- | ------- | ---------------------- |
| 老版本InnoDB(静态编译)             | 5.1     | 支持ACID、行锁、MVCC         |
| InnoDB 1.0.x(InnoDB Plugin) | 5.1     | 增加了compress和dynamic页格式 |
| InnoDB 1.1.x                | 5.5     | 增加了linux AIO、多段回滚      |
| InnoDB 1.2.x                | 5.6     | 增加了全文索引支持、在线索引添加       |

---

2.2 InnoDB体系架构（补图）

后台线程

* 负责刷新内存池中的数据，保证缓冲池中的内存缓存的是最新的数据。
* 将已修改的数据文件刷新到磁盘文件。
* 保证在数据库发生异常的情况下InnoDB能恢复到正常运行状态。

内存池

* InnoDB存储引擎是基于磁盘存储的，并将其中的记录按照页的方式进行管理。


* 维护所有进程/线程需要访问的多个内部数据结构。
* 缓存磁盘上的数据，方便快速地读取，同时在对磁盘文件的数据修改之前在这里缓存。
* 重做日志(redo log)缓冲。

缓冲池缓存的数据页类型

* 索引页（data page）
* 数据页（index page）
* 插入缓冲（insert buffer）
* 自适应哈希索引（adaptive hash index）
* InnoDB存储的锁信息（lock info）
* 数据字典信息（data dictionary）
* undo页

缓冲池管理

* LRU：
  * LRU列表用来管理已经读取的页。
  * midpoint(默认为5/8处)，midponit之后的列表称为old列表，之前的列表称为new列表。新读取到的页并不是直接放入到LRU列表的首部，而是放到LRU列表的midpoint位置。innodb_old_blocks_pct；innodb_old_blocks_time
  * 当LRU列表的old部分加入到new部分时，称为page made young；当因为innodb_old_blocks_time的设置而导致页没有从old部分加入到new部分时，称为page not made young；
* Free List
  * 当数据库刚启动时，LRU列表是空的，这时页都存放在Free列表中。当需要从缓冲池中分页时，首先从Free列表中查找是否有可用的空闲页，若有则将该页从Free列表删除，放入LRU列表中；若无，则太太LRU列表末尾的页，分配给新的页。
* Flush List
  * LRU列表页中的页被修改后，称该页为脏页(dirty page)
  * 脏页既存在于LRU列表中，也存在于Flush列表中。LRU列表用来管理缓冲池中页的可用性，Flush列表用来管理将页刷新回磁盘，二者互不影响。

| 后台线程                | 功能                                       | 相关参数                                     |
| ------------------- | ---------------------------------------- | ---------------------------------------- |
| Master Thread       | 缓冲池中的数据异步刷新到磁盘，保证数据的一致性：包括脏页的刷新、合并插入缓冲、UNDO页的回收等 |                                          |
| IO Thread           | 负责AIO请求的回调处理。insert buffer、log、write(4个)、read(4个) | innodb_reaad_io_threads；innodb_write_io_threads |
| Purge Thread        | 负责回收已经使用并分配的undo页。                       | innodb_purge_thread；                     |
| Page Cleaner Thread | 负责脏页的刷新                                  | innodb_lru_scan_depth；                   |

| 内存池    | 功能                                       | 相关参数                                     |
| ------ | ---------------------------------------- | ---------------------------------------- |
| 缓冲池    | 1）读取：首先判断该页是否在缓冲池中，若存在，则命中；否则，将磁盘读到的页存在缓冲池中。这个过程称为将页“FIX”在缓冲池中；2）修改：首先修改在缓冲池中的页，然后通过Checkpoint机制刷新回磁盘；3）页的默认大小是16KB | innodb_buffer_pool_size；innodb_buffer_pool_instances |
| 重做日志缓冲 | 首先将重做日志信息放入到该缓冲区，然后按一定频率将其刷新到重做日志文件。1）Master Thread每一秒会刷新；2）每个事务提交会刷新；3）当重做日志缓冲池剩余空间小于1/2时会刷新 | innodb_log_buffer_size                   |
| 额外的内存池 |                                          |                                          |

---

2.3 Checkpoint

Checkpoint解决以下几个问题：

* 缩短数据库的恢复时间
* 缓冲池不够用时，将脏页刷新到磁盘
* 重做日志不可用时，刷新脏页

LSN（Log Sequence Number）：8字节的数字，单位是字节

* 每个页有LSN
* 重做日志也有LSN
* checkpoint也有LSN

Checkpoint类型

* Sharp Checkopoint：发生在数据库关闭时间所有的脏页都刷新回磁盘；若运行时使用会影响数据库的可用性
* Fuzzy Checkpoint：只刷新一部分脏页
  * Master Thread Checkpoint：每秒或每十秒从缓冲池中刷新一定比例的页回磁盘；异步
  * FLUSH_LRU_LIST Checkpoint：LRU列表要差不多100个空闲页可供使用
  * Async/Sync Flush Checkpoint：重做日志文件不可用的情况，这时需要强制将一些页刷新回磁盘
  * Dirty Page too much Checkpoint

---

2.4 Master Thread工作方式

* 主循环（loop）:

  * 每秒一次的操作：

    1. 日志缓冲刷新到磁盘，即使这个事务还没有提交（总是）；
    2. 合并插入缓冲（可能）；
    3. 至多刷新100个InnoDB的缓冲池中的脏页到磁盘（可能）；
    4. 如果当前没有用户活动，则切换到background loop（可能）；

  * 10秒一次的操作：

    1. 刷新100个脏页到磁盘（可能）；
    2. 合并至多5个插入缓冲（总数）；
    3. 将日志缓冲刷新到磁盘（总是）；
    4. 删除无用的Undo页（总是）；
    5. 刷新100个或者10个脏页大盘磁盘（总是）；
* background loop：若当前没有用户活动或者数据库关闭，就会切换到这个循环
  * 删除无用的Undo页（总是）；
  * 合并20个插入缓冲（总是）；
  * 跳回到主循环（总是）；
  * 不断刷新100个页知道符合条件（可能，跳转到flush loop中完成）


```bash
void master_thread() {
	goto loop;
	
loop:
for( int i=0;i<10;i++ ){
	thread_sleep(1);
	do log buffer flush to disk
	if( last_one_second_ios < 5% innodb_io_capacity )
		do merge at most 5% innodb_io_capacity insert buffer
    if( buf_get_modified_ratio_pct > innodb_max_dirty_pages_pct )
    	do buffer pool flush 100% innodb_io_capacity dirty page
    else if enable adaptive flush
    	do buffer pool flush desired amount dirty page
    if( no user activity )
    	goto background loop
}
if( last_ten_seconds_ios < innodb_io_capacity )
	do buffer pool flush 100% innodb_io_capacity dirty page
do merge at most 5% innodb_io_capacity insert buffer
do log buffer flush to disk
do full purge
if( buf_get_modified_ratio_pct > 70% )
    do buffer pool flush 100% innodb_io_capacity dirty page
else
	do buffer pool flush 10% innodb_io_capacity dirty page
goto loop

background loop:
do full purge
do merge 100% innodb_io_capacity insert buffer
if not idle
	gote loop
else
	goto flush loop
	
flush loop:
do buffer pool flush 100% innodb_io_capacity dirty page
if( buf_get_modified_ratio_pct > innodb_msx_dirty_pages_pct )
	goto flush loop
goto suspend loop

suspend loop:
suspend_thread()
waiting event
goto loop;
}
```

---

2.5 InnoDB关键特性

2.5.1 插入缓冲（Insert Buffer）

* 对于非聚集索引的插入或更新操作，不是每一次直接插入到索引页中，而是先判断插入的非聚集索引页是否在缓冲池中，若在，则直接插入；若不在，则先放入到一个Insert Buffer对象中，然后以一定频率和情况进行Insert Buffer 和辅助索引叶子节点的merge操作，这时通常能将多个插入合并到一个操作中（因为在一个索引页中），这就答答题高了对于非聚集索引插入的性能

* Insert Buffer的使用需要同时满足两个条件：

  * 索引是辅助索引（secondary index）
  * 索引不是唯一（unique）的

* 数据结构：B+树，全局唯一

  * 非叶节点：存放的是查询的search key，一共占用9个字节。space(4字节)表示待插入记录所在表的表空间id；marker(1字节)兼容老版本的Insert Buffer；offset(4字节)表示表所在的偏移量。当一个辅助索引要插入到页（space, offset）时，如果这个页不在缓冲池中，那么InnoDB存储引擎首先构造一个search key，接下来查询Insert Buffer这棵B+树，然后再将记录插入到叶子节点中。
  * 叶子节点：space、marker、page_no、metadata(4字节)、辅助索引记录

* Insert Buffer Bitmap：用来标记每个辅助索引页（space, page_no ）的可用空间的特殊页

  * 每个Insert Buffer Bitmap页用来追踪16384个辅助索引页，并都在16384个页的第二页中。
  * 每个辅助索引页在Insert Buffer Bitmap页中占用4bit
    * IBUF_BITMAP_FREE(2bit)：表示该辅助索引页中的可用空间数量，0(无)、1(>1/32)、2(>1/16)、3(>1/8)
    * IBUF_BITMAP_BUFFERED(1bit)：1表示该辅助索引页有记录被缓存在Insert Buffer B+树中
    * IBUF_BITMAP_IBUF(1bit)：1表示该页为Insert Buffer B+树的索引页

* Merge Insert buffer

  Merge Insert buffer的操作可能发生在以下几种情况下：

  * 辅助索引页被读取到缓冲池时：先检查Insert Buffer Bitmap页，确认该辅助索引页是否有记录存放在Insert Buffer B+树中，若有，则将B+树中该页的记录插入到该辅助索引页中。
  * Insert Buffer Bitmap页追踪到该辅助索引页已无可用空间时：若插入辅助索引记录时检测到插入记录后可用空间会小于1/32页，则会强制进行一个合并操作，即强制读取辅助索引页，将Insert Buffer B+树中该页的记录及待插入的记录插入到辅助索引页中。
  * Master Thread：每秒或每10秒进行一次Merge Insert buffer的操作。

2.5.2 两次写（Double Write）

* 重做日志中记录的是对页的物理操作，如偏移量800，写'aaa'记录。如果这个页本身已经发生了损坏，再对其进行重做是没有意义的。
* 在应用重做日志前，用户需要一个页的副本，当写入失效发生时，先通过页的副本来还原该页，再进行重做，这就是doublewrite
* double write由两部分组成：
  * 内存中的doublewrite buffer,大小为2MB
  * 物理磁盘上共享表空间中连续的128个页，大小也为2MB
* 写入过程：
  * 在对缓冲区的脏页进行刷新时，通过memcpy函数将脏页先复制到内存中的doublewrite buffer
  * 通过doublewrite buffer分两次，每次1MB顺序地写入共享表空间的物理磁盘上。（第一次写）（因为doublewrite页是连续的，因此这个过程是顺序写的，开销并不是很大）
  * 马上调用fsync函数，同步磁盘
  * 在完成doublewrite页的写入后，再将doublewrite buffer中的页写入到各个表空间文件中，此时写入时离散的。（第二次写）
* 恢复过程：
  * 如果操作系统在将页写入磁盘的过程中发生了崩溃，在恢复过程中，从共享表空间中的doublewrite中找到该页的一个副本，将副本复制到表空间文件，再应用重做日志。

2.5.3 自适应哈希索引（Adaptive Hash Index）

* 哈希在一般情况下查找时间复杂度是O(1)；B+树的查找次数取决于B+树的高度，生产环境中B+树高度一般为3~4层
* InnoDB存储引擎会监控对表上各索引页的查询，如果观察到建立哈希索引能带来速度提升，则建立哈希索引，称之为自适应哈希(AHI)
* AHI通过缓冲池的B+树页构造而来，因此建立速度很快，而且不需要对整张表构建哈希索引。
* InnoDB存储引擎会自动根据访问频率和模式来自动地为某些热点页建立哈希索引。
* AHI要求：
  * 即对这个页的连续访问模式必须是一样的。访问模式一样指的是查询条件一样
  * 以该模式访问了100次
  * 页通过该模式访问了N次，其中N=页中记录*1/16
* AHI只能用来搜索等值的查询

2.5.4 异步IO（Asunc IO）

* 用户可以发出一个IO请求后立即再发出另一个IO请求，当全部IO请求发送完毕后，等待所有IO操作的完成，这就是AIO
* AIO的另一个优势是可以进行IO Merge操作。

2.5.5 刷新临接页（Flush Neighbor Page）

* 当刷新一个脏页时，InnoDB存储引擎会检测该页所在 区的所有页，如果是脏页，那么一起进行刷新。通过AIO可以将多个IO写入操作合并为一个IO操作
* 对传统机械硬盘有优势，固态硬盘可关闭此特性。

---

2.6 启动、关闭和恢复

InnoDB存储引擎的启动和关闭，是指在MySQL实例的启动过程中对 InnoDB存储引擎的处理过程。

| 参数                    | 值                                        |
| --------------------- | ---------------------------------------- |
| innodb_fast_shutdown  | 0:完成full purge、merge insert buffer、所有脏页刷新；1：完成full purge、merge insert buffer；2：将日志写入日志文件，下次启动时会进行 |
| innodb_force_recovery | 0:当发生需要恢复时，进行所有的恢复操作                     |

---

5 索引与算法

* 数据结构与算法
* B+树
* B+树索引
* Cardinality值
* B+树索引的使用
* 哈希算法
* 全文检索

InnoDB存储引擎支持的索引：

* B+树索引：传统意义上的索引，构造类似二叉树，根据键值快速找到数据。
* 全文索引
* 哈希索引：自适应的，会根据表的使用情况自动地为表生成哈希索引，不能人为干预

---

5.1 数据结构与算法

* 二分查找法：将记录按有序化9递增或递减）排列，在查找过程中采用跳跃式方法查找
* 二叉查找树和平衡二叉树（AVL）
  * 二叉查找树：左子树小于根，右子树大于根
  * 平衡二叉树：符合二叉查找树定义，且任何节点的两个子树的盖度最大差为1

---

5.2 B+树（补图）

* B+树由B树和索引顺序访问方法（ISAM）演化而来
* B+树是为磁盘或其他直接存取辅助设备设计的一种平衡查找树。在B+树中：
  * 所有记录节点都是按键值的大小顺序存放在同一层的叶子节点上，由各叶子节点指针进行连接

5.2.1 B+树的插入操作

| Leaf Page满 | Index Page满 | 操作                                       |
| ---------- | ----------- | ---------------------------------------- |
| NO         | NO          | 直接将记录插入到叶子节点                             |
| YES        | NO          | 1）拆分Leaf Page；2）将中间的节点放入到Index Page中；3）小于中间节点的记录放到左边；4）大于或等于中间节点的记录放到右边 |
| YES        | YES         | 1）拆分Leaf Page；2）小于中间节点的记录放到左边；3）大于或等于中间节点的记录放到右边；4）拆分Index Page；5）小于中间节点的记录放到左边；6）大于中间节点的记录放到右边；7）中间节点放入上一层Index Page |

* 为了保持平衡对于新插入的键值可能需要大量的拆分(split)页操作，页的拆分意味着磁盘操作，所以应该在可能的情况下尽量减少页的拆分操作。因此，B+树同样一共了类似于平衡二叉树的旋转（Rotation）功能。
* 旋转发生在Leaf Page已满，但是其左右兄弟节点没有满的情况下，这时B+树会将记录转移到所在页的兄弟节点上

5.2.2 B+树的删除操作

| 叶子节点小于填充因子 | 中间节点小于填充因子 | 操作                                       |
| ---------- | ---------- | ---------------------------------------- |
| NO         | NO         | 直接将记录从叶子节点删除，如果该节点还是Index Page的节点，用该节点的右节点代替 |
| YES        | NO         | 合并叶子节点和它的兄弟节点，同时更新Index Page             |
| YES        | YES        | 1）合并叶子节点和它的兄弟节点；2）更新Index Page；3）合并Index Page和它的兄弟节点 |

* B+树使用填充因子（fill factor）来控制树的删除变化，50%是填充因子可设的最小值。

---

5.3 B+树索引

* B+树索引的本质就是B+树在数据库中的实现，但是B+树索引再数据库中有一个特点就是高扇出性，因此在数据库中，B+树的高度一般都在2~4层

* B+树索引分类：（不同在于叶子节点存放的是否是一整行的信息）

  * 聚集索引（clustered index）
  * 辅助索引（secondary index）


5.3.1 聚集索引（补图）

* InnoDB存储引擎是索引组织表，即表中数据按照主键顺序存放。
* 聚集索引是按照每张表的主键构造一棵B+树，同时叶子节点中存放的即为整张表的行记录数据，也将聚集索引的叶子节点称为数据页。聚集索引的这个特性决定了索引组织表中的数据也是索引的一部分。
* 由于实际的数据页只能按照一颗B+树进行排序，因此每张表只能拥有一个聚集索引。
* 聚集索引B+树：
  * 索引页（即非叶节点）：存放键值及指向数据页的偏移量
  * 数据页（即叶子节点）：存放完整的行记录
* 聚集索引的存储并不是物理上连续的，而是逻辑上连续的，这其中有两点：
  * 页通过双向链表连接，页按照主键的顺序排序
  * 每个页中的记录也是通过双向链表进行维护的，物理存储上可以同样不按照主键存储
* 聚集索引的好处是对于主键的**排序查找**和**范围查找**速度非常快。

5.3.2 辅助索引（补图）

* 辅助索引（也称非聚集索引），叶子节点并不包含行记录的全部数据。叶子节点除了包含索引键值以外，每个叶子节点中的索引行中还包含了一个书签（bookmark）。由于 InnoDB存储引擎表是索引组织表，因此InnoDB存储引擎的辅助索引的书签就是相应行数据的聚集索引键（主键）。
* 辅助索引B+树：
  * 叶子节点：存放索引键值及对应的主键。
* 辅助索引的存在并不影响数据在聚集索引中的组织，因此每张表可以有多个辅助索引。
* 当通过辅助索引来寻找时数据时，InnoDB存储引擎会遍历辅助索引并通过叶级别的指针获得指向主键索引的主键，然后再通过主键索引来找到一个完整的行记录

5.3.3 B+树索引的分裂

* B+树索引页的分裂并不总是从页的中间记录开始，这样可能会导致页空间的浪费（因为插入时顺序的，分裂后的左也可能不会再插入数据）
* InnoDB存储引擎的Page Header中有以下几个部分来保存插入顺序信息，通过这些信息可以决定是向左还是向右进行分裂，同时决定将分裂点记录为哪一个
  * PAGE_LAST_INSERT
  * PAGE_DIRECTION
  * PAGE_N_DIRECTION

---

5.3.4 B+树索引的管理

* 索引管理

  *  ALTER TABLE

    ```mysql
    ALTER TABLE tbl_name 
    ADD {INDEX|KEY} [index_name] [index_type]
    (index_col_name,...) [index_option] ...

    ALTER TABLE tbl_name
    DROP PRIMARY KEY | DROP {INDEX|KEY} index_name
    ```

  * CREATE/DROP INDEX

    ```mysql
    CREATE [UNIQUE] INDEX index_name [index_type]
    ON tbl_name(index_col_namae,...)

    DROP INDEX index_name ON tbl_name
    ```

* 查看索引

  ```mysql
  SHOW INDEX FROM tbl_name;
  ```

  * Table：索引所在的表名。

  * Non_unique：非唯一的索引。

  * Key_name：索引的名字，用户可以通过这个名字来执行DROP INDEX。

  * Seq_in_index：索引中该列的位置。

  * Column_name：索引列的名称。

  * Collation：列以什么方式存储在索引中。可以是A或NULL。B+树索引总是A，即排序的。如果使用了Heap存储引擎，并且建立了Hash索引，这里就会显示NULL了

  * Cardinality：索引中唯一值的数目的估计值，Cardinality/表的行数应尽可能接近1，如果非常小，那么用户需要考虑是否可以删除此索引。Cardinality值非常关键，优化器会根据这个值来判断是否使用这个索引，但是这个值并不是实时更新的，只是一个大概的值，可以使用ANLYZE TABLE 命令。

    ```mysql
    ANALYZE TABLE tbl_name;
    ```

  * Sub_part：是否是列的部分索引。如果索引整个列，则该字段为NULL。

  * Packed：关键字如何被压缩。如果没有被压缩，则为NULL。

  * Null：是否索引的列含有NULL值。

  * Index_type：索引的类型。

  * Comment：注释。

* Fast Index Creation（FIC）

  * MySQL5.5之前，对数据库添加和删除索引这类DDL操作，需要创建临时表-》导入数据-》删除原表-》重命名临时表。
  * 对于辅助索引的创建，InnoDB存储引擎会对创建索引的表加上一个S锁。在创建过程中，不需要重建表。删除辅助索引只需要更新内部视图，并把辅助索引的空间标记为可用，同时删除内部视图中对该表的索引定义
  * 由于FIC在索引的创建过程中对表加上了S锁，因此在创建过程中只能对该表进行读操作，若有大量的事务需要对目标表进行写操作，那么数据库的服务同样不可用。
  * 此外，FIC方式只限定于辅助索引，对于主键的创建和删除同样需要重建一张表。

* Online Scheme Change（OSC）

  * “在线”是指事务的创建过程中，可以有读写事务对表进行操作，这提高了原有MySQL数据库的DDL操作时的并发性。
  * 实现OSC的步骤如下：
    * init：即初始化阶段，会对创建的表做一些验证工作，如检查是否有主键，是否存在触发器或者外键等。
    * createCopyTable：创建和原始表一样的新表。
    * alterCopyTable：对创建的新表进行ALTER TABLE操作，如添加索引或列等。
    * createDeltasTable：创建deltas表，该表的作用为下一步创建的触发器所使用。之后对原表的所有DML操作会被记录到createDeltasTable中。
    * createTriggers：对原表创建INSERT、UPDATE、DELETE操作触发器。触发器操作产生的记录被写入到deltas表。
    * startSnapshorXact：开始OSC操作的事务。
    * selectTableIntoOutfile：将原表中的数据写入到新表，为了减少对原表的锁定时间，这里通过分片(chunked)将数据输出到多个外部文件，然后将外部文件的数据导入到copy表中。分片的大小可以指定，默认为500000。
    * dropNCIndexes：在导入到新表前，删除新表中所有的辅助索引。
    * loadCopyTable：将导出的分片文件导入到新表。
    * replayChanges：将OSC过程中原表DML操作的记录应用到新表中，这些记录被保存在deltas表中。
    * recreateNCIndexes：重新创建辅助索引。
    * replayChanges：再次进行DML日志的回放操作，这些日志是在上述创建辅助索引中新产生的日志。
    * swapTables：将原表和新表交换名字，整个操作需要锁定2张表，不允许新的数据产生，由于改名是一个很快的操作，因此阻塞的时间非常短。
  * 限制：
    * 进行修改的表一定要有主键，表本身不能存在外键和触发器等。
    * 在进行OSC过程中，允许SET sql_bin_log=0，因此所做的操作不会同步到slave服务器，可能导致主从不一致的情况。

* Online DDL

  * 虽然FIC可以让InnoDB存储引擎避免创建临时表，从而提高索引的创建效率。但**索引创建时会阻塞表上的DML操作**，OSC虽然解决的上述的部分问题，但是还是有很大的局限性。

  * MySQL 5.6 开始支持Online DDL，其允许辅助缩影创建的同时，还允许诸如INSERT、UPDATE、DELETE这类的DML操作，这极大地提高了可用性。

  * 可以通过Online DDL方式的操作：

    * 辅助索引的创建和删除
    * 改变自增长值
    * 添加或删除外键约束
    * 列的重命名

  * 通过新的ALTER TABLE语法，用户可以选择索引的创建方式：

    ```mysql
    ALTER TABLE tbl_name
    ADD {INDEX|KEY} [index_name] [index_type]
    (index_col_name,...) [index_option]...
    ALGORITHM [=] {DEFAULT|INPLACE|COPY}
    LOCK [=] {DEFAULT|NONE|SHARE|EXCLUSIVE}
    ```

    * ALGORITHM：指定了创建或删除索引的算法：
      * COPY：按照MySQL 5.1之前的工作模式，即创建临时表的方式
      * INPLACE：不创建临时表
      * DEFAULT：表示根据参数old_alter_table来判断是通过INPLACE还是COPY的算法，默认为INPLACE。
    * LOCK：索引创建或删除时对表添加锁的情况：
      * NONE：对目标表不添加任何的锁，可以进行读写事务，这种模式能获得最大的并发度。
      * SHARE：和FIC类似，对目标表加上S锁，可以并发地读事务，写事务需要等待。
      * EXCLUSIVE：对目标表加上X锁，读写事务都不能进行。
      * DEFAULT：首先会判断当前操作是否可以使用NONE模式，若不能，则判断是否可以使用SHARE模式，最后判断是否可以使用EXCLUSIVE模式

  * InnoDB存储引擎实现Onlien DDL的原理是在执行创建或删除操作的同时，将INSERT、UPDATE、DELETE这类DML操作日志写入到一个缓存中。待完成索引创建后再将重做应用到列表上，以此达到数据的一致性。这个缓存的大小由参数innodb_online_alter_log_max_size控制，默认大小是128MB

---

5.4 Cardinality值

* 对于什么时候添加B+树索引，一般经验是，在访问表中很少一部分时使用B+数索引才有意义。

* 选择性：

  * 低选择性：对于性别、地区、类型等字段，他们的取值范围很小，称为低选择性。
  * 高选择性：如果某个字段的取值范围很广，几乎没有重复，则属于高选择性。此时使用B+数索引是最合适的。

* Cardinality的统计是放在存储引擎层进行的；Cardinality的拥挤是通过**采样（Sample）**的方法来完成的

* InnoDB存储引擎更新Cardinality信息的策略(或)为：

  * 表中1/16的数据已发生过变化
  * stat_modified_counter > 2 000 000 000

* InnoDB存储引擎统计Cardinality的方法为采样。默认InnoDB存储引擎对8个叶子节点进行采样，采样的过程如下：

  * 取得B+树索引中叶子节点的数量，即为A。
  * 随机取得B+树索引中的8个叶子节点。统计每个页不同记录的个数，记为P1，P2，…，P8。
  * 根据采样信息给出Cardinality的预估值：Cardinality=（P1+P2+…_P8）* A / 8

* InnoDB存储引擎重新计算索引的Cardinality的时机为：

  * INSERT和UPDATE操作，且满足更新策略
  * ANALYZE TABLE
  * SHOW TABLES STATUS
  * SHOW INDEX
  * 访问INFORMATION_SCHEMA架构下的表TABLES和STATISTICS时

* 相关参数：

  | 参数                                   | 说明                                       |
  | ------------------------------------ | ---------------------------------------- |
  | innodb_stats_transient_sample_pages  | 每次采样页的数量，默认值：8                           |
  | innodb_stats_method                  | 如何对待索引中出现的NULL值记录，默认值：nulls_equal，表示视为相同；nulls_unequal，表示视为不同；nulls_ignored，表示忽略记录 |
  | innodb_stats_persistent              | 是否将命令ANALYZE TABLE计算得到的Cardinality值存放到磁盘上。默认值：OFF |
  | innodb_stats_on_metadata             | 当通过命令SHOW TABLES STATUS、SHOW INDEX、访问INFORMATION_SCHEMA架构下的表TABLES和STATISTICS时，是否需要重新计算索引的Cardinality值。默认值：OFF |
  | innodb_stats_persistent_sample_pages | 若参数innodb_stats_persistent设置为IN，表示ANALYZE TABLE更新Cardinality值时每次采样页的数量。 |

---

5.5 B+树索引的使用

5.5.1 联合索引（补图）

* 联合索引指对表上的多个列进行索引
* 对联合索引idx_a_b(a，b)，则索引组织先按a列排序，a列值相同再按列b排序…；
* 因为第二个键值已经做了排序（在相同a情况下），在一定情况下可以减少filesort

```mysql
# 会使用联合索引
SELECT ... FROM tbl_name WHERE a=xxx AND b = xxx;
SELECT ... FROM tbl_name WHERE a=xxx;
SELECT ... FROM tbl_name WHERE a=xxx ORDER BY b;
SELECT ... FROM tbl_name WHERE a=xxx AND b = xxx ORDER BY c;

#不会使用联合索引
SELECT ... FROM tbl_name WHERE b=xxx;
SELECT ... FROM tbl_name WHERE a=xxx ORDER BY c;
```

5.5.2 覆盖索引

* InnoDB存储引擎支持覆盖索引（covering index，或称索引覆盖），即从辅助索引中就可以得到查询的记录，而不需要查询聚集索引中的记录。
* 使用覆盖索引的一个好处是辅助索引不包含整行记录的所有信息，故其大小要远小于聚集索引，因此可以减少大量的IO操作。
* 对于InnoDB存储引擎的辅助索引而言，由于其包含了主键信息，因此其叶子节点存放的数据为（primary key1，primary key2，…，key1，key2，...）
* 覆盖索引的另一个好处是对某些统计问题而言的。如果辅助索引就能进行统计的，则使用索引覆盖；在通常情况下，注入（a,b）的联合索引，一般是不可以选择列b中所谓的查询条件，但如果是统计操作，并且是覆盖索引的，则优化器会进行选择。

5.5.3 优化器选择不使用索引的情况

* 在某些情况下，当执行EXPLAIN命令进行SQL语句的分析时，会发现优化器并没有选择索引去查找数据（index scan），而是通过扫描聚集索引，也就是直接进行全表扫描（table scan）来得到数据。这种情况多发生于范围查找、JOIN链接操作等情况下。
* 因此对于不能进行索覆盖的情况，优化器选择辅助索引的情况是，通过辅助索引查找的数据是少量的。这是由当前传统机械硬盘的特性锁决定的。

5.5.4 索引提示

* MySQL数据库支持索引提示（INDEX HINT），显式地告诉优化器使用哪个索引。以下两种情况可能需要用到INDEX HINT：
  * MySQL数据库的优化器错误地选择了某个索引，导致SQL语句运行的很慢。（很少见）
  * 某SQL语句可以选择的索引非常多，这时优化器选择执行计划时间的开销可能会大于SQL语句本身。

```mysql
tbl_name [AS alias] [index_hint_list]

index_hint_list:
index_hint [,index_hint] ...

index_hint:
  USE    {INDEX|KEY} [{FOR {JOIN|ORDER BY|GROUP BY}}] ([index_list])  #可以选择
| IGNORE {INDEX|KEY} [{FOR {JOIN|ORDER BY|GROUP BY}}] ([index_list])  #
| FORCE  {INDEX|KEY} [{FOR {JOIN|ORDER BY|GROUP BY}}] ([index_list])  #强制使用

index_List:
index_name [,index_name] ...
```

5.5.5 Multi-Range Read优化（MRR）

* MRR的目得就是为了减少磁盘的随机访问，并且将随机访问转化为较为顺序的数据访问。MRR可适用于range，ref，eq_ref类型的查询。执行计划里有Using MRR
* MRR的好处：
  * MRR使数据访问变得较为顺序。在查询辅助索引时，首先根据得到的查询结果，按照主键进行排序，并按照主键排序的顺序进行书签查找。
  * 减少缓冲池中页被替换的次数
  * 批量处理对键值的查询操作
* 对于InnoDB和MyISAM存储引擎的范围查询和JOIN查询操作，MRR的工作方式如下：
  * 将查询得到的辅助索引键值存放于一个缓存中，这时缓存中的数据是根据辅助索引键值排序的。
  * 将缓存中的键值根据RowID进行排序。
  * 根据RowID的排序顺序来访问实际的数据文件。
* 此外，MRR还可以将某些范围查询，拆分为键值对，以此来进行批量的数据查询，这样做的好处是可以在拆分过程中，直接过滤一些不符合查询条件的数据。

5.5.6 Index Condition Pushdown优化（ICP）

* 在支持ICP后，MySQL数据库会在取出索引的同时，判断是否可以进行WHERE条件的过滤，也就是将WHERE的部分过滤操作放在了存储引擎层。在某些查询下，可以大大减少上层SQL层对记录的索取（fetch），从而提高数据库的整体性能。
* ICP支持range、ref、eq_ref、ref_or_null类型的查询；当前支持MyISAM和InnoDB存储引擎。执行计划里有Using index condition。
* WHERE可以过滤的条件是该索引可以覆盖到的范围。

---

5.6 哈希算法

5.6.1 哈希表

* 直接寻址表问题：
  * 全域U很大是，存储大小为U的一张表T就有点不实际
  * 如果实际要存储的关键字集合K相对于U来说很小，那么分配给T的大部分空间就要浪费掉
* 哈希表：
  * 函数h将关键字域U映射到哈希表T[0..m-1]的槽位上
  * 碰撞（collision）：两个关键字映射到同一个槽上。数据库中医版采用链接法（chaining）解决碰撞
  * 哈希函数：应该能很好地进行散列，使碰撞最小

5.6.2 InnoDB存储引擎中的哈希算法

* InnoDB存储引擎使用哈希算法来对字典进行查找，其冲突机制采用链表方式，哈希函数采用除法散列方式。
* 对于缓冲池页的哈希表来说，在缓冲池中的Page页都有一个chain指针，它指向相同哈希函数值的页。而对于除法散列，m的取值为略大于2倍缓冲池页数量的质数。
* 怎样将要查找的页转换为自然数呢？关键字K= space_id<<20 + space_id+ offset，然后在通过除法散列到各个槽中去。

5.6.3 自适应哈希索引

* 自适应哈希索引采用之前讨论的哈希表的方式实现。不同的是，这仅是数据库自身创建并使用的，DBA本身不能对其进行干预。
* 自适应哈索引经哈希函数映射到一个哈希表中，因此对于字典类型的查找非常快速；但是对范围查找就无能为力了。哈希索引只能用来索索等值的查询

---

5.7 全文检索（FTS）

* B+树索引可以通过索引字段的前缀进行查找
* 全文检索（Full-Text Search）是将存储于数据库中的整本书或整篇文章的任意内容信息查找出来的技术。

5.7.1 倒排索引

* 全文检索通常使用倒排索引（inverted index）来实现。倒排索引同B+树索引一样，也是一种索引结构。它在辅助表（auxiliary table）中存储了单词与单词自身在一个或多个文档中所在位置之间的映射。这通常利用关联数组实现，其拥有两种表现方式：
  * inverted file index，其表现形式为{单词，单词所在文档的ID}
  * full inverted index，其表现形式为{单词，（单词所在文档的ID，在具体文档中的位置）}

5.7.2 InnoDB全文检索（补图）

```mysql
CREATE FULLTEXT INDEX idx_fts ON tbl_name(col_name);
```

* InnoDB采用full inverted index的方式，在InnoDB存储引擎中，将（DocumentId, Position）视为一个ilist。因此在全文检索的表中，有两个列，一个是word字段，另一个是ilist字段，并且在word字段上设有索引。
* 倒排索引需要将word存放在一张表中，这个表称为Auxiliary Table（辅助表）。在InnoDB存储引擎中，我了提高全文检索的并行性能，共有6张Auxiliary Table，目前每张表根据word的Latin编码进行分区。
* FTS Index Cache(全文检索索引缓存)：Auxiliary Table是持久的表，存放在磁盘上。FTS Index Cache是一个红黑树结构，其根据（word, ilist）进行排序。
* InnoDB存储引擎会批量对Auxiliary Table进行更新：
  * 当对全文检索进行查询时，Auxiliary Table首先会将在FTS Index Cache中对应word字段合并到Auxiliary Table中，然后再进行查询。
  * InnoDB存储引擎总是在事务提交时将分词写入到FTS Index Cache，然后再通过批量更新写入到磁盘；
  * 对于删除操作，其在事务提交时不删除磁盘上的Auxiliary Table中的记录，而只是删除FTS Index Cache中的记录，并将删除记录的FTS Document ID保存在INNODB_FT_DELETED表中。可以使用OPTIMIZE TABLE命令来删除索引：
    * 使用参数innodb_optimize_fulltest_only=1可以只进行删除索引操作
    * 使用参数innodb_ft_num_word_optimize可以限制每次实际删除的分词数量，默认2000
    * 彻底删除的文档ID会记录到表INNODB_FT_BEING_DELETED中
    * 已经删除的文档ID不允许再次插入，否则报错
  * 在数据库关闭时，在FTS Index Cache中的数据会同步到磁盘上的Auxiliary Table中
* FTS Document ID：为了支持全文检索，必须有一个列与word进行映射，在InnoDB中这个列被命名为FTS_DOC_ID，其类sing必须是BIGINT UNSIGNED NOT NULL，并且会自动在该列上加上一个名为FTS_DOC_ID_INDEX的Unique Index
* stopword列表：表示该列表中的word不需要对其进行索引分词操作。存储在INNODB_FT_DAFAULT_STOPWORD表中，默认有36个stopword；可以通过参数innodb_ft_stopword_table来自定义
* InnoDB存储引擎的全文检索限制：
  * 每张表只能有一个全文检索的索引
  * 由多列组合而成的全文检索的索引列必须使用相同的字符集与排序规则
  * 不支持灭有单词界定符（delimiter）的语言，如中文、日语、韩语等

---

5.7.3 全文检索

```mysql
MATCH(col1,col2,...) AGAINST (expr [search_modifier])

search_modifier:
{
  	IN NATURAL LANGUAGE MODE
  | IN NATURAL LANGUAGE MODE WITH QUERY EXPANSION
  | IN BOOLEAN MODE
  | WITH QUERY EXPANSION
}
```

* 在WHERE条件中使用MATCH函数，查询返回的记过是根据相关性(Relevance)进行降序排序的
* 相关性的值是一个非负的浮点数，0表示没有任何的相关性。MySQL其相关性的计算依据以下四个条件：
  * word是否在文档中出现。
  * word在文档中出现的次数。
  * word在索引列中的数量。
  * 多少个文档包含该word。
* 对于InnoDB存储引擎的全文检索，还需要考虑以下因素：
  * 查询word在stopword列中，忽略该字符串的查询
  * 查询的word的字符长度是否在区间[innodb_ft_min_token_size, innodb_ft_max_token_size]内，默认[3, 84]
* Natural Language
  * 默认模式
* Boolean
  * 查询字符串的前后字符会有特殊的含义
  * 操作符：
    * +表示该word必须存在
    * -表示该word必须被排除
    * (no operator)表示该word是可选的，但是如果出现，其相关性会更高
    * @distance 表示查询的多个单词之间的距离是否在distance之内，distance的单位是字节。这种全文检索的查询页称为Proximity Search
    * \>表示出现该单词时增加相关性
    * <表示出现该单词时降低相关性
    * ~表示允许出现该单词，但是出现时相关性为负
    * *表示以该单词开头的单词
    * "表示短语
* Query Expansion
  * MySQL数据库支持全文检索的扩展查询，通常在查询的关键词太短，用户需要implied knowledge（隐含知识）时进行。
  * 该查询分为两个阶段：
    * 第一阶段：根据搜索的单词进行全文索引查询。
    * 第二阶段：根据第一阶段产生的分词再进行一次全文检索的查询。

---

6 锁

* lock与latch
* InnoDB存储引擎中的锁
* 锁的算法
* 锁问题
* 阻塞
* 死锁
* 锁升级

---

6.1 什么是锁

* 锁机制用于管理对共享资源的并发访问，提供数据的完整性和一致性。
* 虽然现在数据库系统做的越来越类似，但是有多少种数据库，就可能存在多少种锁的实现方法
* InnoDB存储引擎提供一致性的非锁定读、行级锁支持；且行级锁没有额外的开销，并可以同时得到并发性和一致性。

---

6.2 lock和latch

* latch一般称为闩(shuan)锁（轻量级的锁），因为其要求锁定的时间必须非常短。若持续的时间长，则应用的性能会非常差。其目得是用来保证**并发线程**操作临界资源的正确性，并且通常没有死锁检测的机制。在InnoDB存储引擎中，latch又可分为：
  * mutex（互斥量）
  * rwlock（读写锁）
* lock的对象是事务，用来锁定数据库中的对象，如表、页、行。并且一般lock的对象在书屋commit或rollback后进行释放。有死锁机制。

|      | lock                                     | latch                           |
| ---- | ---------------------------------------- | ------------------------------- |
| 对象   | 事务                                       | 线程                              |
| 保护   | 数据库内容                                    | 内存数据结构                          |
| 持续时间 | 整个事务过程                                   | 临界资源                            |
| 模式   | 行锁、表锁、意向锁                                | 读写锁、互斥量                         |
| 死锁   | 通过waits-for graph、time out等机制进行死锁检测和处理   | 无死锁检测与处理机制。仅通过应用程序加锁的顺序保证无死锁的情况 |
| 存在于  | Lock Manager的哈希表中                        | 每个数据结构的对象中                      |
| 查看   | SHOW ENGINE INNODB STATUS；INNODB_TRX/INNODB_LOCKS/INNODB_LOCK_WAITS | SHOW ENGINE INNODB MUTEX        |

---

6.3 InnoDB存储引擎的锁

6.3.1 锁的类型

* InnoDB存储引擎实现了如下两种标准的**行级锁**：

  * 共享锁（S Lock），允许事务读一行数据。
  * 排他锁（X Lock），允许事务删除或更新一行数据。

* 锁兼容（Lock Cpmpatible）：如果一个事务T1已经获得了行r的共享锁，呢么另外的事务T2可以立即获得行r的共享锁，这种情况称为锁兼容。需要注意的是，兼容是指对同一记录（row）锁的兼容性情况。

  |      | X    | S    |
  | ---- | ---- | ---- |
  | X    | 不兼容  | 不兼容  |
  | S    | 不兼容  | 兼容   |

* InnoDB存储引擎支持多粒度（granular）锁定，这种锁定允许事务在行级上的锁和表级上的锁同时存在。为了支持不同粒度上进行加锁操作，InnoDB存储引擎支持一种额外的锁方式，称之为意向锁（Intention Lock）。意向锁是将锁定的对象分为多个层次，意向锁以为着事务希望在更细粒度（fine granularity）上进行加锁。（补图）

* InnoDB存储引擎的意向锁即为表级别的锁，因此不会阻塞除权标扫以外的任何请求。设计目得主要是为了在一个事务中揭示下一行将被请求的锁类型，支持两种意向锁：

  * 意向共享锁（IS Lock），事务想要获得一张表中某几行的共享锁
  * 意向排他锁（IX Lock），事务想要获得一张表中某几行的排他锁

  |      | IS   | IX   | S    | X    |
  | ---- | ---- | ---- | ---- | ---- |
  | IS   | 兼容   | 兼容   | 兼容   | 不兼容  |
  | IX   | 兼容   | 兼容   | 兼容   | 不兼容  |
  | S    | 兼容   | 不兼容  | 兼容   | 不兼容  |
  | X    | 不兼容  | 不兼容  | 不兼容  | 不兼容  |

6.3.2 一致性非锁定读（补图）

* 一致性非锁定读（consistent nonlocking read）是指InnoDB存储引擎通过行多版本控制（multi versioning）的方式来读取当前执行时间数据库中行的数据

* 非锁定读不需要等待访问的行上X锁的释放，而是去读取一个快照数据；快照数据是通过undo段来完成的，没有额外的开销；读取快照数据不需要上锁。即读取不会占用和等待表上的锁，这是默认的读取方式

* 一个行记录可能有不止一个快照数据，一般称这种技术为多版本技术，由此带来的并发控制，称之为多版本并发控制（Multi Version Concurrency Control, MVCC）

* 在不同的事务隔离级别下，读取的方式不同，对快照数据的定义不同。在READ COMMITTED和REPEATABLE READ（默认隔离级别）下，InnoDB存储引擎使用非锁定的一致性读。

  |      | READ COMMITED | REPEATABLE READ |
  | ---- | ------------- | --------------- |
  | 读    | 非锁定读          | 非锁定读            |
  | 快照数据 | 被锁定行的最新一份快照数据 | 事务开始时的行数据版本     |
  | 加锁方法 | Record Lock   | Next-Key Lock   |

6.3.3 一致性锁定读

* 可以显式地对数据库读取操作进行加锁操作

```mysql
SELECT ... FOR UPDATE     		#对读取的行记录加了一个X锁
SELECT ... LCOK IN SHARE MODE	#对读取的行记录加了一个S锁

#以上语句必须在事务中，当事务提交了，锁也就释放了
```

6.3.4 自增长与锁

* 在InnoDB存储引擎的内存结构中，对每个含有自增长值的表都有一个自增长计数器（auto-increment counter）。当堆含有自增长计数器的表进行插入操作时，这个计数器会被初始化，执行如下语句来得到计数器的值：

  ```mysql
  SELECT MAX(auto_inc_col) FROM t FOR UPDATE;
  ```

* AUTO-INC Locking：插入操作会依据这个自增长的计数器值+1赋予自增长列。这种锁其实是采用一种特殊的表锁机制。为了提高插入性能，所不是在一个事务完成后才释放，而是在完成对自增长值插入的SQL语句后立即释放。存在问题：

  * 队友有自增长值的列的并发插入性能较差，事务必须等待前一个插入的完成（虽然不用等待事务的完成）
  * 对于INSERT...SELECT的大数据量的插入会影响插入的性能，因为另一个事务的插入会被阻塞。

* 自增长的插入分类：

  | 插入类型               | 说明                                       |
  | ------------------ | ---------------------------------------- |
  | insert-like        | 指所有的插入语句，如INSERT、REPLACE、INSERT...SELECT、REPLACE...SELECT、LOAD DATA等 |
  | simple inserts     | 指能在插入前就确定插入行数的语句。如INSERT、REPLACE等；不包含INSERT...ON DUPLICATE KEY UPDATE这类语句 |
  | bulk inserts       | 指在插入前不能确定得到插入行数的语句，如INSERT...SELECT、REPLACE...SELECT、LOAD DATA |
  | mixed-mode inserts | 指插入中有一部分是自增长的，有一部分是确定的，如INSERT...ON DUPLICATE KEY UPDATE |

* innodb_autoinc_lock_mode参数：

  | innodb_autoinc_lock_mode | 说明                                       |
  | ------------------------ | ---------------------------------------- |
  | 0                        | 即通过表锁的AUTO-INC Locking的方式。因为有新的自增长方式，0这个选项不应该是新版用户的首选项 |
  | 1                        | 默认值，对于“simple inserts”会用互斥量去对内存中的计数器进行累加的操作；对于“bulk inserts”还是使用AUTO-INC Locking。自增长的列值是连续的。在这种方式下，statement-based的replication还是能很好地工作 |
  | 2                        | 对于所有的“insert-like”自增长值的产生都是通过互斥量。最高的并发性能。自增长的列值不是连续的。在这种方式下，statement-based的replication会出现问题，必须使用row-based replication |

* 在InnoDB存储引擎中，自增长值的列必须是索引，同时必须是索引的第一个列。

6.3.5 外键和锁

* 在InnoDB存储引擎中，对于一个外键列，如果灭有显示地对这个列家索引，InnoDB存储引擎自动对其加上一个索引，因为这样可以避免表锁。
* 对于外键值的插入或更新，首先需要查询父表中的记录，即SELECT父表，此时不是使用一致性非锁定读（这样会发生数据不一致的问题），而是使用SELECT...LOCK IN SHARE MODE方式，即**主动对父表加S锁**。如果这时父表已经加了X锁，子表上的操作会被阻塞。

---

6.4 锁的算法

6.4.1 锁的3种算法

* InnoDB存储引擎有3种行锁的算法：
  * Record Lock：单个行记录上的锁
  * Gap Lock：间隙锁，锁定一个范围，但不包含记录本身
  * Next-Key Lock：Gap Lock+Record Lock，锁定一个范围，并且锁定记录本身， 默认。如索引值1，5，8，10，12，若锁住8，则会锁住范围(5,8]和(8,10)
* Record Lock总会去锁住索引记录，如果InnoDB存储引擎表在建立的时候没有设置任何一个索引，那么这时InnoDB存储引擎会使用隐式的主键进行锁定。
* 当查询的索引含有唯一属性时，InnoDB存储引擎会对Next-Key Lock进行优化，将其降级为Record Lock，即进锁住索引本身，而不是范围
* 对于Next-Key Lock，InnoDB存储引擎还会对辅助索引的下一个键值加上gap lock，gap lcok的作用是为了阻止对个事务将记录插入到同一个范围内，而这回导致Phantom Problem问题的产生。

6.4.2 解决Phantom Problem

* Phantom Problem是指在同一事务下，连续执行两次同样的SQL语句可能导致不同的结果，第二次的SQL语句可能会返回之前不存在的行。

---

6.5 锁问题

6.5.1 脏读

* 脏数据是指事务对缓冲池中行记录的修改，并且还没有被提交（commit）。
* 脏读指的就是在不同的事务下，当前事务可以读到另外事务未提交的数据，简单来说就是可以读到脏数据。
* 一般不会发生。

6.5.2 不可重复读

* 不可重复读是指在一个事务内多次读取同一数据集合，读取到的数据是不一样的情况。
* 不可重复读和脏读的区别是：脏读读取到的是未提交的数据，而不可重复读读到的确实已经提交的数据。
* 一般可以接受。
* MySQL官方文档将不可重复读定义为Phantom Problem，InnoDB存储引擎采用Next-key Lock算法，避免了不可重复读。

6.5.3 丢失更新

* 丢失更新是指一个事务的更新操作会被另一个事务的更新操作锁覆盖，从而导致数据的不一致。
* 在当前数据库的任何隔离级别下，都不会导致数据库理论意义上的都是更新问题。
* 另一个逻辑意义上的丢失更新问题:
  * 事务T1查询一行数据，放入本地内存，显示给终端用户User1
  * 事务T2查询一行数据，并将取得的数据显示给终端用户User2
  * User1修改这行记录，更新数据库并提交
  * User2修改这行记录，更新数据库并提交
* 要避免这种情况，需要让事务在这种情况下的操作变成串行化。

---

6.6 阻塞

* 因为不同锁之间的兼容性关系，在某些时刻一个事务中的锁需要等待另一个事务中的锁释放它所占用的资源，这就是阻塞。阻塞并不是一件坏事，其是为了确保事务可以并发且正常地运行。
* 参数innodb_lock_wait_timeout参数用来控制等待的时间（默认50秒）；innodb_rollback_on_timeout参数用来是定是否在等待超时时对进行中的事务进行回滚操作（默认OFF）

---

6.7 死锁

6.7.1 死锁的概念

* 死锁是指两个或两个以上的事务在执行过程中，因争夺资源而造成一种互相等待的现象。
* 当前数据库普遍采用wait-for graph（等待图）的方式来进行死锁检测。其要求数据库曹村以下两种信息：
  * 锁的信息链表
  * 事务等待链表
* 在wait-for graph中，事务为图中的节点，而在图中 ，事务T1执行事务T2边的定义为：
  * 事务T1等待事务T2所占用的资源
  * 事务T1最终等待事务T2所占用的资源，也就是事务之间在等待相同的资源，而事务T1发生在事务T2的后面
* 通过上述链表可以构造出一张图，而在这个图中若存在贿赂，就代表存在死锁。wait-for graph的死锁检测通常采用深度优先的算法实现

6.7.2 死锁概率

* 事务发生死锁的概率与一下几点你因素相关：
  * 系统中事务的数量（n），数量越多发生死锁的概率越大。
  * 每个事务操作的数量（r），每个事务操作的数量越多，发生死锁的概率越大。
  * 操作数据的集合（R），越小则发生死锁的概率越大。

---

6.8 锁升级

* 锁升级（Lock Escalation）是指将当前锁的粒度降低。
* InnoDB不存在锁升级的问题，因为其不是根据每个记录来产生锁的，相反，其根据每个事务访问的每个页对锁进行管理的，采用的是位图的方式。因此不管一个事务锁住页中的一个记录还是多个记录，其开销是一致的。

---

7 事务

* 认识事务
* 事务的实现
* 事务控制语句
* 隐式提交的SQL语句
* 对于事务操作的统计
* 事务的隔离级别
* 分布式事务
* 不好的事务习惯

---

7.1 认识事务

* 事务会把数据库从一种一致状态转换为另一种一致的状态。在事务中的操作，要么都做修改，要么都不做
* ACID：
  * 原子性（Atomicity）：指的是整个数据库事务是不可分割的工作单位。只有使事务中的所有数据库操作都执行成功，才算整个事务成功。
  * 一致性（consistency）：指的是事务将数据从一种状态转变为下一种一致的状态。在事务开始之前和事务结束之后，数据库的完整性约束都没有被破坏。
  * 隔离性（isolation）：事务的隔离性要求每个读写事务的对象对其他事务的操作对象能相互分离，即该事务提交前对其他事务都不可见
  * 持久性（durability）：事务一旦提交，其结果就是永久性的。
* 分类：
  * 扁平事务（Flat Transactions）：
    * 最简单的一种。所有操作都处于同一层次，其由BEGIN WORK开始，由COMMIT WORK或ROLLBACK WORK结束，其间的操作是原子的，要么都执行，要么都回滚。
    * 主要限制是不能提交或回滚事务的某一部分，或分几个步骤提交。
  * 带有保存点的扁平事务（Flat Transactions with Savepoints）
    * 除了支持扁平事务支持的操作外，允许早事务执行过程中回滚到同一事务中较早的一个状态。
    * 保存点（Savepoint）用来通知系统应该记住事务当前的状态，以便当之后发生错误时，事务能回到保存点当时的状态。保存点用SAVE WORK来建立。
    * 当发生系统崩溃时，所有保存点都将消失，因为其保存点是易失的（volatile），而非持久的（persistent）。这以为着当进行恢复时，事务需要从开始处重新执行。
  * 链事务（Chaned Transactions）
    * 保存点模式的一种变种。其思想是：在提交一个事务时，释放不需要的数据对象，将必要的处理上下文隐式地传给下一个要开始的事务。
    * 注意，提交事务操作和开始下一个事务曹组将合并为一个原子操作。这意味着下一个事务将看到上一个事务的结果，就好像在一个事务中进行的一样。
    * 链事务和带有保存点的扁平事务不同的是，带有保存点的扁平事务能回滚到任意正确的保存点；而链事务中的回滚仅限于当前事务，即只能恢复到最近一个的保存点。
  * 嵌套事务（Nested Transactions）
    * 嵌套事务的定义：
      * 嵌套事务是由若干事务组成的一棵树，子树既可以是嵌套事务，也可以是扁平事务。
      * 出在叶节点的事务是扁平事务。但是每个子事务从 根到叶子节点的距离可以是不同的。
      * 位于根节点的事务称为顶层事务（top-level transaction），其他事务称为子事务（subtransaction）。事务的前驱（predecessor）称为父事务（parent），事务的下一层称为儿子事务（child）
      * 子事务既可以提交也可以回滚。但是它的提交操作并不马上生效，除非其父事务已经提交。
      * 树中的任意一个事务的回滚会引起它的所有子事务一同回滚，故子事务仅保留ACI特性，不具有D特性。
  * 分布式事务（Distributed Transactions）
    * 通常是一个在 分布式环境下运行的扁平事务
* 对于InnoDB存储引擎来说，其支持扁平事务、待保存点的事务、链事务、分布式事务。对于嵌套事务，其并不原生支持。然后用户扔可以通过带有保存点的事务来默认串行的嵌套事务。

---

7.2 事务的实现

* 事务的隔离性由锁来实现。原子性、一致性、持久性由数据库的redo log和undo log来完成。redo log用来保证事务的**原子性和持久性**；undo log用来保证事务的**一致性**。
* redo和undo并不是逆过程。redo和undo的作用都可以视为是一种恢复操作，redo恢复提交事务修改的页操作，而undo回滚行记录到某个特定版本。
* 因此两者记录的内容不同。redo通常是物理日志，记录的是页的物理修改操作。undo是逻辑日志，根据每行记录进行记录。

|      | redo   | undo   |
| ---- | ------ | ------ |
| 事务   | 持久性（D） | 一致性(C) |
| 读写   | 顺序     | 随机     |
| 内容   | 物理日志   | 逻辑日志   |

7.2.1 redo

1. 基本概念

* 重做日志用来实现事务的持久性（D），其由两部分组成：
  * 内存中的重做日志缓冲（redo log buffer），其是易失的
  * 重做日志文件（redo log file），其是持久的
* InnoDB存储引擎通过**Force Log at Cimmit机制**实现事务的持久性，即当事务提交时，必须先将该事务的所有日志写入到重做日志文件进行持久化，待事务的COMMIT操作完成才算完成。
* 重做日志缓冲先写入文件系统缓存，为了确保重做日志写入磁盘，必须进行一次fsync操作。因此磁盘的性能决定了事务提交的性能，也就是数据库的性能。
* 参数innodb_flush_log_at_trx_commit用来控制重做日志刷新到磁盘的策略：
  * 默认值是1，表示事务提交时必须调用一次fsync操作。
  * 0表示事务提交时不进行写入重做日志操作。这个操作仅在master thread中完成，master thread中每1秒会进行一次重做日志文件的fsync操作
  * 2表示提交时将重做日志写入重做日志文件，但仅写入文件系统的缓存中，不进行fsync操作。当数据库宕机而操作系统不宕机时，不会导致事务丢失；当操作系统宕机时，重启数据库会丢失未从文件系统缓存刷新到重做日志文件的那部分事务。
* binlog用来进行POINT-IN-TIME（PIT）的恢复及主从复制（Replication）环境的建立。从表面看和重做日志非常相似，都是记录了对于数据库操作的日志，从本质上看，两者非常不同：
  * redo log是在InnoDB存储引擎层产生；而binlog是在MySQL数据库的上层产生的，任何存储引擎对于数据库的更改都会产生binlog
  * 两种日志记录的内容形式不同。binlog是逻辑日志，其记录的是对应的SQL语句；redo log是物理格式日志，其记录的是对每个页的修改
  * 两种日志记录写入磁盘的时间点不同。binlog值在事务提交完成后进行一次写入；而redo log在事务进行中不断地被写入，这表现为日志并不是随事务提交的顺序进行写入的。

2. log block

* 在InnoDB存储引擎中，重做日志都是以512字节进行存储的。这以为着重做日志缓存、重做日志文件都是以块（block）的方式进行保存的，称之为重做日志块（redo log block），每块大小为512字节。

* 若一个页中产生的重做日志数量大于512字节，那么需要分割为多个重做日志块进行存储。由于重做日志块的大小和磁盘扇区的大小一样，因此重做日志的写入可以保证原子性，不需要doublewrite技术。

* 重做日志块组成（补图）：

  * 日志块头（log block header）：12字节

    | 名称                        | 字节   | 说明                                       |
    | ------------------------- | ---- | ---------------------------------------- |
    | LOG_BLOCK_HDR_NO          | 4    | log buffer由log block组成，在内部log buffer就好似一个数组，该部分就用来标记这个数组中的位置。其实递增并且循环使用的。第一位用来判断是否是flush bit，因此最大值为2G |
    | LOG_BLOCK_HDR_DATA_LEN    | 2    | log block所占用的大小，单位字节                     |
    | LOG_BLOCK_FIRST_REC_GROUP | 2    | log block中第一个日志（不算之前block剩余的）所在的偏移量      |
    | LOG_BLOCK_CHECKPOINT_NO   | 4    | 该log block最后写入时的检查点第4个字节的值               |

  * 日志内容（log body）：最多492字节

  * 日志块尾（log block tailer）：8字节

    | 名称               | 字节   | 说明                                       |
    | ---------------- | ---- | ---------------------------------------- |
    | LOG_BLOCK_TRL_NO | 4    | 其值和LOG_BLOCK_HDR_NO相同，并在函数log_block_init中被初始化 |

3. log group（补图）

* log group为重做日志组，其中有多个重做日志文件。InnoDB存储引擎实际只有一个log group

* log group是一个逻辑的概念，并没有一个实际存储的物理文件来表示log group信息。

* log buffer根据一定规则将内存中的log block刷新到磁盘，这个规则是：

  * 事务提交时
  * 当log buffer中有一般的内存空间已经被使用时
  * log checkpoint时

* 对于log block的写入追加(append)到redo log file的最后部分，当一个redo log file被写满时，会接着写入下一个redo log file，其使用方式是round-robin。

* 每个redo log file的前2KB的部分不保存log block信息。对于log group中的第一个redo log file，其前2KB保存4个512字节大小的块，内容如下；log group中的其余redo log file仅保留空间，不保存上述信息。

  | 名称              | 大小（字节） |
  | --------------- | ------ |
  | log file header | 512    |
  | checkpoint1     | 512    |
  | 空               | 512    |
  | checkpoint2     | 512    |

4. 重做日志格式

* InnoDB存储引擎的存储管理是基于页的，故其重做日志格式也是基于页的。（补图）
  * 通用头部格式：
    * redo_log_type：重做日志的类型。InnoDB 1.2版本时，有51种重做日志类型。
    * space：表空间的ID。
    * page_no：页的偏移量。
  * redo log body：根据重做日志类型的不同，会有不同的存储内容

5. LSN

* LSN是Log Sequence Number的缩写，其代表的是日志序列号。在InnoDB存储引擎中，LSN占用8字节，并且单调递增。LSN表示的含义有：
  * 重做日志中：重做日志写入的总量
  * checkpoint的位置：刷新到磁盘的LSN
  * 页中：该页最后刷新时LSN的大小，用来判断页是否需要进行恢复操作

6. 恢复（补图）

* 由于checkpoint表示已经刷新到磁盘页的LSN，因此在恢复过程中仅需恢复checkpoint开始的日志部分
* InnoDB存储引擎的重做日志是物理日志，且是幂等的。

---

7.2.2 undo

1. 基本概念

* 重做日志记录了事务的行为，可以很好地通过其对页进行“重做”操作。但是事务有时还需要进行回滚操作，这时就需要undo
* redo存放在重做日志文件中。与redo不同，undo存放在数据库内部的一个特殊段（segment）中，这个段称为undo段（undo segment）。undo段位于共享表空间内。
* undo是逻辑日志，只是将数据库逻辑地恢复到原来的样子。所有修改都被逻辑取消了，但是数据结构和页本身在回滚之后可能不大相同。
* 除了回滚操作，undo的另一个作用就是MVCC，即在InnoDB存储引擎中MVCC是通过undo来实现的。当用户读取一行记录时，若该记录已经被其他事务占用，当前事务可以通过undo读取之前的行版本信息，以此实现非锁定读取。
* 事务在undo log segment分配也并写入undo log的这个过程同样需要写入重做日志。这是因为undo log也需要持久性的保护。

2. undo存储管理

* 为了保证事务并发操作时，在写各自的undo log时不发生冲突，InnoDB采用回滚段的方式来维护undo log的并发写入和持久化。
* InnoDB存储引擎有rollback segment，每个回滚段中记录了1024个undo log segment(slot)，而在每个undo log segment中进行undo页的申请。共享表空间偏移量为5的页（0，5）记录了所有rollback segment header所在的页，这个页的类型为FIL_PAGE_TYPE_SYS。可支持同时在线的事务数为 rollback segment数量*1024
  * 回滚段0预留在系统表空间ibdata中
  * 回滚段1~32存放于临时表的系统表空间ibtmpl中
  * 回滚段33~根据配置存放到独立undo表空间或ibdata中
* 参数：
  * innodb_undo_directory：用于设置rollback segment文件所在的路径。默认值为‘’.“，表示当前InnoDB存储引擎目录。
  * innodb_undo_logs：用来设置rollback segment的个数，默认128。
  * innodb_undo_tablespaces：用来设置构成rollback segment文件的数量，这样rollback segment可以较为平均的分布在多个文件中。
* 当事务提交时，InnoDB存储引擎会做以下两件事情：
  * 将undo log放入列表中，以供之后的purge操作
  * 判断undo log所在页是否可以重用，若可以分配给下个事务使用。
* 事务提交之后并不能马上删除undo log及undo log所在的页。这是因为可能还有其他事务需要通过undo log来得到行记录之前的版本。故事务提交时将undo log放入一个链表中，是否可以最终删除undo log及undo log所在页由purge线程来判断。
* 若为每一个事务分配一个单独的undo页会非常浪费存储空间，因此InnoDB存储引擎的设计中对undo页可以进行重用。具体来说：
  * 当事务提交时，先将undo log 放入链表中
  * 然后判断undo页的使用空间是否小于3/4
  * 若是，则表示undo页可以被重用，之后新的undo log记录在当前undo log的后面

3. undo log个格式

* 在InnoDB存储引擎中，undo log分为：
  * insert undo log：指在insert操作中产生的undo log。因为insert操作的记录，只对事务本身可见，对其他事务不可见，故该undo log可以在事务提交后直接删除，不需要purge操作。其结构如下（补图）：
    * next：2字节，记录下一个undo log的位置
    * type_cmpl：1字节，记录undo的类型，对于insert undo log，该值为11
    * undo_no：1字节，记录事务的undo no
    * table_id：1字节，记录undo log所对应的表对象
    * n_unique_index：所有主键的列和值，在进行rollback操作时，根据这些值定位到具体的记录，然后进行删除即可。
    * start：2字节，记录undo log的开始位置
  * update undo log（补图）：记录的是对delete和update操作产生的undo log。该undo log可能需要提供MVCC机制，因此不能再事务提交时就进行删除。提交时需要放入undo log链表，等待purge线程进行最后的删除。其结构如下（补图）：
    * next
    * type_cmpl
      * 12 TRX_UNDO_UPD_EXIST_REC：更新non-delete-mark的记录
      * 13 TRX_UNDO_UPD_DEL_REC：将delete的记录标记为not delete
      * 14 TRX_UNDO_DEL_MARK_REC：将记录标记为delete
    * undo_no
    * table_id
    * info_bits：1字节
    * DATA_TRX_ID：rec 事务Id，6字节
    * DATA_ROLL_PTR：rec 回滚指针，7字节
    * n_unique_index
    * update vector：表示update操作导致发生改变的列。每个修改的列信息都要记录到undo log 中。对于不同的undo log类型，可能还需要记录对索引列所做的修改。
    * start

4. 查看undo信息

---

7.2.3 purge

* purge用于最终完成delete和update操作。若该行记录已不被任何其他事务引用了，那么就可以进行真正的delete操作。
* history列表，根据事务提交的顺序，将undo log进行链接。（补图）
* 先从history列表中找undo log，然后再从undo page中找undo log变了大量的随机读取操作
* 参数：
  * innodb_purge_batch_size：用来设置每次purge操作需要清理的undo page数量，默认300。
  * innodb_msx_purge_lag：用来控制history list的长度，若长度大于该参数时，其会”延缓“DML操作，默认为0，表示不做限制
    * 延缓算法：delay =  ( length(history_list)  - innodb_msx_purge_lag  ) * 10- 5
    * 延迟单位：毫秒
    * 延迟对象：行（不是DML操作，如DML操作有5行，则延迟5*delay ms）
  * innodb_max_purge_lag_delay：控制delay的最大毫秒数

---

7.2.4 group commit

* 为了提高磁盘fsync的效率，当前数据库都提供了group commit的功能，即一次fsync可以刷新确保多个事务日志被写入文件。
* 对于InnoDB存储引擎来说，事务提交会进行两个阶段的操作，其他事务的步骤a）可以在步骤b）执行时进行：
  * 修改内存中事务对应的信息，并且将日志写入重做日志缓冲。
  * 调用fsync将确保日志都从重做日志缓冲写入磁盘。
* 为了确保存储引擎层中的事务和binlog的一致性，二者之间使用了两阶段事务：（补图）
  * 当事务提交时InnoDB存储引擎进行prepare操作。
  * MySQL数据库上层写入binlog
  * InnoDB存储引擎将日志写入重做日志文件
    * 修改内存中事务对应的信息，并且将日志写入重做日志缓冲
    * 调用fsync将确保日志都从重做日志缓冲写入磁盘
* 为了保证MySQL数据库上层binlog的写入顺序和InnoDB层的事务提交顺序一致，MySQL数据库库内部使用了prepare_commit_mutex这个锁。但在启用这个锁之后，步骤3）中的步骤a）不可以在其他事务执行步骤b）时进行，从而导致了group commit失效。
* BLGC（Binary Log Group Commit）:（补图）在MySQL数据库上层进行提交时首先按顺序将其放入一个队列中，队列中的第一个事务称为leader，其他事务称为follower。BLGC步骤：
  * Flush阶段，将每个事务的binlog写入内存
  * Sync阶段，将内存中的binlog刷新到磁盘，若队列中有多个事务，那么仅一次sync操作就完成了二进制日志的写入，这就是BLCG
  * Commit阶段，leader根据顺序调用存储引擎层事务的提交，因此修复原先由锁prepare_commit_mutex导致group commit失效的问题。

---

7.3 事务控制语句

* 默认设置下，事务是自动提交的，即执行SQL语句后就会马上执行COMMIT操作。
* 事务控制语句：
  * START TRANSACTION|BEGIN：显式地开启一个事务
  * COMMIT [WORK]：提交事务，并使得已对数据库做的修改称为永久性的
  * ROLLBACK [WORK]：回滚事务会结束用户的事务，并撤销正在进行的所有未提交的修改
  * SAVEPOINT identifier：SAVEPOINT允许在事务中创建一个保存点，一个事务中可以有多个SAVEPOINT
  * RELEASE SAVEPOINT identifier：删除一个事务的保存点
  * ROLLBACK TO [SAVEPOINT] identifier：把事务回滚到保存点
  * SET TRANSACTION：设置事务的隔离级别
* completion_type：控制[WORK]事务结束后的行为是CHAIN 还是RELEASE
  * 0：默认，没有任何操作，这种设置下COMMIT 和COMMIT WORK是完全等价的
  * 1：COMMIT WORK等同于COMMIT AND CHAIN，表示马上自动开启一个相同隔离界别的事务
  * 2：COMMIT WORK等同于COMMIT AND RELEASE，表示事务提交后会自动断开与服务器的连接。
* 一些注意点：
  * 一条语句失败并抛出异常时，并不会导致先前已经执行的语句自动回滚。必须由用户自己来决定不是否对其进行提交或者回滚操作。
  * 即使执行了ROLLBACK TO SAVEPOINT，之后也需要显式地运行COMMIT或ROLLBACK命令

---

7.4 隐式提交的SQL语句

* 以下这些SQL语句会产生一个隐式的提交（COMMIT）操作

  * DDL

    |           | ALTER | CREATE | DROP | RENAME | TRUNCATE |
    | --------- | ----- | ------ | ---- | ------ | -------- |
    | DATABASE  |       | YES    | YES  |        |          |
    | EVENT     | YES   | YES    | YES  |        |          |
    | PROCEDURE | YES   | YES    | YES  |        |          |
    | TABLE     | YES   | YES    | YES  | YES    | YES      |
    | VIEW      | YES   | YES    | YES  |        |          |
    | INDEX     |       | YES    | YES  |        |          |
    | TRIGGER   |       | YES    | YES  |        |          |

  * 用来隐式地修改MySQL架构的操作：CREATE USER、DROP USER、GRANT、RENAME USER、REVOKES、SET PASSWORD

  * 管理语句：ANALYZE TABLE、CACHE INDEX、CHECK TABLE、LOAD INDEX、INTO CACHE、OPTIMIZE TABLE、REPAIR TABLE

---

7.5 对于事务操作的统计

* TPS（Transaction Per Second）
* 计算TPS的方法是：（com_commit + com_rollback） / time
  * 前提：所有的事务都是显式提交的，如果存在隐式提交和回滚（默认autocommit=1），不会计算到com_commit 和 com_rollback变量中。

---

7.6 事务的隔离级别

* SQL标注定义的四个隔离级别为：

  * READ UNCOMMITTED
  * READ COMMITTED
  * REPEATABLE READ（InnoDB默认，通过Next Key Lock算法避免了幻读）
  * SERIALIZABLE

* 隔离级别修改

  * ```mysql
    SET [GLOBAL | SESSION] TRANSACTION ISOLATION LEVEL
    {
      	READ UNCOMMITTED
      | READ COMMITTED
      | REPEATABLE READ
      | SERIALIZABLE
    }
    ```

    * 配置文件中[mysqld]中添加 transaction-isolation = xxx

    * 查看：SELECT @@tx_isolation

  * 在SERIALIZABLE的事务隔离级别，InnoDB会对每个SELECT语句后自动加上LOCK IN SHARE MODE，在这个事务隔离级别下，读占用了锁，对一致性非锁定读不再予以支持。主要用于InnoDB存储引擎的分布式事务。

  * 在READ COMMITED的事务隔离级别下，除了唯一性的约束检查及外键约束的检查需要gap lock，InnoDB存储引擎不会使用gap lock的锁算法

---

7.7 分布式事务

7.7.1 MySQL数据库分布式事务

* InnoDB存储引擎提供了对XA事务的支持，并通过XA事务来支持分布式事务的实现。

* 分布式事务指的是允许多个独立的事务资源（transaction resources）参与到一个全局的事务中。全局事务要求在其中所有参与的事务要么都提交，要么都回滚。

* XA事务有一个或多个资源管理器（Resource Managers）、一个事务管理器（Transaction Manager）以及一个应用程序（Application Program）组成

  * 资源管理器：提供访问资源的方法。通常一个数据库就是一个资源管理器
  * 事务管理器：协调参与全局事务的各个事务。需要和参与全局事务的所有资源管理器进行通信。
  * 应用程序：定义事务的边界，指定全局事务中的操作。

* 分布式事务使用两阶段提交（two-phase commit）:

  * 第一阶段：所有参与全局事务的节点都开始准备（PREPARE），告诉事务管理器它们准备好提交了。
  * 第二阶段：事务管理器告诉资源管理器执行ROLLBACK还是COMMIT。如果任何一个节点显示不能提交，则所有的节点都被告知需要回滚

* MySQL XA事务语法：

  ```mysql
  XA {START|BEGIN} xid [JOIN|RESUME]
  XA END xid [SUSPEND [FOR MIGRATE]]
  XA PREPARE xid
  XA COMMIT xid [ONE PHASE]
  XA ROLLBACK xid
  XA RECOVER
  ```

7.7.2 内部XA事务

* 之前讨论的分布式事务是外部事务，即资源管理器是MySQL数据库本身。
* 内部XA事务：其在存储引擎与插件之间，又或者在存储引擎与存储引擎之间。
* 最常见的内部XA事务存在于binlog与InnoDB存储引擎之间（补图）

---

7.8 不好的事务习惯

* 在循环中提交
* 使用自动提交
* 使用自动回滚

---

7.9 长事务

* 长事务（Long-Lived Transactions）就是执行时间较长的事务。
* 解决：
  * 转化为小批量（mini batch）的事务来进行处理

---

8 备份与恢复

8.1 概述

* 按据备份方法：
  * Hot Backup（热备）：数据库运行中直接备份，对正在运行的数据库操作没有任何影响
  * Cold Backup（冷备）：数据库停止的情况下备份
  * Warm Backup（温备）：数据库运行中备份，但是会对当前数据库的操作有所影响
* 按备份后文件的内容：
  * 逻辑备份：备份的文件内容是可读的，一般是文本内容。时间长
  * 裸文件备份：复制数据库的物理文件。时间较短
* 按备份数据库的内容“
  * 完全备份：对数据库进行一个完整的备份
  * 增量备份：在上次完全备份的基础上，对于更新的数据进行备份
  * 日志备份：对MySQL数据库binlog德尔备份。

8.2 冷备

* 对于InnoDB存储引擎的冷备非常简单，只需要备份MySQL数据库的frm文件，共享表空间文件，独立表空间文件（*.ibd），重做日志文件。
* 冷备的优点：
  * 备份简单，只要复制相关文件即可。
  * 备份文件易于在不同操作系统，不同MySQL版本下进行恢复
  * 恢复相当简单，只需要把文件恢复到指定位置即可。
  * 恢复速度快，不需要执行任何SQL语句，也不需要重建索引。
* 冷备的缺点：
  * InnoDB存储引擎冷备的文件通常比逻辑文件大很多，因为表空间中存放着很多其他的数据，如undo端，插入缓冲等信息。
  * 冷备也不总是可以轻易地跨平台。操作系统、MySQL版本、文件大小写敏感和浮点数格式都会成为问题

8.3 逻辑备份

8.3.1 mysqldump

* 通常用来完成转存（dump）数据库的备份及不同数据库之间的移植

* 语法：

  ```shell
  mysqldump [arguments] >file_name

  # 如果要备份所有的数据库
  mysqldump --all-database >dump.sql

  # 如果要备份指定的数据库
  mysqldump --database db1 db2 db3 >dump.sql
  ```

* 重要参数：

  * --single-transaction：在备份开始前，先执行START TRANSACTION命令。只对InnoDB有效
  * --lock-tables(-l)：在备份中，依次锁住每个架构下的所有表。和--single-transaction互斥
  * --lock-all-tables：在备份中，对所有架构中的所有表上锁
  * --all-drop-database ：在CREATE DATABASE前先运行DROP DATABASE
  * --master-data [=value]：通过该参数产生的备份转存文件主要用来建立一个replication
  * —master-data：会自动忽略—lock-tables选项
  * —events（-E）：备份时间调度器
  * —routines（-R）：备份存储过程和函数
  * —triggers：备份触发器
  * —hex-blob：将BINARY、VARBINARY、BLOG和BIT类型备份为十六进制的格式
  * —tab=path（-T path）：缠身TAB分隔的数据文件
  * —where='where_condition'（-w 'where_condition'）：导出给定条件的数据

* 注意：

  * 不能导出视图

8.3.2 SELECT…INTO OUTFILE

* 导出一张表中的数据

```mysql
SELECT [column 1],[column 2]...
INTO
OUTFILE 'file_name'		 #导出的文件，所在路径的权限必须是mysql:mysql
[{FIELDS |COLUMNS}]
[TERMINATED BY 'string']    			 #每个列的分隔符，默认'\t'
[
  [OPTIONALLY] ENCLOSED BY 'char']		 #对于字符串的包含符，默认''
  [ESCAPED BY 'char']				    #转义符，默认'\\'
 ]
 [
   LINES
   [STARTING BY 'string']				#每行的开始符号，默认''
   [TERMINATED BY 'string']				#每行的结束符号，默认'\n'
 ]
 FROM TABLE WHERE ...
```

8.3.3 逻辑备份的恢复

```mysql
mysql -uroot -p<test_backup.sql

source /home/mysql/test_backup.sql
```

8.3.4 LOAD DATA INFILE

```mysql
LOAD DATA INTO TABLE a IGNORE 1 LINES INFILE 'home/mysql/a.txt'
```

8.4 二进制日志备份与恢复

```shell
[mysqld]
log-bin = mysql-bin
sync_binlog = 1
innodb_support_xa = 1
```

* mysqlbinlog [options] log_file...

---

8.5 热备

8.5.1 ibbackup

* 工作原理：
  * 记录备份开始时，InnoDB存储引擎重做日志文件检查点的LSN
  * 复制共享表空间文件以及堵路表空间文件
  * 记录复制完表空间文件后，InnoDB存储引擎重做日志文件检查点的LSN
  * 复制在备份时产生的重做日志
* 优点：
  * 在线备份，不阻塞任何的SQL语句
  * 备份性能好，备份的是指是复制数据库文件和重做日志文件
  * 支持压缩备份
  * 跨平台支持
* 恢复步骤：
  * 恢复表空间文件
  * 应用重做日志文件

8.5.2 XtraBackup

---

8.6 快照备份

* MySQL数据库本身并不支持快照功能，因此快照备份是指通过文件系统支持的快照功能对数据库进行备份

---

8.7 复制

* replication的工作原理：
  * 主服务器（master）把数据更改记录到二进制日志（binlog）中
  * 从服务器（slave）把主服务器的二进制日志复制到自己的中继日志（relay log）中
  * 从服务器重做中级日志中的日志，把更改应用到自己的数据库上，以达到数据的最终一致性
* 复制可以用来作为备份，但功能不仅限于备份，其主要功能如下：
  * 数据分布
  * 读取的负载平衡
  * 数据库备份
  * 高可用性和故障转译

