1. Mysql体系结构和存储引擎
   1. 定义数据库和实例
   2. MySQL体系结构
   3. MySQL存储引擎
2. InnoDB存储引擎
   1. InnoDB体系架构
   2. Checkpoint
   3. Master Thread工作方式
   4. InnoDB关键特性
3. 文件
   1. 参数文件
   2. 日志文件
   3. 套接字文件
   4. pid文件
   5. 表结构定义文件
   6. InnoDB存储引擎文件
4. 表
   1. 索引组织表
   2. InnoDB逻辑存储结构
   3. InnoDB行记录格式
   4. InnoDB数据页结构
   5. Named File Formats机制
   6. 约束
   7. 视图
   8. 分区表
5. 索引与算法
   1. 数据结构与算法
   2. B+树
   3. B+树索引
   4. Cardinality值
   5. B+树索引的使用
   6. 哈希算法
   7. 全文检索
6. 锁
   1. lock与latch
   2. InnoDB存储引擎中的锁
   3. 锁的算法
   4. 锁问题
   5. 阻塞
   6. 死锁
   7. 锁升级
7. 事务
   1. 认识事务
   2. 事务的实现
   3. 事务控制语句
   4. 隐式提交的SQL语句
   5. 对于事务操作的统计
   6. 事务的隔离级别
   7. 分布式事务
   8. 不好的事务习惯
8. 备份与恢复
   1. 冷备
   2. 逻辑备份
   3. 二进制日志的备份与恢复
   4. 热备
   5. 快照备份
   6. 复制
9. 性能调优
10. InnoDB存储引擎源代码编译与调试

---

1. Mysql体系结构和存储引擎

1.1定义数据库和实例

数据库(database)：

* 物理操作系统文件或其他形式文件类型的集合。

实例(instance)：

* 由后台线程以及一个共享内存区组成。
* 数据库实例才是真正用于操作数据库文件的。
* MySQL被设计为单进程多线程架构的数据库，MySQL数据库实例在系统上的表现就是一个进程。

---

1.2 MySQL体系结构

* 连接池组件
* 管理服务与工具组件
* SQL接口组件
* 查询分析器组件
* 优化器组件
* 缓冲组件
* **插件式存储引擎**（基于表的）
* 物理文件

---

1.3 MySQL存储引擎

| 存储引擎      | 特点                                       |
| --------- | ---------------------------------------- |
| InnoDB    | 行锁；支持外键；非锁定读；MVCC；事务（next-key）；高性能高可用（插入缓冲；二次写；自适应哈希；预读）；聚集（6字节ROWID）；idb |
| MyISAM    | 表锁；不支持事务；全文索引；只缓存索引文件；MYD(数据文件)和MYI(索引文件) |
| NDB       | 集群存储引擎；share nothing；数据放在内存中；            |
| Memory    | 表锁；数据放在内存中；哈希索引；不支持TEXT和BLOB，变长字段按定长字段方式；作为临时表存放查询的中间结果集，若超容量，会转换到MyISAM，有查询性能损失 |
| Archive   | 行锁；不是事务安全；只支持INSERT和SELECT；zlib算法按行压缩，压缩比可达1:10；适合存储归档数据 |
| Federated | 不存放数据，指向一台远程MySQL服务器上的                   |
| Maria     | 用于取代原有的MyISAM；支持缓存数据和索引文件；行锁；MVCC        |
| 其他        | Merge、CSV、Sphinx、Infobright              |

---

1.4 连接MySQL

* 连接MySQL操作是一个连接进程和MySQL书数据库实例进行通信，本质上是进程通信
* TCP/IP
* 命名管道和共享内存：--enable-named-pipe   —shared-memory
* UNIX域套接字

---

2. InnoDB存储引擎

2.1 InnoDB存储引擎版本

| 版本                          | MySQL版本 | 功能                     |
| --------------------------- | ------- | ---------------------- |
| 老版本InnoDB(静态编译)             | 5.1     | 支持ACID、行锁、MVCC         |
| InnoDB 1.0.x(InnoDB Plugin) | 5.1     | 增加了compress和dynamic页格式 |
| InnoDB 1.1.x                | 5.5     | 增加了linux AIO、多段回滚      |
| InnoDB 1.2.x                | 5.6     | 增加了全文索引支持、在线索引添加       |

---

2.2 InnoDB体系架构（补图）

后台线程

* 负责刷新内存池中的数据，保证缓冲池中的内存缓存的是最新的数据。
* 将已修改的数据文件刷新到磁盘文件。
* 保证在数据库发生异常的情况下InnoDB能恢复到正常运行状态。

内存池

* InnoDB存储引擎是基于磁盘存储的，并将其中的记录按照页的方式进行管理。


* 维护所有进程/线程需要访问的多个内部数据结构。
* 缓存磁盘上的数据，方便快速地读取，同时在对磁盘文件的数据修改之前在这里缓存。
* 重做日志(redo log)缓冲。

缓冲池缓存的数据页类型

* 索引页（data page）
* 数据页（index page）
* 插入缓冲（insert buffer）
* 自适应哈希索引（adaptive hash index）
* InnoDB存储的锁信息（lock info）
* 数据字典信息（data dictionary）
* undo页

缓冲池管理

* LRU：
  * LRU列表用来管理已经读取的页。
  * midpoint(默认为5/8处)，midponit之后的列表称为old列表，之前的列表称为new列表。新读取到的页并不是直接放入到LRU列表的首部，而是放到LRU列表的midpoint位置。innodb_old_blocks_pct；innodb_old_blocks_time
  * 当LRU列表的old部分加入到new部分时，称为page made young；当因为innodb_old_blocks_time的设置而导致页没有从old部分加入到new部分时，称为page not made young；
* Free List
  * 当数据库刚启动时，LRU列表是空的，这时页都存放在Free列表中。当需要从缓冲池中分页时，首先从Free列表中查找是否有可用的空闲页，若有则将该页从Free列表删除，放入LRU列表中；若无，则太太LRU列表末尾的页，分配给新的页。
* Flush List
  * LRU列表页中的页被修改后，称该页为脏页(dirty page)
  * 脏页既存在于LRU列表中，也存在于Flush列表中。LRU列表用来管理缓冲池中页的可用性，Flush列表用来管理将页刷新回磁盘，二者互不影响。

| 后台线程                | 功能                                       | 相关参数                                     |
| ------------------- | ---------------------------------------- | ---------------------------------------- |
| Master Thread       | 缓冲池中的数据异步刷新到磁盘，保证数据的一致性：包括脏页的刷新、合并插入缓冲、UNDO页的回收等 |                                          |
| IO Thread           | 负责AIO请求的回调处理。insert buffer、log、write(4个)、read(4个) | innodb_reaad_io_threads；innodb_write_io_threads |
| Purge Thread        | 负责回收已经使用并分配的undo页。                       | innodb_purge_thread；                     |
| Page Cleaner Thread | 负责脏页的刷新                                  | innodb_lru_scan_depth；                   |

| 内存池    | 功能                                       | 相关参数                                     |
| ------ | ---------------------------------------- | ---------------------------------------- |
| 缓冲池    | 1）读取：首先判断该页是否在缓冲池中，若存在，则命中；否则，将磁盘读到的页存在缓冲池中。这个过程称为将页“FIX”在缓冲池中；2）修改：首先修改在缓冲池中的页，然后通过Checkpoint机制刷新回磁盘；3）页的默认大小是16KB | innodb_buffer_pool_size；innodb_buffer_pool_instances |
| 重做日志缓冲 | 首先将重做日志信息放入到该缓冲区，然后按一定频率将其刷新到重做日志文件。1）Master Thread每一秒会刷新；2）每个事务提交会刷新；3）当重做日志缓冲池剩余空间小于1/2时会刷新 | innodb_log_buffer_size                   |
| 额外的内存池 |                                          |                                          |

---

2.3 Checkpoint

Checkpoint解决以下几个问题：

* 缩短数据库的恢复时间
* 缓冲池不够用时，将脏页刷新到磁盘
* 重做日志不可用时，刷新脏页

LSN（Log Sequence Number）：8字节的数字，单位是字节

* 每个页有LSN
* 重做日志也有LSN
* checkpoint也有LSN

Checkpoint类型

* Sharp Checkopoint：发生在数据库关闭时间所有的脏页都刷新回磁盘；若运行时使用会影响数据库的可用性
* Fuzzy Checkpoint：只刷新一部分脏页
  * Master Thread Checkpoint：每秒或每十秒从缓冲池中刷新一定比例的页回磁盘；异步
  * FLUSH_LRU_LIST Checkpoint：LRU列表要差不多100个空闲页可供使用
  * Async/Sync Flush Checkpoint：重做日志文件不可用的情况，这时需要强制将一些页刷新回磁盘
  * Dirty Page too much Checkpoint

---

2.4 Master Thread工作方式

* 主循环（loop）:

  * 每秒一次的操作：

    1. 日志缓冲刷新到磁盘，即使这个事务还没有提交（总是）；
    2. 合并插入缓冲（可能）；
    3. 至多刷新100个InnoDB的缓冲池中的脏页到磁盘（可能）；
    4. 如果当前没有用户活动，则切换到background loop（可能）；

  * 10秒一次的操作：

    1. 刷新100个脏页到磁盘（可能）；
    2. 合并至多5个插入缓冲（总数）；
    3. 将日志缓冲刷新到磁盘（总是）；
    4. 删除无用的Undo页（总是）；
    5. 刷新100个或者10个脏页大盘磁盘（总是）；
* background loop：若当前没有用户活动或者数据库关闭，就会切换到这个循环
  * 删除无用的Undo页（总是）；
  * 合并20个插入缓冲（总是）；
  * 跳回到主循环（总是）；
  * 不断刷新100个页知道符合条件（可能，跳转到flush loop中完成）


```bash
void master_thread() {
	goto loop;
	
loop:
for( int i=0;i<10;i++ ){
	thread_sleep(1);
	do log buffer flush to disk
	if( last_one_second_ios < 5% innodb_io_capacity )
		do merge at most 5% innodb_io_capacity insert buffer
    if( buf_get_modified_ratio_pct > innodb_max_dirty_pages_pct )
    	do buffer pool flush 100% innodb_io_capacity dirty page
    else if enable adaptive flush
    	do buffer pool flush desired amount dirty page
    if( no user activity )
    	goto background loop
}
if( last_ten_seconds_ios < innodb_io_capacity )
	do buffer pool flush 100% innodb_io_capacity dirty page
do merge at most 5% innodb_io_capacity insert buffer
do log buffer flush to disk
do full purge
if( buf_get_modified_ratio_pct > 70% )
    do buffer pool flush 100% innodb_io_capacity dirty page
else
	do buffer pool flush 10% innodb_io_capacity dirty page
goto loop

background loop:
do full purge
do merge 100% innodb_io_capacity insert buffer
if not idle
	gote loop
else
	goto flush loop
	
flush loop:
do buffer pool flush 100% innodb_io_capacity dirty page
if( buf_get_modified_ratio_pct > innodb_msx_dirty_pages_pct )
	goto flush loop
goto suspend loop

suspend loop:
suspend_thread()
waiting event
goto loop;
}
```

---

2.5 InnoDB关键特性

2.5.1 插入缓冲（Insert Buffer）

* 对于非聚集索引的插入或更新操作，不是每一次直接插入到索引页中，而是先判断插入的非聚集索引页是否在缓冲池中，若在，则直接插入；若不在，则先放入到一个Insert Buffer对象中，然后以一定频率和情况进行Insert Buffer 和辅助索引叶子节点的merge操作，这时通常能将多个插入合并到一个操作中（因为在一个索引页中），这就答答题高了对于非聚集索引插入的性能

* Insert Buffer的使用需要同时满足两个条件：

  * 索引是辅助索引（secondary index）
  * 索引不是唯一（unique）的

* 数据结构：B+树，全局唯一

  * 非叶节点：存放的是查询的search key，一共占用9个字节。space(4字节)表示待插入记录所在表的表空间id；marker(1字节)兼容老版本的Insert Buffer；offset(4字节)表示表所在的偏移量。当一个辅助索引要插入到页（space, offset）时，如果这个页不在缓冲池中，那么InnoDB存储引擎首先构造一个search key，接下来查询Insert Buffer这棵B+树，然后再将记录插入到叶子节点中。
  * 叶子节点：space、marker、page_no、metadata(4字节)、辅助索引记录

* Insert Buffer Bitmap：用来标记每个辅助索引页（space, page_no ）的可用空间的特殊页

  * 每个Insert Buffer Bitmap页用来追踪16384个辅助索引页，并都在16384个页的第二页中。
  * 每个辅助索引页在Insert Buffer Bitmap页中占用4bit
    * IBUF_BITMAP_FREE(2bit)：表示该辅助索引页中的可用空间数量，0(无)、1(>1/32)、2(>1/16)、3(>1/8)
    * IBUF_BITMAP_BUFFERED(1bit)：1表示该辅助索引页有记录被缓存在Insert Buffer B+树中
    * IBUF_BITMAP_IBUF(1bit)：1表示该页为Insert Buffer B+树的索引页

* Merge Insert buffer

  Merge Insert buffer的操作可能发生在以下几种情况下：

  * 辅助索引页被读取到缓冲池时：先检查Insert Buffer Bitmap页，确认该辅助索引页是否有记录存放在Insert Buffer B+树中，若有，则将B+树中该页的记录插入到该辅助索引页中。
  * Insert Buffer Bitmap页追踪到该辅助索引页已无可用空间时：若插入辅助索引记录时检测到插入记录后可用空间会小于1/32页，则会强制进行一个合并操作，即强制读取辅助索引页，将Insert Buffer B+树中该页的记录及待插入的记录插入到辅助索引页中。
  * Master Thread：每秒或每10秒进行一次Merge Insert buffer的操作。

2.5.2 两次写（Double Write）

* 重做日志中记录的是对页的物理操作，如偏移量800，写'aaa'记录。如果这个页本身已经发生了损坏，再对其进行重做是没有意义的。
* 在应用重做日志前，用户需要一个页的副本，当写入失效发生时，先通过页的副本来还原该页，再进行重做，这就是doublewrite
* double write由两部分组成：
  * 内存中的doublewrite buffer,大小为2MB
  * 物理磁盘上共享表空间中连续的128个页，大小也为2MB
* 写入过程：
  * 在对缓冲区的脏页进行刷新时，通过memcpy函数将脏页先复制到内存中的doublewrite buffer
  * 通过doublewrite buffer分两次，每次1MB顺序地写入共享表空间的物理磁盘上。（第一次写）（因为doublewrite页是连续的，因此这个过程是顺序写的，开销并不是很大）
  * 马上调用fsync函数，同步磁盘
  * 在完成doublewrite页的写入后，再将doublewrite buffer中的页写入到各个表空间文件中，此时写入时离散的。（第二次写）
* 恢复过程：
  * 如果操作系统在将页写入磁盘的过程中发生了崩溃，在恢复过程中，从共享表空间中的doublewrite中找到该页的一个副本，将副本复制到表空间文件，再应用重做日志。

2.5.3 自适应哈希索引（Adaptive Hash Index）

* 哈希在一般情况下查找时间复杂度是O(1)；B+树的查找次数取决于B+树的高度，生产环境中B+树高度一般为3~4层
* InnoDB存储引擎会监控对表上各索引页的查询，如果观察到建立哈希索引能带来速度提升，则建立哈希索引，称之为自适应哈希(AHI)
* AHI通过缓冲池的B+树页构造而来，因此建立速度很快，而且不需要对整张表构建哈希索引。
* InnoDB存储引擎会自动根据访问频率和模式来自动地为某些热点页建立哈希索引。
* AHI要求：
  * 即对这个页的连续访问模式必须是一样的。访问模式一样指的是查询条件一样
  * 以该模式访问了100次
  * 页通过该模式访问了N次，其中N=页中记录*1/16
* AHI只能用来搜索等值的查询

2.5.4 异步IO（Asunc IO）

* 用户可以发出一个IO请求后立即再发出另一个IO请求，当全部IO请求发送完毕后，等待所有IO操作的完成，这就是AIO
* AIO的另一个优势是可以进行IO Merge操作。

2.5.5 刷新临接页（Flush Neighbor Page）

* 当刷新一个脏页时，InnoDB存储引擎会检测该页所在 区的所有页，如果是脏页，那么一起进行刷新。通过AIO可以将多个IO写入操作合并为一个IO操作
* 对传统机械硬盘有优势，固态硬盘可关闭此特性。

---

2.6 启动、关闭和恢复

InnoDB存储引擎的启动和关闭，是指在MySQL实例的启动过程中对 InnoDB存储引擎的处理过程。

| 参数                    | 值                                        |
| --------------------- | ---------------------------------------- |
| innodb_fast_shutdown  | 0:完成full purge、merge insert buffer、所有脏页刷新；1：完成full purge、merge insert buffer；2：将日志写入日志文件，下次启动时会进行 |
| innodb_force_recovery | 0:当发生需要恢复时，进行所有的恢复操作                     |

---

3. 文件

MySQL数据库文件：

* 参数文件
* 日志文件：错误日志、慢查询日志、查询日志、二进制日志
* 套接字文件
* pid文件
* 表结构定义文件

各存储引擎相关的文件：

* InnoDB存储引擎文件

---

3.1 参数文件

告诉MySQL实例启动时在哪里可以找到数据库文件，并且指定某些初始化参数，这些参数定义了某种内存结构的大小等设置。

* MySQL根据配置文件的参数来启动实例。读取顺序为/etc/my.cnf ->/etc/mysql/my.cnf ->/usr/local/mysql/etc/my.cnf ->/.my.cnf 。同一参数以最后读到的为准；若无配置文件，则使用编译的默认值


* 可以通过命令SHOW VARIABLES查看数据库中的所有参数，也可以通过LIKE来过滤参数名。

```mssql
SHOW VARIABLES LIKE 'innodb_buffer%'\G;
```

* 还可以通过**information_schema**架构下的GLOBAL_VARIABLES视图来进行查找。

```mysql
SELECT * FROM GLOBAL_VARIABLES WHERE VARIABLE_NAME LIKE 'innodb_buffer%'\G;
```

* 参数类型：

  * 动态参数（dynamic）：可以在MySQL实例运行中进行更改。可以通过SET命令对动态参数值进行修改。
  * 静态参数（static）：在整个实例生命周期内都不得进行更改。

  ```mysql
  SET | [global | session] system_var_name = expr | [@@global. | @@session.|@@]system_var_name = expr

  SET read_buffer_size=524288; //将当前会话的参数read_buffer_size调整为512KB
  SET @@global.read_buffer_size=1048576; //read_buffer_size全局值更改为1MB(当前会话的还是512KB，并且只在这次的实例生命周期内有效，下次启动时MySQL实例还是会拿读取参数文件)
  ```

---

3.2 日志文件

用来记录MySQL实例对某种条件作出响应时写入的文件，如错误日志、二进制文件、慢查询日志文件、查询日志文件。

3.2.1 错误日志（error log）

* 对MySQL的启动、运行、关闭过程进行了记录。默认名是：主机名.err

```mysql
SHOW VARIABLES LIKE 'log_error'\G;
```


3.2.2 慢查询日志（slow query log）

*  可以在MySQL启动时设一个阈值，将运行时间超过该值的所有SQL语句都记录到慢查询日志文件中

```mysql
SHOW VARIABLES LIKE 'long_query_time'\G;  	#慢查询时间阈值，默认值是10秒
SHOW VARIABLES LIKE 'long_query_io'\G;  	#慢查询逻辑IO次数阈值，默认值是100
SHOW VARIABLES LIKE 'slow_query_type'\G;  	#慢查询类型，0不记录、1根据时间、2根据逻辑IO次数、3根据时间+逻辑IO次数
SHOW VARIABLES LIKE 'log_slow_queries'\G; 	#慢查询开关，默认不开启慢查询日志，需要手动将该参数设为ON
SHOW VARIABLES LIKE 'log_queries_not_using_indexes'\G; #若运行的SQL语句没有使用索引，则会将这条SQL语句记录到慢查询日志文件
SHOW VARIABLES LIKE 'log_throttle_not_using_indexes'\G; #每分钟允许记录到slow log的且未使用索引的SQL语句次数，默认值0，表示无限制
SHOW VARIABLES LIKE 'log_output'\G;  #指定慢查询输出的格式，默认为FILE,可以将它设为TABLE，然后就可以查询mysql架构下的slow_log表了
```

* mysqldumpslow可用于分析slow log

```mysql
mysqldumpslow /opt/tmp/mysql.slow
```

* 慢查询表在mysql架构下，名为slow_log

```mysql
SHOW CREATE TABLE mysql.slow_log\G;
```

3.2.3 查询日志（log）

* 记录了所有对MySQL数据库请求的信息，无论这些请求是否得到了正确的执行，默认名是：主机名.log
* 在mysql架构下，表名为general_log

3.2.4 二进制日志（binlog）

* 二进制日志记录了对MySQL数据库执行更改的所有操作，但是不包括SELECT和SHOW这类操作。
* 二进制日志的作用：
  * 恢复（recovery）：某些数据的恢复需要二进制日志
  * 复制（replication）：其原理与恢复类似，通过复制和执行二进制日志使一台；远程的MySQL数据库（称为slave或standby）与一台MySQL数据库（称为master或primary）进行实时同步
  * 审计（audit）：用户可以通过二进制日志中的信息来进行审计，判断是否有对数据库进行注入的攻击
* 相关参数：
  * **log-bin [=name]**
    * 配置该参数可以启动二进制日志
    * 若不指定**name**则**默认文件名为主机名**，**后缀名为二进制日志的序列号**
    * 所在路**径为数据库所在目录**（datadir）
  * **max_binlog_size**
    * 单个二进制日志文件的最大值，默认1G
    * 如果超过该值，则产生新的二进制日志文件，后缀名+1，并记录到.index文件
  * **binlog_cache_size**
    * 当使用事务的表存储引擎时，所有**未提交**的二进制日志会被记录到一个缓存中去，等该事务**提交**时直接将该缓冲中的二进制日志写入二进制日志文件
    * 该缓冲的大小由该参数决定，默认32K
    * 此外，该参数是基于会话的，当一个线程开始一个事务时，MySQL会自动分配一个大小为binlog_cache_size的缓存，所以不能设置太大
    * 当一个事务的记录大于设定的binlog_cache_size时，MySQL会把缓冲中的日志写入一个**临时文件**中，所以不能设置太小
    * binlog_cache_use记录了使用缓冲写二进制日志的次数
    * binlog_cache_disk_use记录了使用临时文件写二进制日志的次数
  * **sync_binlog **
    * 二进制文件并不是在每次写(缓冲写)的时候同步到磁盘
    * 该参数表示每写缓冲多少次就同步到磁盘。默认值0
    * sync_binlog=1表示采用同步写磁盘的方式来写二进制日志，这时写操作不使用操作系统的缓冲来写二进制文件。
    * innodb_support_xa参数可以确保二进制日志和InnoDB存储引擎数据文件的同步
  * **binlog-do-db/binlog-ignore-db**
    * 要写入和忽略哪些库的日志，默认为空，表示需要同步所有库的日志到二进制日志
  * **log-slave-update**
    * 如果当前数据库是slave角色，则它不会将从master取得并执行的二进制日志写入自己的二进制日志文件中
    * 如果需要写入，则需要设置该参数
  * **binlog_format**：影响记录二进制日志的格式
    * STATEMENT：记录的是日志的逻辑SQL语句，可能出现主从不一致的情况
    * ROW：记录表的行更改情况，会对磁盘空间要求有一定的增加
    * MIXED：默认采用STATEMENT格式，在一些情况下会使用ROW格式
* mysqlbinlog查看二进制日志文件

```mysql
mysqlbinlog -vv --start-position=1065 test.000004
```

---

3.3 套接字文件

当用UNIX域套接字方式进行连接时需要的文件。

```mysql
SHOW VARIABLES LIKE 'socket'\G;
```

---

3.4 pid文件

当MySQL实例启动时，会将自己的进程ID写入一个文件中

```mysql
SHOW VARIABLES LIKE 'pid_file'\G;
```

---

3.5 表结构定义文件

用来存放MySQL表结构定义文件。

* MySQL数据的存储是根据表进行的，每个表都有与之对应的文件，但不论采用何种存储引擎，MySQL都有一个以frm为后缀名的文件，这个文件记录了该表的表结构定义。
* frm用来存放视图的定义。

---

3.6 InnoDB存储引擎文件

每个存储引擎都有自己的文件来保存各种数据，这些存储引擎真正存储了记录和索引等数据。

3.6.1 表空间文件

* InnoDB采用将存储的数据按表空间(tablespace)进行存放的设计，默认配置下会有一个初始大小为10MB，名为**ibdata1**的文件，可通过**innodb_data_file_path**进行设置

* **innodb_data_file_path**

  * 所有基于InnoDB存储引擎的表的数据都会记录到该共享表空间中。
  ```mysql
  innodb_data_file_path = /db/ibdata1:2000M;/dr2/db/ibdata2:2000M:autoextend
  ```

* **innodb_file_per_table**

  * 则用户可以将每个基于InnoDB存储引擎的表产生一个独立表空间。命名规则为：表名.ibd。这些独立的表空间文件仅存储该表的数据、索引和插入缓冲bitmap等信息，其余信息还是存放在默认的表空间中。


---

3.6.2 重做日志文件

* 默认情况下，在InnoDB存储引擎的数据目录下会有两个名为ib_logfile0和ib_logfile1的文件。它们记录了对于InnoDB存储引擎的事务日志。
* 每个InnoDB存储引擎至少有1个重做日志文件组（group）,每个文件组下至少有2个重做日志文件。为了得到更高的可靠性，用户可以设置多个的镜像日志组(mirrored log groups)，将不同的文件组方在不同的磁盘上，以此提高重做日志的高可用性。
* 日志组中放入每个重做日志文件的大小一致，并以循环写入的方式运行
* 重要参数：
  * innodb_log_file_size：指定每个重做日志文件的大小。
  * innodb_log_file_in_group：指定了日志文件组中重做日志文件的数量，默认为2。
  * innodb_mirrored_log_groups：指定了日志镜像文件组的数量，默认为1。
  * innodb_log_group_home_dir：指定了日志文件组所在路径，默认为./，表示数据目录下。
* 和binlog区别：
  * 二进制日志会记录所有与MySQL数据库有关的日志记录，包括各种存储引擎的日志；而InnoDB存储引擎的重做日志只记录有关该存储引擎本身的事务日志。
  * 记录的内容不同：二进制日志文件记录的是关于一个事务的具体操作的内容，即该日志的逻辑日志；而InnoDB存储引擎的重做日志文件记录的是关于每个页（Page）的更改的物理情况。
  * 写入时间不同：二进制日志文件仅在事务提交前进行提交，即只写磁盘一次，不论这时该事务多大；而在事务进行的过程中，却不断有重做日志条目(redo entry)被写入到重做日志文件中。
* 重做日志条目(redo entry)结构：
  * redo_log_type（1字节）：重做日志的类型，51种类型
  * space（4字节）：表空间ID
  * page_no（4字节）：页的偏移量
  * redo_log_body：每个重做日志的数据部分，恢复时需要调用相应的函数进行解析
* 从重做日志缓冲写入磁盘上的重做日志文件条件：
  * 主线程每秒刷新，不论事务是否已经提交
  * 参数innodb_flush_log_at_trx-commit控制，表示在提交操作时，处理重做日志的方式：
    * 0：提交事务时，并不将事务的重做日志写入磁盘上的日志文件，而是等到主线程每秒的刷新
    * 1：表示执行commit时将重做日志缓冲同步写到磁盘，即伴有fsync调用
    * 2：表示将重做日志异步写到磁盘，进写到文件系统缓存中，因此不能完全保证在执行commit时肯定会写入重做日志文件，只是有这个动作发生。

---

4. 表

表是关于特定实体的数据集合

* 索引组织表
* InnoDB逻辑存储结构
* InnoDB行记录格式
* InnoDB数据页结构
* Named File Formats机制
* 约束
* 视图
* 分区表

4.1 索引组织表（index organized table）

* 在InnoDB存储引擎中，表都是根据主键顺序组织存放的，这种存储方式的表称为索引组织表。
* 在InnoDB存储引擎中，每张表都有个主键（Primary Key），如果在创建表时没有显示定义，则按如下方式创建：
  * 首先判断表中是否有非空的唯一索引（Unique NOT NULL）,如果有，则该列即为主键。若有多个非空的唯一索引，选择建表时第一个定义的非空唯一索引为主键
  * 如果不符合上述条件，则InnoDB存储引擎自动创建一个6字节大小的指针。

---

4.2 InnoDB逻辑存储结构（补图）

* 所有数据都被逻辑地存放在一个空间中，称之为表空间(tablespace)。
* 表空间又由段（segment）、区（extend）、页（page）/或称为块（block）组成。

4.2.1 表空间

* InnoDB存储引擎逻辑结构的最高层，所有的数据都存放在表空间中。
* 每张表的表空间存放的只是数据、索引和插入缓冲bitmap；其他类的数据，如回滚(undo)信息，插入缓冲索引页、系统事务信息、二次写缓冲等还是存放在共享表空间内。

4.2.2 段

* 表空间由各个段组成的，常见的段有数据段、索引段、回滚段等
* InnoDB存储引擎表是索引组织的(index organized)，因此数据即索引，索引即数据
* 数据段即为B+树的叶子节点；索引段即为B+树的非叶子节点

4.2.3 区

* 区是由连续页组成的空间，在任何情况下每个区的大小都是1MB。页的默认大小是16KB，即一个区中一共与64个连续的页。
* 创建的表默认大小是96KB，这是因为每个段开始时，先用32个页大小的碎片页（fragment page）来存放数据，在使用完这些页之后才是64个连续页的申请

4.2.4 页

* 页是InnoDB磁盘管理的最小单位，每个页的默认大小是16KB，可以通过innodb_page_size设置。
* 页类型：
  * 数据页（B-tree Node）
  * undo页（Undo log Page）
  * 系统页（System Page）
  * 事务数据页（Transaction system Page）
  * 插入缓冲位图页（Insert Buffer Bitmap）
  * 插入缓冲空闲列表页（Insert Buffer Free List）
  * 未压缩的二进制大对象页（Uncompressed BLOB Page）
  * 压缩的二进制大对象页（Compressed BLOB Page）

4.2.5 行

* InnoDB存储引擎是面向列（row-oriented， infobright是column-oriented）的，也就是数据是按行进行存放的。
* 每个页存放的行记录也是有硬性规定的，最多允许存放16KB/2-200行的记录

---

4.3 InnoDB行记录格式

4.3.1  Compact行记录格式

| 变长字段长度列表 | NULL标志位 | 记录头信息 | 主键列  | 隐藏列  | 列1数据 | 列2数据 | …... |
| -------- | ------- | ----- | ---- | ---- | ---- | ---- | ---- |
|          |         |       |      |      |      |      |      |

* 变长字段长度列表（1字节或2字节* 非NULL的VARCHAR字段数）

  * 按列的顺序逆序放置
  * 列的长度小于255字节，用1字节表示；大于255字节，用2字节表示（因此varchar的最大长度限制是65535字节，实际上还有别的开销，能存放VARCHAR类型的最大长度为65532字节）
  * 为NULL值，不记录长度，用NULL标志位标识

* NULL标志位

  * 指示该行数据是否有NULL值，有则用1表示；最右边的位代表第一列，一次类推

* 记录头信息（5字节）

  | 名称              | 大小（bit） | 描述                                       |
  | --------------- | ------- | ---------------------------------------- |
  | ()              | 1       | 未知                                       |
  | ()              | 1       | 未知                                       |
  | deleted_flag    | 1       | 该行是否已被删除                                 |
  | min_rec_flag    | 1       | 为1，如果该记录是预先被定义为最小的记录                     |
  | n_owned         | 4       | 该（slot槽）记录拥有的记录数                         |
  | heap_no         | 13      | 索引堆中该条记录的索引号                             |
  | **record_type** | 3       | 记录类型，000表示普通，001表示B+树节点指针，010表示Infimun，011表示Supremun，1xx表示保留 |
  | next_record     | 16      | 页中下一条记录的偏移量，即当前行记录内容的位置加上偏移量就是下条记录（内容）的初始位置 |
  | Total           | 40      |                                          |

* 每个列的实际数据

  * NULL不占该部分任何空间，即NULL除了占有NULL标志位，实际存储不占有任何空间
  * 每行数据除了用户定义的列外，还有2个隐藏列，事务ID（TransactionID，6字节 ）和回滚指针列（Roll Pointer，7字节）；若表没有定义主键，每行还会增加一个的RowID列（6字节）
  * 固定长度CHAR字段在未能完全占用其长度空间时，会用0x20来进行填充

* 例子（补图）

---

4.3.1 Redundant行记录格式

| 字段长度偏移列表 | 记录头信息 | 主键列  | 隐藏列  | 列1数据 | 列2数据 | …….  |
| -------- | ----- | ---- | ---- | ---- | ---- | ---- |
|          |       |      |      |      |      |      |

* 字段长度偏移列表

  * 按照列的顺序逆序放置
  * 列的长度小于255字节，用1字节表示；大于255字节，用2字节表示

* 记录头信息（6字节）

  | 名称                  | 大小（bit） | 描述                      |
  | ------------------- | ------- | ----------------------- |
  | ()                  | 1       | 未知                      |
  | ()                  | 1       | 未知                      |
  | deleted_flag        | 1       | 该行是否已被删除                |
  | min_rec_flag        | 1       | 为1，如果该记录是预先被定义为最小的记录    |
  | n_owned             | 4       | 该（slot槽）记录拥有的记录数        |
  | heap_no             | 13      | 索引堆中该条记录的索引号            |
  | **n_fields**        | 10      | 记录中列的数量，因此一行支持最多的列为1023 |
  | **1byte_offd_flag** | 1       | 偏移列表为1字节还是2字节           |
  | next_record         | 16      | 页中下一条记录的相对位置            |
  | Total               | 48      |                         |

* 每个列的实际数据

  * VARCHAR的NULL值不占用任何存储空间，而CHAR的NULL值需要占用空间
  * CHAR类型将会占用可能存放的最大值字节数

---

4.3.3 行溢出数据

* InnoDB存储引擎可以将一条记录中的某些数据存储在真正的数据页面之外。BLOB可以不将数据放在溢出页面，VARCHAR也有可能被存放在溢出页面
* VARCHAR：
  * InnoDB存储引擎并不支持65535长度的VARCHAR，因为还有别的开销，实际能存放的最大长度是65532字节
  * VARCHAR(N)中的N指的是字符的长度，VARCHAR类型最大支持65535字节
  * 65535长度指所欲VARCHAR列的长度总和
  * InnoDB存储引擎的页为16KB，并不能存放65532字节。因此，一般情况下，InnoDB存储引擎的数据都是存放在页类型为B-tree node中，当发生行溢出时，数据存放在也类型为Uncompress BLOB页中。数据页只保存768字节的前缀
  * InnoDB存储引擎表是索引组织的，即B+树的结构，这样每个页至少应该有2条行记录，因此，如果页中只能存放下一条记录，那么InnoDB存储引擎会自动将行数据存放到溢出页中
  * 实际阈值是8098，不超过这个阈值的VARCHAR会存放在数据页中
* BLOB/TEXT：
  * 是放在数据页中还是BLOB页中，和前面讨论的VARCHAR一样，至少保证一个也能存放两条记录

---

4.3.4 Compressed和Dynamic行记录格式

* Antelope

  * Compact
  * Redundant

* Barracuda

  * Compressed
  * Dynamic

  新的两种格式对于存放在BLOB中的数据采用了完全的行溢出的方式，数据页中只存放20个字节的指针，实际的数据都存放在Off Page中；而之前的两种格式会存放768个前缀字节。

  Compressed行记录格式的另一个功能是存储在其中的行数据会以zlib的算法进行压缩

---

4.3.5 CHAR的行结构存储

* CHAR(N)中的N指的是字符的长度，而不是字节的长度，也就是说在不同的字符集下，CHAR类型列内部存储的可能不是定长的数据
* 因此对于**多字节字符编码**的CHAR数据类型的存储，InnoDB存储引擎在内部将其视为变长字符类型，这也意味着在变长长度列表中会记录CHAR数据类型的长度。
* 因此可以认为在多字节字符集的情况下，CHAR和VARCHAR的实际行存储基本是没有区别的。

---

4.4 InnoDB数据页结构（补图）

页类型为B-tree Node的页存放的即是表中行的实际数据了。InnoDB数据页由以下7个部分组成：

* File Header（文件头）：38字节
* Page Header（页头）：56字节
* Infimum 和 Supremum Records：13+13字节（Compact格式）
* User Records（用户记录，即行记录）
* Free Space（空闲空间）
* Page Directory（页目录）
* File Trailer（文件结尾信息）：8字节

4.4.1 File Header

* File Header用来记录页的一些头信息，由8个部分组成，共占用38字节

  | 名称                              | 大小（字节） | 说明                                       |
  | ------------------------------- | ------ | ---------------------------------------- |
  | FIL_PAGE_SPACE_OR_CHKSUM        | 4      | 页的checksum值                              |
  | FIL_PAGE_OFFSET                 | 4      | 表空间页的偏移量。如某独立表空间a.ibd的大小为1GB，如果页的大小为16KB，那么总共有65536个页。FIL_PAGE_OFFSET表示该页在所有页中的位置。若此表空间的ID为10，那么搜索页（10,1）就表示查找表a中的第二个页 |
  | FIL_PAGE_PREV                   | 4      | 当前页的上一个页，B+树特性决定了叶子节点必须是双向列表             |
  | FIL_PAGE_NEXT                   | 4      | 当前页的下一个页，B+树特性决定了叶子节点必须是双向列表             |
  | FIL_PAGE_LSN                    | 8      | 该页最后被修改的日志序列位置LSN（Log Sequence Number）   |
  | FIL_PAGE_TYPE                   | 2      | 页类型，0x45BF代表存放的是数据页                      |
  | FIL_PAGE_FILE_FLUSH_LSN         | 8      | 仅在系统表空间的一个页中定义，代表文件至少被更新到了该LSN值；对于独立表空间，该值都为0 |
  | FIL_PAGE_ARCH_LOG_NO_OR_APCE_ID | 4      | 页属于哪个表空间                                 |


* InnoDB存储引擎中页的类型

  | 名称                      | 十六进制   | 解释                |
  | ----------------------- | ------ | ----------------- |
  | FIL_PAGE_INDEX          | 0x45BF | B+树叶节点            |
  | FIL_PAGE_UNDO_LOG       | 0x0002 | Undo Log页         |
  | FIL_PAGE_INODE          | 0x0003 | 索引节点              |
  | FIL_PAGE_IBUF_FREE_LIST | 0x0004 | Insert Buffer空闲列表 |
  | FIL_PAGE_TYPE_ALLOCATED | 0x0000 | 该页为最新分配           |
  | FIL_PAGE_IBUF_BITMAP    | 0x0005 | Insert Buffer位图   |
  | FIL_PAGE_TYPE_SYS       | 0x0006 | 系统页               |
  | FIL_PAGE_TYPE_TRX_SYS   | 0x0007 | 事务系统数据            |
  | FIL_PAGE_TYPE_FSP_HDR   | 0x0008 | File Space Header |
  | FIL_PAGE_TYPE_XDES      | 0x0009 | 扩展描述页             |
  | FIL_PAGE_TYPE_BLOB      | 0x000A | BLOB页             |

* 通过Recorder Header的最后两个字节记录的下一记录的偏移量就可以得到该页中的所有行记录；通过Page Header的PAGE_PREV和PAEG_NEXT就可以知道上个页和下个页的位置，这样InnoDB存储引擎就能读到整张表所有的行记录数据

---

4.4.2 Page Header

* 该部分用来记录数据页的状态信息，由14个部分组成，共占用56字节：

  | 名称                | 大小（字节） | 说明                                       |
  | ----------------- | ------ | ---------------------------------------- |
  | PAGE_N_DIR_SLOTS  | 2      | 在Page Directory中的Slot数                   |
  | PAGE_HEAP_TOP     | 2      | 空闲空间开始位置的偏移量                             |
  | PAGE_N_HEAP       | 2      | 堆中的记录数。第15位表示行记录格式；初始值为2，表示已有Infrimun和Supremun的伪记录行 |
  | PAGE_FREE         | 2      | 指向可重用空间的首指针                              |
  | PAGE_GARBAGE      | 2      | 已删除记录的字节数，即行记录结构中delete flag为1的记录大小的总数   |
  | PAGE_LAST_INSERT  | 2      | 最后插入记录（内容）的偏移量                           |
  | PAGE_DIRECTION    | 2      | 最后插入的方向:LEFT/RIGHT/SAMR_REC/SAME_PAGE/NO_DEDIRECTION |
  | PAGE_N_DIRECTION  | 2      | 一个方向连续插入记录的数量                            |
  | PAGE_N_RECS       | 2      | 该页中记录的数量                                 |
  | PAGE_MAX_TRX_ID   | 8      | 修改当前页的最大事务ID，该值仅在Secondary Index中定义      |
  | PAGE_LEVEL        | 2      | 当前页在索引树中的位置，0x00代表叶节点，即叶节点总是在第0层         |
  | PAGE_INDEX_ID     | 8      | 索引ID，表示当前页属于哪个索引                         |
  | PAGE_BTR_SEG_LEAF | 10     | B+树数据页非叶节点所在段的segment header。仅在B+树的Root页定义 |
  | PAGE_BTR_SEG_TOP  | 10     | B+树数据页所在段的segment header。仅在B+树的Root页定义   |

---

4.4.3 Infimum和Supremum Records（补图）

* 在InnoDB存储引擎中，每个数据页都有两个虚拟的行记录，用来限定记录的边界。
* Infimum记录是比该页中任何主键值都要小的值；Supremum指比任何可能大的值还要大的值
* 这两个值在页创建时被建立，并且在任何情况下都被删除
* InnoDB存储引擎中设置伪行只有一个列，且类型是CHAR(8)，内容就是infimum0x00和supremum。Compact格式的话各占用5(header)+8(列内容)=13字节

---

4.4.4 User Record 和 Free Space

* User Record即实际存储行记录内容。InnoDB存储引擎表总是B+树索引组织的
* Free Space指的是空闲空间，是个链表数据结构，在一条记录被删除后，该空间会被加入到空闲链表中

---

4.4.5 Page Directory

* 存放了记录内容的相对位置（存放的是页相对位置），这些记录指针称为Slots(槽)，每个Slot2个字节
* InnoDB中并不是每个记录都拥有 一个槽，InnoDB存储引擎的槽是一个稀疏目录，即一个槽中可能包含多个记录。伪记录Infrinum的n_owned值总是1；Supremun的n_owned的取值范围是[1,8]；其他用户记录的n_owned的取值范围是[4, 8]。当记录被插入或删除时需要对槽进行分裂或平衡的维护操作
* B+数索引本身并不能找到具体的一条记录，只能找到该记录所在的页；把页加载到内存之后，再通过Page Directory进行二叉查找
* 因为 Page Directory是个稀疏目录，二叉查找的结果是一个粗略的结果，必须通过recorder header中的next_record来继续查找相关记录
* Page Directory是逆序存放的，并且槽中的数据都是按照主键顺序存放的

---

4.4.6 File Trailer

* 为了检测页是否已经完整地写入磁盘，InnoDB存储引擎的页中设置了File Trailer部分
* File Trailer只有FIL_PAGE_END_LSN部分，占8字节。前4字节代表该页的checksum值；后4字节和File Header中的FIL_PAGE_LSN相同。将这两个值与File Header中的FIL_PAGE_SPACE_OR_CHKSUM和FIL_PAGE_LSN值进行比较，以此来保证页的完整性

---

4.5 Named File Formats机制

* InnoDB存储引擎通过Named File Formats机制来解决不同版本下页架构兼容性的问题。
* 参数innodb_file_format用来指定文件格式；innodb_file_format_check用来简写当前InnoDB存储引擎文件格式的支持度，若出现不支持的文件格式，能在错误日志中看到错误

---

4.6 约束

4.6.1 数据完整性

* 关系型数据库系统和文件系统的一个不同点是，关系数据库本身能保证存储数据的完整性。当前几乎所有的关系型数据库都提供了约束（Constraint）机制，该机制提供了一条强大而简易的途径来保证数据库中数据的完整性
* 数据完整性形式
  * 实体完整性：保证表中有一个主键。途径：
    * Primary Key 约束
    * Unique Key 约束
    * 编写触发器
  * 域完整性：保证数据每列的值满足特定的条件。途径：
    * 选择合适的数据类型确保一个数据值满足特定条件
    * 外键（Foreign Key）约束
    * 编写触发器
    * 还可以考虑用DEFAULT约束作为强制域完整性的一个方面
  * 参照完整性：保证两张表之间的关系。途径：
    * 外键约束
    * 编写触发器
* InnoDB提供以下几种约束：
  * Primary Key
  * Unique Key
  * Foreign Key
  * Default
  * NOT NULL

4.6.2 约束的创建和查找

* 约束的创建：
  * 表建立时就进行约束定义
  * 利用ALTER TABLE命令来进行创建约束
  * 对Unique Key的约束，还可以通过命令CREATE UNIQUE INDEX来建立
* 约束名称：
  * Primary Key的默认约束名为PRIMARY
  * Unique Key的默认约束名和列名一样，当然也可以人为指定
  * Foreign Key有一个比较神秘的默认名称

4.6.3 约束和索引的区别

* 创建了一个唯一索引就创建了一个唯一的约束
* 约束更是一个逻辑的概念，用来保证数据的完整性；索引是一个数据结构，既有逻辑上的概念，在数据库中还代表着物理存储的方式。

4.6.4 ENUM和SET约束

* MySQL不支持CHECK约束，可以通过ENUM和SET类型来解决部分这样的约束需求
* 只限于离散值的约束，连续值的范围约束需要通过触发器来实现

4.6.5 触发器与约束

* 触发器的作用是在执行INSERT、DELETE和UPDATE命令之前或之后自动调用SQL命令或存储过程。

```mysql
CREATE 
[DEFINER = { user | CURRENT_USER }] 
TRIGGER trigger_name BEFORE|AFTER INSERT|UPDATE|DELETE
ON tb1_name FOR EACH ROW trigger_stmt
```

* 最多可以为1个表建立6个触发器，即分别为INSERT、UPDATE、DELETE的BEFORE和AFTER各定义一个。
* 通过触发器，用户可以实现MySQL数据库本身并不支持的一些特性，如传统的CHECK约束、物化视图、高级复制、审计等特性。

4.6.6 外键约束

```mysql
[CONSTRAINT [symbol]] FOREIGN KEY
[index_name] (index_col_name,...)
REFERENCES tb1_name(index_col_name,...)
[ON DELETE reference_option]   # 表示对父表进行DELETE操作时，对子表所做的操作
[ON UPDATE reference_option]

reference_option: 
CASCADE    #当父表发生DELETE或UPDATE操作时，对相应的子表中的数据也进行DELETE或UPDATE操作
SET NULL   #当父表发生DELETE或UPDATE操作时，相应的子表中的数据被更新为NULL值
NO ACTION  #当父表发生DELETE或UPDATE操作时，抛出错误，不允许这类操作发生
RESTRICT   #当父表发生DELETE或UPDATE操作时，抛出错误，不允许这类操作发生。没设置时是默认值
```

* 延时检查：即检查在SQL语句运行完成后再进行

* 即时检查：目前MySQL数据库的外键约束都是即时检查，因此NO ACTION和RESTRICT功能相同。即使检查会导致数据的导入操作花费大量时间，可以在导入过程中忽视外键的检查：

  ```mysql
  SET foreign_key_checks = 0;
  LOAD DATA ...
  SET foreign_key_checks = 1;
  ```

* InnoDB存储引擎在外键建立时会自动对该列加一个索引

---

4.7 视图

* 在MySQL数据库中，视图（View）是一个命名的虚表，它由一个SQL查询来定义，可以当做表使用。与持久表（permanent table）不同的是，视图中的数据没有实际的物理存储

* 视图虽然是基于基表（base table）的一个虚拟表，但是用户可以对某些视图进行更新操作，其本质就是通过视图的定义来更新基本表的。

  ```mysql
  CREATE 
  [OR REPLACE]
  [ALGORITHM = { UNDEFINED | MERGE |TEMPTABLE}]
  [DEFINER = { user | CURRENT_USER}]
  [SQL SECURITY { DEFINER | INVOKER }]
  VIEW view_name [{column_list}]
  AS select_statement
  [WITH [CASCADE | LOCAL] CHECK OPTION] #针对可更新视图的，即更新的值是否需要检查
  ```

4.7.1 物化视图

* **物化视图**不是基于基表的虚表，而是根据基表实际存在的实表，即物化视图的数据存储在非易失的存储设备上。物化视图可以用于预先计算并保存多表的链接（JOIN）和聚集（GROUP BY）等耗时较多的SQL操作结果。
* **查询重写**是指当对物化视图 基表进行查询时，数据库会自动判断能否通过查询物化视图来直接得到最终结果
* **物化视图的刷新**是指当基表发生了DML操作后，物化视图何时采用哪种方式和基表进行同步。
  * 刷新模式有：
    * ON DEMAND：物化视图在用户需要时的时候进行刷新
    * ON COMMIT：物化视图在对基表的DML操作提交的同时进行刷新
  * 刷新方法：
    * FAST：采用增量刷新，只刷新自上次刷新以后进行的修改
    * COMPLETE：对整个物化视图进行完全的刷新
    * FORCE：数据库在刷新时会去判断是否可以进行快速刷新，如果可以用FAST，否则用COMPLETE
    * NEVER：物化视图不进行任何刷新
* Oracle数据库中，物化视图的创建方式：
  - BUILD IMMEDIATE：在创建物化视图时就生成数据
  - BUILD DEFERRED：在创建物化视图时不生成数据，以后根据需要再生成数据。
* MySQL本身并不支持物化视图，但是可以通过一些机制来实现物化视图
  * 触发器

---

4.8 分区表

* 分区的过程是将一个表或索引分解为多个更小、更可管理的部分。从逻辑上讲，只有一个表或一个索引，但是物理上这个表或索引可能由数是个物理分区组成。

* MySQL支持的分区类型：

  * 水平分区：指将同一个表中不同行的记录分配到不同的物理文件中。
  * 垂直分区：不支持。指将同一个表中不同列的记录分配到不同的物理文件中。

* MySQL的分区是：

  * 局部分区索引：一个分区中既存放了数据又存放了索引。
  * 全局分区索引：不支持。指数据存放在各个分区中，但是所有数据的索引存放在一个对象中。

* 分区参数：

  ```mysql
  SHOW VARIABLES LIKE 'have_partition'\G;
  或
  SHOW PLUGINS\G;
  ```

* MySQL支持的分区类型：

  * RANGE分区：行数据基于属于一个给定连续区间的列值被放入分区。
  * LIST分区：和RANGE分区类似，只是LIST分区面向离散的值。
  * HASH分区：根据用户自定义的表达式的返回值来进行分区，返回值不能使负数。
  * KEY分区：根据MySQL数据库提供的哈希函数来进行分区

* 如果表中存在主键或唯一索引，分区列必须是唯一索引的一个组成部分；如果建表时没有指定主键，唯一索引，可以指定任何一个列未分区列。

---

4.8.1 分区类型

RANGE分区

```mysql
CREATE TABLE t(
id INT
)ENGINE=INNODB
PARTITION BY RANGE(id)(
PARTITION p0 VALUES LESS THAN (10),
PARTITION P1 VALUES LESS THAN (20)
); #会生成t.frm、t.par、t#P#p0.ibd、t#P#p1.ibd

ALTER TABLE t
ADD PARTITION(
PARTITION p0 VALUES LESS THAN  MAXVALUE
); 
```

* 当插入一个不在分区中定义的值时会抛出错误
* 分区修剪（Partion Pruning）：SQL优化器只需搜索相关分区，而不会去搜索所有的分区
* 对于RANGE分区的查询，优化器只能对YEAR()、TO_DAYS()、TO_SECONDS()、UNIX_TIMESTAMP()这类函数进行优化选择


LIST分区

```mysql
CREATE TABLE t(
a INT,
b INT
)ENGINE=INNODB
PARTITION BY LIST(b)(
PARTITION p0 VALUES IN (1,3,5,7,9),
PARTITION P1 VALUES IN (0,2,4,6,8)
); 
```

* 当插入一个不在分区中定义的值时同样会抛出错误
* 用INSERT插入多行数据过程中遇到分区未定义的值时：
  * MyISAM：会将之前的数据都插入，但之后的数据不会插入
  * InnoDB：将其视为一个事务，因此没有任何数据插入

HASH分区

```mysql
CREATE TABLE t_hash(
a INT,
b DATETIME
)ENGINE=INNODB
PARTITION BY [LINEAR] HASH(YEAR(b))  #基于要进行哈希分区的列值指定一个列值或表达式(返回一个整数)
PARTITION 4;  #被分区的表将要被分割成的分区数量，默认数量是1
```

* HASH 分区的目的是将数据均匀地分布到预先定义的各个分区中，保证各分区数据数量大致都是一样的。算法：
  * 所在分区 = MOD(expr, mm)
* LINEAR HASH分区：使用一个更复杂的算法来确定新行插入到已经分区的表中的位置。优点在于增加、删除、合并和拆分分区表将变得更加快捷；缺点在于各个分区间数据的分布可能不大均衡，算法：
  * 取大于等于分区数量mm的一下个2的幂值V
  * 所在分区N = expr & (V-1)

KEY分区

* KEY分区和HASH分区相似，不同之处在于KEY分区使用MySQL数据库提供的函数进行分区
* 对于NDB Cluster引擎，使用MD5函数；其他存储引擎，使用内部的哈希函数，这些函数基于与PASSWORD()一样的运算法则。
* 在KEY分区中使用关键字LINEAR和在HASH分区中使用具有同样的效果，分区的编号是通过2的幂算法得到的，而部署通过模数运算。

COLUMNS分区

```mysql
CREATE TABLE t_columns_range(
  a INT,
  b DATETIME
)ENGINE=INNODB
PARTITION BY RANGE COLUMNS(b)(
PARTITION p0 VALUES LESS THAN('2017-01-01'),
PARTITION p1 VALUES LESS THAN('2018-01-01')
);
```

* RANGE、LIST、HASH、KEY这四种分区的条件是：数据必须是整型，如果不是整型，则应该通过函数将其转化为整型
* COLUMNS分区可视为RANGE、LIST分区的一种进化，可以直接使用非整型的数据进行分区，分区根据类型直接比较而得，不需要转化为整型；此外，RANGE COLUMNS分区可以对多个列的值进行分区
* COLUMNS分区支持的数据类型：
  * 所有的整型类型，如INT、SMALLINT、TINYINT、BIGINT。FLOAT和DECIMAL不支持
  * 日期类型，如DATE何DATETIME。其余的日期类型不予支持
  * 字符串类型，如CHAR、VARVAHR、BINARY、VARBINARY。BLOB和TEXT不予支持

---

4.8.2 子分区

```mysql
CREATE TABLE ts(a INT,b DATE)ENGINE=INNODB
PARTITION BY RANGE( YEAR(b) )
SUBPARTITION BY HASH( TO_DAYS(b) )
SUBPARTITIONS 2 (
  PARTITION p0 VALUES LESS THAN (1990),
  PARTITION p1 VALUES LESS THAN (2000),
  PARTITION p2 VALUES LESS THAN MAXVALUE
); 
#表ts先根据b列进行了RANGE分区，然后又进行了一次HASH分区，所以分区数量为(3*2=)6个。会生成:ts.frm、ts.par、ts#P#p0#SP#p0sp0.ibd、ts#P#p0#SP#p0sp1.ibd、ts#P#p1#SP#p1sp0.ibd、ts#P#p1#SP#p1sp1.ibd、ts#P#p2#SP#p2sp0.ibd、ts#P#p2#SP#p2sp1.ibd

CREATE TABLE ts(a INT,b DATE)ENGINE=INNODB
PARTITION BY RANGE( YEAR(b) )
SUBPARTITION BY HASH( TO_DAYS(b) )(
  PARTITION p0 VALUES LESS THAN (1990)(
    SUBPARTITION s0,
    SUBPARTITION s1
  ),
  PARTITION p0 VALUES LESS THAN (1990)(
    SUBPARTITION s2,
    SUBPARTITION s3
  ),
  PARTITION p0 VALUES LESS THAN (1990)(
    SUBPARTITION s4,
    SUBPARTITION s5
  )
); #也可以通过SUBPARTITION语法来显式地指出各个子分区的名字
```

* 子分区（subpartition）是分区的基础上再进行分区，有时也称这种分区为复合分区（composite partition）
* MySQL数据库允许在RANGE和LIST分区上再进行HASH和KEY子分区
* 子分区的建立需要注意：
  * 每个子分区的数量必须相同
  * 要在一个分区表的任何分区上使用SUBPARTITION来明确定义任何子分区，就必须定义所有的子分区
  * 每个SUBPATITION子句必须包含子分区的一个名字
  * 子分区的名字必须是唯一的

---

4.8.3 分区中的NULL值

* MySQL数据库允许对NULL值做分区，总是视NULL值小于任何一个非NULL值：
  * RANGE分区如果插入NULL值，则会让该值放入最左边的分区
  * LIST分区要使用NULL值，则必须显式地指出哪个分区放入NULL值，否则报错
  * HASH和KEY分区的任何分区函数都会将含有NULL值的记录返回0

---

4.8.4 分区和性能

* 数据库的应用分两类：
  * OLTP（在线事务处理）：如Blog、电子商务、网络游戏等
  * OLAP（在线分析处理）：如数据仓库、数据集市等
* 对于OLAP的应用，分区的确可以很好地提高查询的性能，因为OLAP应用大多数查询需要频繁地扫描一张很大的表
* 对于OLTP的应用，通常不可能会获取一张大表10%的数据，大部分都是通过索引返回几条记录即可。而根据B+树索引的原理可知，对于一张大表，一般的B+树需要2~3次的磁盘IO，因此B+树可以很好地完成操作，不需要分区的帮助，并且设计不好的分区会带来严重的性能问题。

---

4.8.5 在表和分区交换数据

```mysql
ALTER TABLE e EXCHANGE PARTITION p0 WITH TABLE e2; #将表e的分区p0中的数据移动到表e2中
```

* ALTER TABLE …EXCHANGE PARTITION语法允许**分区或子分区**的数据与**另一个非分区**的表中的数据进行交换。如果非分区表中的数据为空，那么相当于将分区中的数据移到非分区表中；若分区表中的数据为空，则相当于将外部表中的数据导入到分区表中
* 必选满足下面的条件：
  * 要交换的表需和分区表有着相同的表结构，但是表不能含有分区
  * 在非分区表中的数据必须在交换的分区定义内
  * 被交换的表中不能含有外键，或者其他的表含有对该表的外键引用
  * 用户除了需要ALTER、INSERT、CREATE权限外，还需要DROP权限
* 此外，有两个小的细节需要注意：
  * 使用该语句时，不会触发交换表和被交换表上的触发器
  * AUTO_INCREMENT列将被重置

---

5 索引与算法

* 数据结构与算法
* B+树
* B+树索引
* Cardinality值
* B+树索引的使用
* 哈希算法
* 全文检索

InnoDB存储引擎支持的索引：

* B+树索引：传统意义上的索引，构造类似二叉树，根据键值快速找到数据。
* 全文索引
* 哈希索引：自适应的，会根据表的使用情况自动地为表生成哈希索引，不能人为干预

---

5.1 数据结构与算法

* 二分查找法：将记录按有序化9递增或递减）排列，在查找过程中采用跳跃式方法查找
* 二叉查找树和平衡二叉树（AVL）
  * 二叉查找树：左子树小于根，右子树大于根
  * 平衡二叉树：符合二叉查找树定义，且任何节点的两个子树的盖度最大差为1

---

5.2 B+树（补图）

* B+树由B树和索引顺序访问方法（ISAM）演化而来
* B+树是为磁盘或其他直接存取辅助设备设计的一种平衡查找树。在B+树中：
  * 所有记录节点都是按键值的大小顺序存放在同一层的叶子节点上，由各叶子节点指针进行连接

5.2.1 B+树的插入操作

| Leaf Page满 | Index Page满 | 操作                                       |
| ---------- | ----------- | ---------------------------------------- |
| NO         | NO          | 直接将记录插入到叶子节点                             |
| YES        | NO          | 1）拆分Leaf Page；2）将中间的节点放入到Index Page中；3）小于中间节点的记录放到左边；4）大于或等于中间节点的记录放到右边 |
| YES        | YES         | 1）拆分Leaf Page；2）小于中间节点的记录放到左边；3）大于或等于中间节点的记录放到右边；4）拆分Index Page；5）小于中间节点的记录放到左边；6）大于中间节点的记录放到右边；7）中间节点放入上一层Index Page |

* 为了保持平衡对于新插入的键值可能需要大量的拆分(split)页操作，页的拆分意味着磁盘操作，所以应该在可能的情况下尽量减少页的拆分操作。因此，B+树同样一共了类似于平衡二叉树的旋转（Rotation）功能。
* 旋转发生在Leaf Page已满，但是其左右兄弟节点没有满的情况下，这时B+树会将记录转移到所在页的兄弟节点上

5.2.2 B+树的删除操作

| 叶子节点小于填充因子 | 中间节点小于填充因子 | 操作                                       |
| ---------- | ---------- | ---------------------------------------- |
| NO         | NO         | 直接将记录从叶子节点删除，如果该节点还是Index Page的节点，用该节点的右节点代替 |
| YES        | NO         | 合并叶子节点和它的兄弟节点，同时更新Index Page             |
| YES        | YES        | 1）合并叶子节点和它的兄弟节点；2）更新Index Page；3）合并Index Page和它的兄弟节点 |

* B+树使用填充因子（fill factor）来控制树的删除变化，50%是填充因子可设的最小值。

---

5.3 B+树索引

* B+树索引的本质就是B+树在数据库中的实现，但是B+树索引再数据库中有一个特点就是高扇出性，因此在数据库中，B+树的高度一般都在2~4层

* B+树索引分类：（不同在于叶子节点存放的是否是一整行的信息）

  * 聚集索引（clustered index）
  * 辅助索引（secondary index）


5.3.1 聚集索引（补图）

* InnoDB存储引擎是索引组织表，即表中数据按照主键顺序存放。
* 聚集索引是按照每张表的主键构造一棵B+树，同时叶子节点中存放的即为整张表的行记录数据，也将聚集索引的叶子节点称为数据页。聚集索引的这个特性决定了索引组织表中的数据也是索引的一部分。
* 由于实际的数据页只能按照一颗B+树进行排序，因此每张表只能拥有一个聚集索引。
* 聚集索引B+树：
  * 索引页（即非叶节点）：存放键值及指向数据页的偏移量
  * 数据页（即叶子节点）：存放完整的行记录
* 聚集索引的存储并不是物理上连续的，而是逻辑上连续的，这其中有两点：
  * 页通过双向链表连接，页按照主键的顺序排序
  * 每个页中的记录也是通过双向链表进行维护的，物理存储上可以同样不按照主键存储
* 聚集索引的好处是对于主键的**排序查找**和**范围查找**速度非常快。

5.3.2 辅助索引（补图）

* 辅助索引（也称非聚集索引），叶子节点并不包含行记录的全部数据。叶子节点除了包含索引键值以外，每个叶子节点中的索引行中还包含了一个书签（bookmark）。由于 InnoDB存储引擎表是索引组织表，因此InnoDB存储引擎的辅助索引的书签就是相应行数据的聚集索引键（主键）。
* 辅助索引B+树：
  * 叶子节点：存放索引键值及对应的主键。
* 辅助索引的存在并不影响数据在聚集索引中的组织，因此每张表可以有多个辅助索引。
* 当通过辅助索引来寻找时数据时，InnoDB存储引擎会遍历辅助索引并通过叶级别的指针获得指向主键索引的主键，然后再通过主键索引来找到一个完整的行记录

5.3.3 B+树索引的分裂

* B+树索引页的分裂并不总是从页的中间记录开始，这样可能会导致页空间的浪费（因为插入时顺序的，分裂后的左也可能不会再插入数据）
* InnoDB存储引擎的Page Header中有以下几个部分来保存插入顺序信息，通过这些信息可以决定是向左还是向右进行分裂，同时决定将分裂点记录为哪一个
  * PAGE_LAST_INSERT
  * PAGE_DIRECTION
  * PAGE_N_DIRECTION

---

5.3.4 B+树索引的管理

* 索引管理

  *  ALTER TABLE

    ```mysql
    ALTER TABLE tbl_name 
    ADD {INDEX|KEY} [index_name] [index_type]
    (index_col_name,...) [index_option] ...

    ALTER TABLE tbl_name
    DROP PRIMARY KEY | DROP {INDEX|KEY} index_name
    ```

  * CREATE/DROP INDEX

    ```mysql
    CREATE [UNIQUE] INDEX index_name [index_type]
    ON tbl_name(index_col_namae,...)

    DROP INDEX index_name ON tbl_name
    ```

* 查看索引

  ```mysql
  SHOW INDEX FROM tbl_name;
  ```

  * Table：索引所在的表名。

  * Non_unique：非唯一的索引。

  * Key_name：索引的名字，用户可以通过这个名字来执行DROP INDEX。

  * Seq_in_index：索引中该列的位置。

  * Column_name：索引列的名称。

  * Collation：列以什么方式存储在索引中。可以是A或NULL。B+树索引总是A，即排序的。如果使用了Heap存储引擎，并且建立了Hash索引，这里就会显示NULL了

  * Cardinality：索引中唯一值的数目的估计值，Cardinality/表的行数应尽可能接近1，如果非常小，那么用户需要考虑是否可以删除此索引。Cardinality值非常关键，优化器会根据这个值来判断是否使用这个索引，但是这个值并不是实时更新的，只是一个大概的值，可以使用ANLYZE TABLE 命令。

    ```mysql
    ANALYZE TABLE tbl_name;
    ```

  * Sub_part：是否是列的部分索引。如果索引整个列，则该字段为NULL。

  * Packed：关键字如何被压缩。如果没有被压缩，则为NULL。

  * Null：是否索引的列含有NULL值。

  * Index_type：索引的类型。

  * Comment：注释。

* Fast Index Creation（FIC）

  * MySQL5.5之前，对数据库添加和删除索引这类DDL操作，需要创建临时表-》导入数据-》删除原表-》重命名临时表。
  * 对于辅助索引的创建，InnoDB存储引擎会对创建索引的表加上一个S锁。在创建过程中，不需要重建表。删除辅助索引只需要更新内部视图，并把辅助索引的空间标记为可用，同时删除内部视图中对该表的索引定义
  * 由于FIC在索引的创建过程中对表加上了S锁，因此在创建过程中只能对该表进行读操作，若有大量的事务需要对目标表进行写操作，那么数据库的服务同样不可用。
  * 此外，FIC方式只限定于辅助索引，对于主键的创建和删除同样需要重建一张表。

* Online Scheme Change（OSC）

  * “在线”是指事务的创建过程中，可以有读写事务对表进行操作，这提高了原有MySQL数据库的DDL操作时的并发性。
  * 实现OSC的步骤如下：
    * init：即初始化阶段，会对创建的表做一些验证工作，如检查是否有主键，是否存在触发器或者外键等。
    * createCopyTable：创建和原始表一样的新表。
    * alterCopyTable：对创建的新表进行ALTER TABLE操作，如添加索引或列等。
    * createDeltasTable：创建deltas表，该表的作用为下一步创建的触发器所使用。之后对原表的所有DML操作会被记录到createDeltasTable中。
    * createTriggers：对原表创建INSERT、UPDATE、DELETE操作触发器。触发器操作产生的记录被写入到deltas表。
    * startSnapshorXact：开始OSC操作的事务。
    * selectTableIntoOutfile：将原表中的数据写入到新表，为了减少对原表的锁定时间，这里通过分片(chunked)将数据输出到多个外部文件，然后将外部文件的数据导入到copy表中。分片的大小可以指定，默认为500000。
    * dropNCIndexes：在导入到新表前，删除新表中所有的辅助索引。
    * loadCopyTable：将导出的分片文件导入到新表。
    * replayChanges：将OSC过程中原表DML操作的记录应用到新表中，这些记录被保存在deltas表中。
    * recreateNCIndexes：重新创建辅助索引。
    * replayChanges：再次进行DML日志的回放操作，这些日志是在上述创建辅助索引中新产生的日志。
    * swapTables：将原表和新表交换名字，整个操作需要锁定2张表，不允许新的数据产生，由于改名是一个很快的操作，因此阻塞的时间非常短。
  * 限制：
    * 进行修改的表一定要有主键，表本身不能存在外键和触发器等。
    * 在进行OSC过程中，允许SET sql_bin_log=0，因此所做的操作不会同步到slave服务器，可能导致主从不一致的情况。

* Online DDL

  * 虽然FIC可以让InnoDB存储引擎避免创建临时表，从而提高索引的创建效率。但**索引创建时会阻塞表上的DML操作**，OSC虽然解决的上述的部分问题，但是还是有很大的局限性。

  * MySQL 5.6 开始支持Online DDL，其允许辅助缩影创建的同时，还允许诸如INSERT、UPDATE、DELETE这类的DML操作，这极大地提高了可用性。

  * 可以通过Online DDL方式的操作：

    * 辅助索引的创建和删除
    * 改变自增长值
    * 添加或删除外键约束
    * 列的重命名

  * 通过新的ALTER TABLE语法，用户可以选择索引的创建方式：

    ```mysql
    ALTER TABLE tbl_name
    ADD {INDEX|KEY} [index_name] [index_type]
    (index_col_name,...) [index_option]...
    ALGORITHM [=] {DEFAULT|INPLACE|COPY}
    LOCK [=] {DEFAULT|NONE|SHARE|EXCLUSIVE}
    ```

    * ALGORITHM：指定了创建或删除索引的算法：
      * COPY：按照MySQL 5.1之前的工作模式，即创建临时表的方式
      * INPLACE：不创建临时表
      * DEFAULT：表示根据参数old_alter_table来判断是通过INPLACE还是COPY的算法，默认为INPLACE。
    * LOCK：索引创建或删除时对表添加锁的情况：
      * NONE：对目标表不添加任何的锁，可以进行读写事务，这种模式能获得最大的并发度。
      * SHARE：和FIC类似，对目标表加上S锁，可以并发地读事务，写事务需要等待。
      * EXCLUSIVE：对目标表加上X锁，读写事务都不能进行。
      * DEFAULT：首先会判断当前操作是否可以使用NONE模式，若不能，则判断是否可以使用SHARE模式，最后判断是否可以使用EXCLUSIVE模式

  * InnoDB存储引擎实现Onlien DDL的原理是在执行创建或删除操作的同时，将INSERT、UPDATE、DELETE这类DML操作日志写入到一个缓存中。待完成索引创建后再将重做应用到列表上，以此达到数据的一致性。这个缓存的大小由参数innodb_online_alter_log_max_size控制，默认大小是128MB

---

5.4 Cardinality值

* 对于什么时候添加B+树索引，一般经验是，在访问表中很少一部分时使用B+数索引才有意义。

* 选择性：

  * 低选择性：对于性别、地区、类型等字段，他们的取值范围很小，称为低选择性。
  * 高选择性：如果某个字段的取值范围很广，几乎没有重复，则属于高选择性。此时使用B+数索引是最合适的。

* Cardinality的统计是放在存储引擎层进行的；Cardinality的拥挤是通过**采样（Sample）**的方法来完成的

* InnoDB存储引擎更新Cardinality信息的策略(或)为：

  * 表中1/16的数据已发生过变化
  * stat_modified_counter > 2 000 000 000

* InnoDB存储引擎统计Cardinality的方法为采样。默认InnoDB存储引擎对8个叶子节点进行采样，采样的过程如下：

  * 取得B+树索引中叶子节点的数量，即为A。
  * 随机取得B+树索引中的8个叶子节点。统计每个页不同记录的个数，记为P1，P2，…，P8。
  * 根据采样信息给出Cardinality的预估值：Cardinality=（P1+P2+…_P8）* A / 8

* InnoDB存储引擎重新计算索引的Cardinality的时机为：

  * INSERT和UPDATE操作，且满足更新策略
  * ANALYZE TABLE
  * SHOW TABLES STATUS
  * SHOW INDEX
  * 访问INFORMATION_SCHEMA架构下的表TABLES和STATISTICS时

* 相关参数：

  | 参数                                   | 说明                                       |
  | ------------------------------------ | ---------------------------------------- |
  | innodb_stats_transient_sample_pages  | 每次采样页的数量，默认值：8                           |
  | innodb_stats_method                  | 如何对待索引中出现的NULL值记录，默认值：nulls_equal，表示视为相同；nulls_unequal，表示视为不同；nulls_ignored，表示忽略记录 |
  | innodb_stats_persistent              | 是否将命令ANALYZE TABLE计算得到的Cardinality值存放到磁盘上。默认值：OFF |
  | innodb_stats_on_metadata             | 当通过命令SHOW TABLES STATUS、SHOW INDEX、访问INFORMATION_SCHEMA架构下的表TABLES和STATISTICS时，是否需要重新计算索引的Cardinality值。默认值：OFF |
  | innodb_stats_persistent_sample_pages | 若参数innodb_stats_persistent设置为IN，表示ANALYZE TABLE更新Cardinality值时每次采样页的数量。 |

---

5.5 B+树索引的使用

5.5.1 联合索引（补图）

* 联合索引指对表上的多个列进行索引
* 对联合索引idx_a_b(a，b)，则索引组织先按a列排序，a列值相同再按列b排序…；
* 因为第二个键值已经做了排序（在相同a情况下），在一定情况下可以减少filesort

```mysql
# 会使用联合索引
SELECT ... FROM tbl_name WHERE a=xxx AND b = xxx;
SELECT ... FROM tbl_name WHERE a=xxx;
SELECT ... FROM tbl_name WHERE a=xxx ORDER BY b;
SELECT ... FROM tbl_name WHERE a=xxx AND b = xxx ORDER BY c;

#不会使用联合索引
SELECT ... FROM tbl_name WHERE b=xxx;
SELECT ... FROM tbl_name WHERE a=xxx ORDER BY c;
```

5.5.2 覆盖索引

* InnoDB存储引擎支持覆盖索引（covering index，或称索引覆盖），即从辅助索引中就可以得到查询的记录，而不需要查询聚集索引中的记录。
* 使用覆盖索引的一个好处是辅助索引不包含整行记录的所有信息，故其大小要远小于聚集索引，因此可以减少大量的IO操作。
* 对于InnoDB存储引擎的辅助索引而言，由于其包含了主键信息，因此其叶子节点存放的数据为（primary key1，primary key2，…，key1，key2，...）
* 覆盖索引的另一个好处是对某些统计问题而言的。如果辅助索引就能进行统计的，则使用索引覆盖；在通常情况下，注入（a,b）的联合索引，一般是不可以选择列b中所谓的查询条件，但如果是统计操作，并且是覆盖索引的，则优化器会进行选择。

5.5.3 优化器选择不使用索引的情况

* 在某些情况下，当执行EXPLAIN命令进行SQL语句的分析时，会发现优化器并没有选择索引去查找数据（index scan），而是通过扫描聚集索引，也就是直接进行全表扫描（table scan）来得到数据。这种情况多发生于范围查找、JOIN链接操作等情况下。
* 因此对于不能进行索覆盖的情况，优化器选择辅助索引的情况是，通过辅助索引查找的数据是少量的。这是由当前传统机械硬盘的特性锁决定的。

5.5.4 索引提示

* MySQL数据库支持索引提示（INDEX HINT），显式地告诉优化器使用哪个索引。以下两种情况可能需要用到INDEX HINT：
  * MySQL数据库的优化器错误地选择了某个索引，导致SQL语句运行的很慢。（很少见）
  * 某SQL语句可以选择的索引非常多，这时优化器选择执行计划时间的开销可能会大于SQL语句本身。

```mysql
tbl_name [AS alias] [index_hint_list]

index_hint_list:
index_hint [,index_hint] ...

index_hint:
  USE    {INDEX|KEY} [{FOR {JOIN|ORDER BY|GROUP BY}}] ([index_list])  #可以选择
| IGNORE {INDEX|KEY} [{FOR {JOIN|ORDER BY|GROUP BY}}] ([index_list])  #
| FORCE  {INDEX|KEY} [{FOR {JOIN|ORDER BY|GROUP BY}}] ([index_list])  #强制使用

index_List:
index_name [,index_name] ...
```

5.5.5 Multi-Range Read优化（MRR）

* MRR的目得就是为了减少磁盘的随机访问，并且将随机访问转化为较为顺序的数据访问。MRR可适用于range，ref，eq_ref类型的查询。执行计划里有Using MRR
* MRR的好处：
  * MRR使数据访问变得较为顺序。在查询辅助索引时，首先根据得到的查询结果，按照主键进行排序，并按照主键排序的顺序进行书签查找。
  * 减少缓冲池中页被替换的次数
  * 批量处理对键值的查询操作
* 对于InnoDB和MyISAM存储引擎的范围查询和JOIN查询操作，MRR的工作方式如下：
  * 将查询得到的辅助索引键值存放于一个缓存中，这时缓存中的数据是根据辅助索引键值排序的。
  * 将缓存中的键值根据RowID进行排序。
  * 根据RowID的排序顺序来访问实际的数据文件。
* 此外，MRR还可以将某些范围查询，拆分为键值对，以此来进行批量的数据查询，这样做的好处是可以在拆分过程中，直接过滤一些不符合查询条件的数据。

5.5.6 Index Condition Pushdown优化（ICP）

* 在支持ICP后，MySQL数据库会在取出索引的同时，判断是否可以进行WHERE条件的过滤，也就是将WHERE的部分过滤操作放在了存储引擎层。在某些查询下，可以大大减少上层SQL层对记录的索取（fetch），从而提高数据库的整体性能。
* ICP支持range、ref、eq_ref、ref_or_null类型的查询；当前支持MyISAM和InnoDB存储引擎。执行计划里有Using index condition。
* WHERE可以过滤的条件是该索引可以覆盖到的范围。

---

5.6 哈希算法

5.6.1 哈希表

* 直接寻址表问题：
  * 全域U很大是，存储大小为U的一张表T就有点不实际
  * 如果实际要存储的关键字集合K相对于U来说很小，那么分配给T的大部分空间就要浪费掉
* 哈希表：
  * 函数h将关键字域U映射到哈希表T[0..m-1]的槽位上
  * 碰撞（collision）：两个关键字映射到同一个槽上。数据库中医版采用链接法（chaining）解决碰撞
  * 哈希函数：应该能很好地进行散列，使碰撞最小

5.6.2 InnoDB存储引擎中的哈希算法

* InnoDB存储引擎使用哈希算法来对字典进行查找，其冲突机制采用链表方式，哈希函数采用除法散列方式。
* 对于缓冲池页的哈希表来说，在缓冲池中的Page页都有一个chain指针，它指向相同哈希函数值的页。而对于除法散列，m的取值为略大于2倍缓冲池页数量的质数。
* 怎样将要查找的页转换为自然数呢？关键字K= space_id<<20 + space_id+ offset，然后在通过除法散列到各个槽中去。

5.6.3 自适应哈希索引

* 自适应哈希索引采用之前讨论的哈希表的方式实现。不同的是，这仅是数据库自身创建并使用的，DBA本身不能对其进行干预。
* 自适应哈索引经哈希函数映射到一个哈希表中，因此对于字典类型的查找非常快速；但是对范围查找就无能为力了。哈希索引只能用来索索等值的查询

---

5.7 全文检索（FTS）

* B+树索引可以通过索引字段的前缀进行查找
* 全文检索（Full-Text Search）是将存储于数据库中的整本书或整篇文章的任意内容信息查找出来的技术。

5.7.1 倒排索引

* 全文检索通常使用倒排索引（inverted index）来实现。倒排索引同B+树索引一样，也是一种索引结构。它在辅助表（auxiliary table）中存储了单词与单词自身在一个或多个文档中所在位置之间的映射。这通常利用关联数组实现，其拥有两种表现方式：
  * inverted file index，其表现形式为{单词，单词所在文档的ID}
  * full inverted index，其表现形式为{单词，（单词所在文档的ID，在具体文档中的位置）}

5.7.2 InnoDB全文检索（补图）

```mysql
CREATE FULLTEXT INDEX idx_fts ON tbl_name(col_name);
```

* InnoDB采用full inverted index的方式，在InnoDB存储引擎中，将（DocumentId, Position）视为一个ilist。因此在全文检索的表中，有两个列，一个是word字段，另一个是ilist字段，并且在word字段上设有索引。
* 倒排索引需要将word存放在一张表中，这个表称为Auxiliary Table（辅助表）。在InnoDB存储引擎中，我了提高全文检索的并行性能，共有6张Auxiliary Table，目前每张表根据word的Latin编码进行分区。
* FTS Index Cache(全文检索索引缓存)：Auxiliary Table是持久的表，存放在磁盘上。FTS Index Cache是一个红黑树结构，其根据（word, ilist）进行排序。
* InnoDB存储引擎会批量对Auxiliary Table进行更新：
  * 当对全文检索进行查询时，Auxiliary Table首先会将在FTS Index Cache中对应word字段合并到Auxiliary Table中，然后再进行查询。
  * InnoDB存储引擎总是在事务提交时将分词写入到FTS Index Cache，然后再通过批量更新写入到磁盘；
  * 对于删除操作，其在事务提交时不删除磁盘上的Auxiliary Table中的记录，而只是删除FTS Index Cache中的记录，并将删除记录的FTS Document ID保存在INNODB_FT_DELETED表中。可以使用OPTIMIZE TABLE命令来删除索引：
    * 使用参数innodb_optimize_fulltest_only=1可以只进行删除索引操作
    * 使用参数innodb_ft_num_word_optimize可以限制每次实际删除的分词数量，默认2000
    * 彻底删除的文档ID会记录到表INNODB_FT_BEING_DELETED中
    * 已经删除的文档ID不允许再次插入，否则报错
  * 在数据库关闭时，在FTS Index Cache中的数据会同步到磁盘上的Auxiliary Table中
* FTS Document ID：为了支持全文检索，必须有一个列与word进行映射，在InnoDB中这个列被命名为FTS_DOC_ID，其类sing必须是BIGINT UNSIGNED NOT NULL，并且会自动在该列上加上一个名为FTS_DOC_ID_INDEX的Unique Index
* stopword列表：表示该列表中的word不需要对其进行索引分词操作。存储在INNODB_FT_DAFAULT_STOPWORD表中，默认有36个stopword；可以通过参数innodb_ft_stopword_table来自定义
* InnoDB存储引擎的全文检索限制：
  * 每张表只能有一个全文检索的索引
  * 由多列组合而成的全文检索的索引列必须使用相同的字符集与排序规则
  * 不支持灭有单词界定符（delimiter）的语言，如中文、日语、韩语等

---

5.7.3 全文检索

```mysql
MATCH(col1,col2,...) AGAINST (expr [search_modifier])

search_modifier:
{
  	IN NATURAL LANGUAGE MODE
  | IN NATURAL LANGUAGE MODE WITH QUERY EXPANSION
  | IN BOOLEAN MODE
  | WITH QUERY EXPANSION
}
```

* 在WHERE条件中使用MATCH函数，查询返回的记过是根据相关性(Relevance)进行降序排序的
* 相关性的值是一个非负的浮点数，0表示没有任何的相关性。MySQL其相关性的计算依据以下四个条件：
  * word是否在文档中出现。
  * word在文档中出现的次数。
  * word在索引列中的数量。
  * 多少个文档包含该word。
* 对于InnoDB存储引擎的全文检索，还需要考虑以下因素：
  * 查询word在stopword列中，忽略该字符串的查询
  * 查询的word的字符长度是否在区间[innodb_ft_min_token_size, innodb_ft_max_token_size]内，默认[3, 84]
* Natural Language
  * 默认模式
* Boolean
  * 查询字符串的前后字符会有特殊的含义
  * 操作符：
    * +表示该word必须存在
    * -表示该word必须被排除
    * (no operator)表示该word是可选的，但是如果出现，其相关性会更高
    * @distance 表示查询的多个单词之间的距离是否在distance之内，distance的单位是字节。这种全文检索的查询页称为Proximity Search
    * \>表示出现该单词时增加相关性
    * <表示出现该单词时降低相关性
    * ~表示允许出现该单词，但是出现时相关性为负
    * *表示以该单词开头的单词
    * "表示短语
* Query Expansion
  * MySQL数据库支持全文检索的扩展查询，通常在查询的关键词太短，用户需要implied knowledge（隐含知识）时进行。
  * 该查询分为两个阶段：
    * 第一阶段：根据搜索的单词进行全文索引查询。
    * 第二阶段：根据第一阶段产生的分词再进行一次全文检索的查询。

---

6 锁

* lock与latch
* InnoDB存储引擎中的锁
* 锁的算法
* 锁问题
* 阻塞
* 死锁
* 锁升级

---

6.1 什么是锁

* 锁机制用于管理对共享资源的并发访问，提供数据的完整性和一致性。
* 虽然现在数据库系统做的越来越类似，但是有多少种数据库，就可能存在多少种锁的实现方法
* InnoDB存储引擎提供一致性的非锁定读、行级锁支持；且行级锁没有额外的开销，并可以同时得到并发性和一致性。

---

6.2 lock和latch

* latch一般称为闩(shuan)锁（轻量级的锁），因为其要求锁定的时间必须非常短。若持续的时间长，则应用的性能会非常差。其目得是用来保证**并发线程**操作临界资源的正确性，并且通常没有死锁检测的机制。在InnoDB存储引擎中，latch又可分为：
  * mutex（互斥量）
  * rwlock（读写锁）
* lock的对象是事务，用来锁定数据库中的对象，如表、页、行。并且一般lock的对象在书屋commit或rollback后进行释放。有死锁机制。

|      | lock                                     | latch                           |
| ---- | ---------------------------------------- | ------------------------------- |
| 对象   | 事务                                       | 线程                              |
| 保护   | 数据库内容                                    | 内存数据结构                          |
| 持续时间 | 整个事务过程                                   | 临界资源                            |
| 模式   | 行锁、表锁、意向锁                                | 读写锁、互斥量                         |
| 死锁   | 通过waits-for graph、time out等机制进行死锁检测和处理   | 无死锁检测与处理机制。仅通过应用程序加锁的顺序保证无死锁的情况 |
| 存在于  | Lock Manager的哈希表中                        | 每个数据结构的对象中                      |
| 查看   | SHOW ENGINE INNODB STATUS；INNODB_TRX/INNODB_LOCKS/INNODB_LOCK_WAITS | SHOW ENGINE INNODB MUTEX        |

---

6.3 InnoDB存储引擎的锁

6.3.1 锁的类型

* InnoDB存储引擎实现了如下两种标准的**行级锁**：

  * 共享锁（S Lock），允许事务读一行数据。
  * 排他锁（X Lock），允许事务删除或更新一行数据。

* 锁兼容（Lock Cpmpatible）：如果一个事务T1已经获得了行r的共享锁，呢么另外的事务T2可以立即获得行r的共享锁，这种情况称为锁兼容。需要注意的是，兼容是指对同一记录（row）锁的兼容性情况。

  |      | X    | S    |
  | ---- | ---- | ---- |
  | X    | 不兼容  | 不兼容  |
  | S    | 不兼容  | 兼容   |

* InnoDB存储引擎支持多粒度（granular）锁定，这种锁定允许事务在行级上的锁和表级上的锁同时存在。为了支持不同粒度上进行加锁操作，InnoDB存储引擎支持一种额外的锁方式，称之为意向锁（Intention Lock）。意向锁是将锁定的对象分为多个层次，意向锁以为着事务希望在更细粒度（fine granularity）上进行加锁。（补图）

* InnoDB存储引擎的意向锁即为表级别的锁，因此不会阻塞除权标扫以外的任何请求。设计目得主要是为了在一个事务中揭示下一行将被请求的锁类型，支持两种意向锁：

  * 意向共享锁（IS Lock），事务想要获得一张表中某几行的共享锁
  * 意向排他锁（IX Lock），事务想要获得一张表中某几行的排他锁

  |      | IS   | IX   | S    | X    |
  | ---- | ---- | ---- | ---- | ---- |
  | IS   | 兼容   | 兼容   | 兼容   | 不兼容  |
  | IX   | 兼容   | 兼容   | 兼容   | 不兼容  |
  | S    | 兼容   | 不兼容  | 兼容   | 不兼容  |
  | X    | 不兼容  | 不兼容  | 不兼容  | 不兼容  |

6.3.2 一致性非锁定读（补图）

* 一致性非锁定读（consistent nonlocking read）是指InnoDB存储引擎通过行多版本控制（multi versioning）的方式来读取当前执行时间数据库中行的数据

* 非锁定读不需要等待访问的行上X锁的释放，而是去读取一个快照数据；快照数据是通过undo段来完成的，没有额外的开销；读取快照数据不需要上锁。即读取不会占用和等待表上的锁，这是默认的读取方式

* 一个行记录可能有不止一个快照数据，一般称这种技术为多版本技术，由此带来的并发控制，称之为多版本并发控制（Multi Version Concurrency Control, MVCC）

* 在不同的事务隔离级别下，读取的方式不同，对快照数据的定义不同。在READ COMMITTED和REPEATABLE READ（默认隔离级别）下，InnoDB存储引擎使用非锁定的一致性读。

  |      | READ COMMITED | REPEATABLE READ |
  | ---- | ------------- | --------------- |
  | 读    | 非锁定读          | 非锁定读            |
  | 快照数据 | 被锁定行的最新一份快照数据 | 事务开始时的行数据版本     |
  | 加锁方法 | Record Lock   | Next-Key Lock   |

6.3.3 一致性锁定读

* 可以显式地对数据库读取操作进行加锁操作

```mysql
SELECT ... FOR UPDATE     		#对读取的行记录加了一个X锁
SELECT ... LCOK IN SHARE MODE	#对读取的行记录加了一个S锁

#以上语句必须在事务中，当事务提交了，锁也就释放了
```

6.3.4 自增长与锁

* 在InnoDB存储引擎的内存结构中，对每个含有自增长值的表都有一个自增长计数器（auto-increment counter）。当堆含有自增长计数器的表进行插入操作时，这个计数器会被初始化，执行如下语句来得到计数器的值：

  ```mysql
  SELECT MAX(auto_inc_col) FROM t FOR UPDATE;
  ```

* AUTO-INC Locking：插入操作会依据这个自增长的计数器值+1赋予自增长列。这种锁其实是采用一种特殊的表锁机制。为了提高插入性能，所不是在一个事务完成后才释放，而是在完成对自增长值插入的SQL语句后立即释放。存在问题：

  * 队友有自增长值的列的并发插入性能较差，事务必须等待前一个插入的完成（虽然不用等待事务的完成）
  * 对于INSERT...SELECT的大数据量的插入会影响插入的性能，因为另一个事务的插入会被阻塞。

* 自增长的插入分类：

  | 插入类型               | 说明                                       |
  | ------------------ | ---------------------------------------- |
  | insert-like        | 指所有的插入语句，如INSERT、REPLACE、INSERT...SELECT、REPLACE...SELECT、LOAD DATA等 |
  | simple inserts     | 指能在插入前就确定插入行数的语句。如INSERT、REPLACE等；不包含INSERT...ON DUPLICATE KEY UPDATE这类语句 |
  | bulk inserts       | 指在插入前不能确定得到插入行数的语句，如INSERT...SELECT、REPLACE...SELECT、LOAD DATA |
  | mixed-mode inserts | 指插入中有一部分是自增长的，有一部分是确定的，如INSERT...ON DUPLICATE KEY UPDATE |

* innodb_autoinc_lock_mode参数：

  | innodb_autoinc_lock_mode | 说明                                       |
  | ------------------------ | ---------------------------------------- |
  | 0                        | 即通过表锁的AUTO-INC Locking的方式。因为有新的自增长方式，0这个选项不应该是新版用户的首选项 |
  | 1                        | 默认值，对于“simple inserts”会用互斥量去对内存中的计数器进行累加的操作；对于“bulk inserts”还是使用AUTO-INC Locking。自增长的列值是连续的。在这种方式下，statement-based的replication还是能很好地工作 |
  | 2                        | 对于所有的“insert-like”自增长值的产生都是通过互斥量。最高的并发性能。自增长的列值不是连续的。在这种方式下，statement-based的replication会出现问题，必须使用row-based replication |

* 在InnoDB存储引擎中，自增长值的列必须是索引，同时必须是索引的第一个列。

6.3.5 外键和锁

* 在InnoDB存储引擎中，对于一个外键列，如果灭有显示地对这个列家索引，InnoDB存储引擎自动对其加上一个索引，因为这样可以避免表锁。
* 对于外键值的插入或更新，首先需要查询父表中的记录，即SELECT父表，此时不是使用一致性非锁定读（这样会发生数据不一致的问题），而是使用SELECT...LOCK IN SHARE MODE方式，即**主动对父表加S锁**。如果这时父表已经加了X锁，子表上的操作会被阻塞。

---

6.4 锁的算法

6.4.1 锁的3种算法

* InnoDB存储引擎有3种行锁的算法：
  * Record Lock：单个行记录上的锁
  * Gap Lock：间隙锁，锁定一个范围，但不包含记录本身
  * Next-Key Lock：Gap Lock+Record Lock，锁定一个范围，并且锁定记录本身， 默认。如索引值1，5，8，10，12，若锁住8，则会锁住范围(5,8]和(8,10)
* Record Lock总会去锁住索引记录，如果InnoDB存储引擎表在建立的时候没有设置任何一个索引，那么这时InnoDB存储引擎会使用隐式的主键进行锁定。
* 当查询的索引含有唯一属性时，InnoDB存储引擎会对Next-Key Lock进行优化，将其降级为Record Lock，即进锁住索引本身，而不是范围
* 对于Next-Key Lock，InnoDB存储引擎还会对辅助索引的下一个键值加上gap lock，gap lcok的作用是为了阻止对个事务将记录插入到同一个范围内，而这回导致Phantom Problem问题的产生。

6.4.2 解决Phantom Problem

* Phantom Problem是指在同一事务下，连续执行两次同样的SQL语句可能导致不同的结果，第二次的SQL语句可能会返回之前不存在的行。

---

6.5 锁问题

6.5.1 脏读

* 脏数据是指事务对缓冲池中行记录的修改，并且还没有被提交（commit）。
* 脏读指的就是在不同的事务下，当前事务可以读到另外事务未提交的数据，简单来说就是可以读到脏数据。
* 一般不会发生。

6.5.2 不可重复读

* 不可重复读是指在一个事务内多次读取同一数据集合，读取到的数据是不一样的情况。
* 不可重复读和脏读的区别是：脏读读取到的是未提交的数据，而不可重复读读到的确实已经提交的数据。
* 一般可以接受。
* MySQL官方文档将不可重复读定义为Phantom Problem，InnoDB存储引擎采用Next-key Lock算法，避免了不可重复读。

6.5.3 丢失更新

* 丢失更新是指一个事务的更新操作会被另一个事务的更新操作锁覆盖，从而导致数据的不一致。
* 在当前数据库的任何隔离级别下，都不会导致数据库理论意义上的都是更新问题。
* 另一个逻辑意义上的丢失更新问题:
  * 事务T1查询一行数据，放入本地内存，显示给终端用户User1
  * 事务T2查询一行数据，并将取得的数据显示给终端用户User2
  * User1修改这行记录，更新数据库并提交
  * User2修改这行记录，更新数据库并提交
* 要避免这种情况，需要让事务在这种情况下的操作变成串行化。

---

6.6 阻塞

* 因为不同锁之间的兼容性关系，在某些时刻一个事务中的锁需要等待另一个事务中的锁释放它所占用的资源，这就是阻塞。阻塞并不是一件坏事，其是为了确保事务可以并发且正常地运行。
* 参数innodb_lock_wait_timeout参数用来控制等待的时间（默认50秒）；innodb_rollback_on_timeout参数用来是定是否在等待超时时对进行中的事务进行回滚操作（默认OFF）

---

6.7 死锁

6.7.1 死锁的概念

* 死锁是指两个或两个以上的事务在执行过程中，因争夺资源而造成一种互相等待的现象。
* 当前数据库普遍采用wait-for graph（等待图）的方式来进行死锁检测。其要求数据库曹村以下两种信息：
  * 锁的信息链表
  * 事务等待链表
* 在wait-for graph中，事务为图中的节点，而在图中 ，事务T1执行事务T2边的定义为：
  * 事务T1等待事务T2所占用的资源
  * 事务T1最终等待事务T2所占用的资源，也就是事务之间在等待相同的资源，而事务T1发生在事务T2的后面
* 通过上述链表可以构造出一张图，而在这个图中若存在贿赂，就代表存在死锁。wait-for graph的死锁检测通常采用深度优先的算法实现

6.7.2 死锁概率

* 事务发生死锁的概率与一下几点你因素相关：
  * 系统中事务的数量（n），数量越多发生死锁的概率越大。
  * 每个事务操作的数量（r），每个事务操作的数量越多，发生死锁的概率越大。
  * 操作数据的集合（R），越小则发生死锁的概率越大。

---

6.8 锁升级

* 锁升级（Lock Escalation）是指将当前锁的粒度降低。
* InnoDB不存在锁升级的问题，因为其不是根据每个记录来产生锁的，相反，其根据每个事务访问的每个页对锁进行管理的，采用的是位图的方式。因此不管一个事务锁住页中的一个记录还是多个记录，其开销是一致的。

---

7 事务

* 认识事务
* 事务的实现
* 事务控制语句
* 隐式提交的SQL语句
* 对于事务操作的统计
* 事务的隔离级别
* 分布式事务
* 不好的事务习惯

---

7.1 认识事务

* 事务会把数据库从一种一致状态转换为另一种一致的状态。在事务中的操作，要么都做修改，要么都不做
* ACID：
  * 原子性（Atomicity）：指的是整个数据库事务是不可分割的工作单位。只有使事务中的所有数据库操作都执行成功，才算整个事务成功。
  * 一致性（consistency）：指的是事务将数据从一种状态转变为下一种一致的状态。在事务开始之前和事务结束之后，数据库的完整性约束都没有被破坏。
  * 隔离性（isolation）：事务的隔离性要求每个读写事务的对象对其他事务的操作对象能相互分离，即该事务提交前对其他事务都不可见
  * 持久性（durability）：事务一旦提交，其结果就是永久性的。
* 分类：
  * 扁平事务（Flat Transactions）：
    * 最简单的一种。所有操作都处于同一层次，其由BEGIN WORK开始，由COMMIT WORK或ROLLBACK WORK结束，其间的操作是原子的，要么都执行，要么都回滚。
    * 主要限制是不能提交或回滚事务的某一部分，或分几个步骤提交。
  * 带有保存点的扁平事务（Flat Transactions with Savepoints）
    * 除了支持扁平事务支持的操作外，允许早事务执行过程中回滚到同一事务中较早的一个状态。
    * 保存点（Savepoint）用来通知系统应该记住事务当前的状态，以便当之后发生错误时，事务能回到保存点当时的状态。保存点用SAVE WORK来建立。
    * 当发生系统崩溃时，所有保存点都将消失，因为其保存点是易失的（volatile），而非持久的（persistent）。这以为着当进行恢复时，事务需要从开始处重新执行。
  * 链事务（Chaned Transactions）
    * 保存点模式的一种变种。其思想是：在提交一个事务时，释放不需要的数据对象，将必要的处理上下文隐式地传给下一个要开始的事务。
    * 注意，提交事务操作和开始下一个事务曹组将合并为一个原子操作。这意味着下一个事务将看到上一个事务的结果，就好像在一个事务中进行的一样。
    * 链事务和带有保存点的扁平事务不同的是，带有保存点的扁平事务能回滚到任意正确的保存点；而链事务中的回滚仅限于当前事务，即只能恢复到最近一个的保存点。
  * 嵌套事务（Nested Transactions）
    * 嵌套事务的定义：
      * 嵌套事务是由若干事务组成的一棵树，子树既可以是嵌套事务，也可以是扁平事务。
      * 出在叶节点的事务是扁平事务。但是每个子事务从 根到叶子节点的距离可以是不同的。
      * 位于根节点的事务称为顶层事务（top-level transaction），其他事务称为子事务（subtransaction）。事务的前驱（predecessor）称为父事务（parent），事务的下一层称为儿子事务（child）
      * 子事务既可以提交也可以回滚。但是它的提交操作并不马上生效，除非其父事务已经提交。
      * 树中的任意一个事务的回滚会引起它的所有子事务一同回滚，故子事务仅保留ACI特性，不具有D特性。
  * 分布式事务（Distributed Transactions）
    * 通常是一个在 分布式环境下运行的扁平事务
* 对于InnoDB存储引擎来说，其支持扁平事务、待保存点的事务、链事务、分布式事务。对于嵌套事务，其并不原生支持。然后用户扔可以通过带有保存点的事务来默认串行的嵌套事务。

---

7.2 事务的实现

* 事务的隔离性由锁来实现。原子性、一致性、持久性由数据库的redo log和undo log来完成。redo log用来保证事务的**原子性和持久性**；undo log用来保证事务的**一致性**。
* redo和undo并不是逆过程。redo和undo的作用都可以视为是一种恢复操作，redo恢复提交事务修改的页操作，而undo回滚行记录到某个特定版本。
* 因此两者记录的内容不同。redo通常是物理日志，记录的是页的物理修改操作。undo是逻辑日志，根据每行记录进行记录。

|      | redo   | undo   |
| ---- | ------ | ------ |
| 事务   | 持久性（D） | 一致性(C) |
| 读写   | 顺序     | 随机     |
| 内容   | 物理日志   | 逻辑日志   |

7.2.1 redo

1. 基本概念

* 重做日志用来实现事务的持久性（D），其由两部分组成：
  * 内存中的重做日志缓冲（redo log buffer），其是易失的
  * 重做日志文件（redo log file），其是持久的
* InnoDB存储引擎通过**Force Log at Cimmit机制**实现事务的持久性，即当事务提交时，必须先将该事务的所有日志写入到重做日志文件进行持久化，待事务的COMMIT操作完成才算完成。
* 重做日志缓冲先写入文件系统缓存，为了确保重做日志写入磁盘，必须进行一次fsync操作。因此磁盘的性能决定了事务提交的性能，也就是数据库的性能。
* 参数innodb_flush_log_at_trx_commit用来控制重做日志刷新到磁盘的策略：
  * 默认值是1，表示事务提交时必须调用一次fsync操作。
  * 0表示事务提交时不进行写入重做日志操作。这个操作仅在master thread中完成，master thread中每1秒会进行一次重做日志文件的fsync操作
  * 2表示提交时将重做日志写入重做日志文件，但仅写入文件系统的缓存中，不进行fsync操作。当数据库宕机而操作系统不宕机时，不会导致事务丢失；当操作系统宕机时，重启数据库会丢失未从文件系统缓存刷新到重做日志文件的那部分事务。
* binlog用来进行POINT-IN-TIME（PIT）的恢复及主从复制（Replication）环境的建立。从表面看和重做日志非常相似，都是记录了对于数据库操作的日志，从本质上看，两者非常不同：
  * redo log是在InnoDB存储引擎层产生；而binlog是在MySQL数据库的上层产生的，任何存储引擎对于数据库的更改都会产生binlog
  * 两种日志记录的内容形式不同。binlog是逻辑日志，其记录的是对应的SQL语句；redo log是物理格式日志，其记录的是对每个页的修改
  * 两种日志记录写入磁盘的时间点不同。binlog值在事务提交完成后进行一次写入；而redo log在事务进行中不断地被写入，这表现为日志并不是随事务提交的顺序进行写入的。

2. log block

* 在InnoDB存储引擎中，重做日志都是以512字节进行存储的。这以为着重做日志缓存、重做日志文件都是以块（block）的方式进行保存的，称之为重做日志块（redo log block），每块大小为512字节。

* 若一个页中产生的重做日志数量大于512字节，那么需要分割为多个重做日志块进行存储。由于重做日志块的大小和磁盘扇区的大小一样，因此重做日志的写入可以保证原子性，不需要doublewrite技术。

* 重做日志块组成（补图）：

  * 日志块头（log block header）：12字节

    | 名称                        | 字节   | 说明                                       |
    | ------------------------- | ---- | ---------------------------------------- |
    | LOG_BLOCK_HDR_NO          | 4    | log buffer由log block组成，在内部log buffer就好似一个数组，该部分就用来标记这个数组中的位置。其实递增并且循环使用的。第一位用来判断是否是flush bit，因此最大值为2G |
    | LOG_BLOCK_HDR_DATA_LEN    | 2    | log block所占用的大小，单位字节                     |
    | LOG_BLOCK_FIRST_REC_GROUP | 2    | log block中第一个日志（不算之前block剩余的）所在的偏移量      |
    | LOG_BLOCK_CHECKPOINT_NO   | 4    | 该log block最后写入时的检查点第4个字节的值               |

  * 日志内容（log body）：最多492字节

  * 日志块尾（log block tailer）：8字节

    | 名称               | 字节   | 说明                                       |
    | ---------------- | ---- | ---------------------------------------- |
    | LOG_BLOCK_TRL_NO | 4    | 其值和LOG_BLOCK_HDR_NO相同，并在函数log_block_init中被初始化 |

3. log group（补图）

* log group为重做日志组，其中有多个重做日志文件。InnoDB存储引擎实际只有一个log group

* log group是一个逻辑的概念，并没有一个实际存储的物理文件来表示log group信息。

* log buffer根据一定规则将内存中的log block刷新到磁盘，这个规则是：

  * 事务提交时
  * 当log buffer中有一般的内存空间已经被使用时
  * log checkpoint时

* 对于log block的写入追加(append)到redo log file的最后部分，当一个redo log file被写满时，会接着写入下一个redo log file，其使用方式是round-robin。

* 每个redo log file的前2KB的部分不保存log block信息。对于log group中的第一个redo log file，其前2KB保存4个512字节大小的块，内容如下；log group中的其余redo log file仅保留空间，不保存上述信息。

  | 名称              | 大小（字节） |
  | --------------- | ------ |
  | log file header | 512    |
  | checkpoint1     | 512    |
  | 空               | 512    |
  | checkpoint2     | 512    |

4. 重做日志格式

* InnoDB存储引擎的存储管理是基于页的，故其重做日志格式也是基于页的。（补图）
  * 通用头部格式：
    * redo_log_type：重做日志的类型。InnoDB 1.2版本时，有51种重做日志类型。
    * space：表空间的ID。
    * page_no：页的偏移量。
  * redo log body：根据重做日志类型的不同，会有不同的存储内容

5. LSN

* LSN是Log Sequence Number的缩写，其代表的是日志序列号。在InnoDB存储引擎中，LSN占用8字节，并且单调递增。LSN表示的含义有：
  * 重做日志中：重做日志写入的总量
  * checkpoint的位置：刷新到磁盘的LSN
  * 页中：该页最后刷新时LSN的大小，用来判断页是否需要进行恢复操作

6. 恢复（补图）

* 由于checkpoint表示已经刷新到磁盘页的LSN，因此在恢复过程中仅需恢复checkpoint开始的日志部分
* InnoDB存储引擎的重做日志是物理日志，且是幂等的。

---

7.2.2 undo

1. 基本概念

* 重做日志记录了事务的行为，可以很好地通过其对页进行“重做”操作。但是事务有时还需要进行回滚操作，这时就需要undo
* redo存放在重做日志文件中。与redo不同，undo存放在数据库内部的一个特殊段（segment）中，这个段称为undo段（undo segment）。undo段位于共享表空间内。
* undo是逻辑日志，只是将数据库逻辑地恢复到原来的样子。所有修改都被逻辑取消了，但是数据结构和页本身在回滚之后可能不大相同。
* 除了回滚操作，undo的另一个作用就是MVCC，即在InnoDB存储引擎中MVCC是通过undo来实现的。当用户读取一行记录时，若该记录已经被其他事务占用，当前事务可以通过undo读取之前的行版本信息，以此实现非锁定读取。
* 事务在undo log segment分配也并写入undo log的这个过程同样需要写入重做日志。这是因为undo log也需要持久性的保护。

2. undo存储管理

* 为了保证事务并发操作时，在写各自的undo log时不发生冲突，InnoDB采用回滚段的方式来维护undo log的并发写入和持久化。
* InnoDB存储引擎有rollback segment，每个回滚段中记录了1024个undo log segment(slot)，而在每个undo log segment中进行undo页的申请。共享表空间偏移量为5的页（0，5）记录了所有rollback segment header所在的页，这个页的类型为FIL_PAGE_TYPE_SYS。可支持同时在线的事务数为 rollback segment数量*1024
  * 回滚段0预留在系统表空间ibdata中
  * 回滚段1~32存放于临时表的系统表空间ibtmpl中
  * 回滚段33~根据配置存放到独立undo表空间或ibdata中
* 参数：
  * innodb_undo_directory：用于设置rollback segment文件所在的路径。默认值为‘’.“，表示当前InnoDB存储引擎目录。
  * innodb_undo_logs：用来设置rollback segment的个数，默认128。
  * innodb_undo_tablespaces：用来设置构成rollback segment文件的数量，这样rollback segment可以较为平均的分布在多个文件中。
* 当事务提交时，InnoDB存储引擎会做以下两件事情：
  * 将undo log放入列表中，以供之后的purge操作
  * 判断undo log所在页是否可以重用，若可以分配给下个事务使用。
* 事务提交之后并不能马上删除undo log及undo log所在的页。这是因为可能还有其他事务需要通过undo log来得到行记录之前的版本。故事务提交时将undo log放入一个链表中，是否可以最终删除undo log及undo log所在页由purge线程来判断。
* 若为每一个事务分配一个单独的undo页会非常浪费存储空间，因此InnoDB存储引擎的设计中对undo页可以进行重用。具体来说：
  * 当事务提交时，先将undo log 放入链表中
  * 然后判断undo页的使用空间是否小于3/4
  * 若是，则表示undo页可以被重用，之后新的undo log记录在当前undo log的后面

3. undo log个格式

* 在InnoDB存储引擎中，undo log分为：
  * insert undo log：指在insert操作中产生的undo log。因为insert操作的记录，只对事务本身可见，对其他事务不可见，故该undo log可以在事务提交后直接删除，不需要purge操作。其结构如下（补图）：
    * next：2字节，记录下一个undo log的位置
    * type_cmpl：1字节，记录undo的类型，对于insert undo log，该值为11
    * undo_no：1字节，记录事务的undo no
    * table_id：1字节，记录undo log所对应的表对象
    * n_unique_index：所有主键的列和值，在进行rollback操作时，根据这些值定位到具体的记录，然后进行删除即可。
    * start：2字节，记录undo log的开始位置
  * update undo log（补图）：记录的是对delete和update操作产生的undo log。该undo log可能需要提供MVCC机制，因此不能再事务提交时就进行删除。提交时需要放入undo log链表，等待purge线程进行最后的删除。其结构如下（补图）：
    * next
    * type_cmpl
      * 12 TRX_UNDO_UPD_EXIST_REC：更新non-delete-mark的记录
      * 13 TRX_UNDO_UPD_DEL_REC：将delete的记录标记为not delete
      * 14 TRX_UNDO_DEL_MARK_REC：将记录标记为delete
    * undo_no
    * table_id
    * info_bits：1字节
    * DATA_TRX_ID：rec 事务Id，6字节
    * DATA_ROLL_PTR：rec 回滚指针，7字节
    * n_unique_index
    * update vector：表示update操作导致发生改变的列。每个修改的列信息都要记录到undo log 中。对于不同的undo log类型，可能还需要记录对索引列所做的修改。
    * start

4. 查看undo信息

---

7.2.3 purge

* purge用于最终完成delete和update操作。若该行记录已不被任何其他事务引用了，那么就可以进行真正的delete操作。
* history列表，根据事务提交的顺序，将undo log进行链接。（补图）
* 先从history列表中找undo log，然后再从undo page中找undo log变了大量的随机读取操作
* 参数：
  * innodb_purge_batch_size：用来设置每次purge操作需要清理的undo page数量，默认300。
  * innodb_msx_purge_lag：用来控制history list的长度，若长度大于该参数时，其会”延缓“DML操作，默认为0，表示不做限制
    * 延缓算法：delay =  ( length(history_list)  - innodb_msx_purge_lag  ) * 10- 5
    * 延迟单位：毫秒
    * 延迟对象：行（不是DML操作，如DML操作有5行，则延迟5*delay ms）
  * innodb_max_purge_lag_delay：控制delay的最大毫秒数

---

7.2.4 group commit

* 为了提高磁盘fsync的效率，当前数据库都提供了group commit的功能，即一次fsync可以刷新确保多个事务日志被写入文件。
* 对于InnoDB存储引擎来说，事务提交会进行两个阶段的操作，其他事务的步骤a）可以在步骤b）执行时进行：
  * 修改内存中事务对应的信息，并且将日志写入重做日志缓冲。
  * 调用fsync将确保日志都从重做日志缓冲写入磁盘。
* 为了确保存储引擎层中的事务和binlog的一致性，二者之间使用了两阶段事务：（补图）
  * 当事务提交时InnoDB存储引擎进行prepare操作。
  * MySQL数据库上层写入binlog
  * InnoDB存储引擎将日志写入重做日志文件
    * 修改内存中事务对应的信息，并且将日志写入重做日志缓冲
    * 调用fsync将确保日志都从重做日志缓冲写入磁盘
* 为了保证MySQL数据库上层binlog的写入顺序和InnoDB层的事务提交顺序一致，MySQL数据库库内部使用了prepare_commit_mutex这个锁。但在启用这个锁之后，步骤3）中的步骤a）不可以在其他事务执行步骤b）时进行，从而导致了group commit失效。
* BLGC（Binary Log Group Commit）:（补图）在MySQL数据库上层进行提交时首先按顺序将其放入一个队列中，队列中的第一个事务称为leader，其他事务称为follower。BLGC步骤：
  * Flush阶段，将每个事务的binlog写入内存
  * Sync阶段，将内存中的binlog刷新到磁盘，若队列中有多个事务，那么仅一次sync操作就完成了二进制日志的写入，这就是BLCG
  * Commit阶段，leader根据顺序调用存储引擎层事务的提交，因此修复原先由锁prepare_commit_mutex导致group commit失效的问题。

---

7.3 事务控制语句

* 默认设置下，事务是自动提交的，即执行SQL语句后就会马上执行COMMIT操作。
* 事务控制语句：
  * START TRANSACTION|BEGIN：显式地开启一个事务
  * COMMIT [WORK]：提交事务，并使得已对数据库做的修改称为永久性的
  * ROLLBACK [WORK]：回滚事务会结束用户的事务，并撤销正在进行的所有未提交的修改
  * SAVEPOINT identifier：SAVEPOINT允许在事务中创建一个保存点，一个事务中可以有多个SAVEPOINT
  * RELEASE SAVEPOINT identifier：删除一个事务的保存点
  * ROLLBACK TO [SAVEPOINT] identifier：把事务回滚到保存点
  * SET TRANSACTION：设置事务的隔离级别
* completion_type：控制[WORK]事务结束后的行为是CHAIN 还是RELEASE
  * 0：默认，没有任何操作，这种设置下COMMIT 和COMMIT WORK是完全等价的
  * 1：COMMIT WORK等同于COMMIT AND CHAIN，表示马上自动开启一个相同隔离界别的事务
  * 2：COMMIT WORK等同于COMMIT AND RELEASE，表示事务提交后会自动断开与服务器的连接。
* 一些注意点：
  * 一条语句失败并抛出异常时，并不会导致先前已经执行的语句自动回滚。必须由用户自己来决定不是否对其进行提交或者回滚操作。
  * 即使执行了ROLLBACK TO SAVEPOINT，之后也需要显式地运行COMMIT或ROLLBACK命令

---

7.4 隐式提交的SQL语句

* 以下这些SQL语句会产生一个隐式的提交（COMMIT）操作

  * DDL

    |           | ALTER | CREATE | DROP | RENAME | TRUNCATE |
    | --------- | ----- | ------ | ---- | ------ | -------- |
    | DATABASE  |       | YES    | YES  |        |          |
    | EVENT     | YES   | YES    | YES  |        |          |
    | PROCEDURE | YES   | YES    | YES  |        |          |
    | TABLE     | YES   | YES    | YES  | YES    | YES      |
    | VIEW      | YES   | YES    | YES  |        |          |
    | INDEX     |       | YES    | YES  |        |          |
    | TRIGGER   |       | YES    | YES  |        |          |

  * 用来隐式地修改MySQL架构的操作：CREATE USER、DROP USER、GRANT、RENAME USER、REVOKES、SET PASSWORD

  * 管理语句：ANALYZE TABLE、CACHE INDEX、CHECK TABLE、LOAD INDEX、INTO CACHE、OPTIMIZE TABLE、REPAIR TABLE

---

7.5 对于事务操作的统计

* TPS（Transaction Per Second）
* 计算TPS的方法是：（com_commit + com_rollback） / time
  * 前提：所有的事务都是显式提交的，如果存在隐式提交和回滚（默认autocommit=1），不会计算到com_commit 和 com_rollback变量中。

---

7.6 事务的隔离级别

* SQL标注定义的四个隔离级别为：

  * READ UNCOMMITTED
  * READ COMMITTED
  * REPEATABLE READ（InnoDB默认，通过Next Key Lock算法避免了幻读）
  * SERIALIZABLE

* 隔离级别修改

  * ```mysql
    SET [GLOBAL | SESSION] TRANSACTION ISOLATION LEVEL
    {
      	READ UNCOMMITTED
      | READ COMMITTED
      | REPEATABLE READ
      | SERIALIZABLE
    }
    ```

    * 配置文件中[mysqld]中添加 transaction-isolation = xxx

    * 查看：SELECT @@tx_isolation

  * 在SERIALIZABLE的事务隔离级别，InnoDB会对每个SELECT语句后自动加上LOCK IN SHARE MODE，在这个事务隔离级别下，读占用了锁，对一致性非锁定读不再予以支持。主要用于InnoDB存储引擎的分布式事务。

  * 在READ COMMITED的事务隔离级别下，除了唯一性的约束检查及外键约束的检查需要gap lock，InnoDB存储引擎不会使用gap lock的锁算法

---

7.7 分布式事务

7.7.1 MySQL数据库分布式事务

* InnoDB存储引擎提供了对XA事务的支持，并通过XA事务来支持分布式事务的实现。

* 分布式事务指的是允许多个独立的事务资源（transaction resources）参与到一个全局的事务中。全局事务要求在其中所有参与的事务要么都提交，要么都回滚。

* XA事务有一个或多个资源管理器（Resource Managers）、一个事务管理器（Transaction Manager）以及一个应用程序（Application Program）组成

  * 资源管理器：提供访问资源的方法。通常一个数据库就是一个资源管理器
  * 事务管理器：协调参与全局事务的各个事务。需要和参与全局事务的所有资源管理器进行通信。
  * 应用程序：定义事务的边界，指定全局事务中的操作。

* 分布式事务使用两阶段提交（two-phase commit）:

  * 第一阶段：所有参与全局事务的节点都开始准备（PREPARE），告诉事务管理器它们准备好提交了。
  * 第二阶段：事务管理器告诉资源管理器执行ROLLBACK还是COMMIT。如果任何一个节点显示不能提交，则所有的节点都被告知需要回滚

* MySQL XA事务语法：

  ```mysql
  XA {START|BEGIN} xid [JOIN|RESUME]
  XA END xid [SUSPEND [FOR MIGRATE]]
  XA PREPARE xid
  XA COMMIT xid [ONE PHASE]
  XA ROLLBACK xid
  XA RECOVER
  ```

7.7.2 内部XA事务

* 之前讨论的分布式事务是外部事务，即资源管理器是MySQL数据库本身。
* 内部XA事务：其在存储引擎与插件之间，又或者在存储引擎与存储引擎之间。
* 最常见的内部XA事务存在于binlog与InnoDB存储引擎之间（补图）

---

7.8 不好的事务习惯

* 在循环中提交
* 使用自动提交
* 使用自动回滚

---

7.9 长事务

* 长事务（Long-Lived Transactions）就是执行时间较长的事务。
* 解决：
  * 转化为小批量（mini batch）的事务来进行处理

---

8 备份与恢复

8.1 概述

* 按据备份方法：
  * Hot Backup（热备）：数据库运行中直接备份，对正在运行的数据库操作没有任何影响
  * Cold Backup（冷备）：数据库停止的情况下备份
  * Warm Backup（温备）：数据库运行中备份，但是会对当前数据库的操作有所影响
* 按备份后文件的内容：
  * 逻辑备份：备份的文件内容是可读的，一般是文本内容。时间长
  * 裸文件备份：复制数据库的物理文件。时间较短
* 按备份数据库的内容“
  * 完全备份：对数据库进行一个完整的备份
  * 增量备份：在上次完全备份的基础上，对于更新的数据进行备份
  * 日志备份：对MySQL数据库binlog德尔备份。

8.2 冷备

* 对于InnoDB存储引擎的冷备非常简单，只需要备份MySQL数据库的frm文件，共享表空间文件，独立表空间文件（*.ibd），重做日志文件。
* 冷备的优点：
  * 备份简单，只要复制相关文件即可。
  * 备份文件易于在不同操作系统，不同MySQL版本下进行恢复
  * 恢复相当简单，只需要把文件恢复到指定位置即可。
  * 恢复速度快，不需要执行任何SQL语句，也不需要重建索引。
* 冷备的缺点：
  * InnoDB存储引擎冷备的文件通常比逻辑文件大很多，因为表空间中存放着很多其他的数据，如undo端，插入缓冲等信息。
  * 冷备也不总是可以轻易地跨平台。操作系统、MySQL版本、文件大小写敏感和浮点数格式都会成为问题

8.3 逻辑备份

8.3.1 mysqldump

* 通常用来完成转存（dump）数据库的备份及不同数据库之间的移植

* 语法：

  ```shell
  mysqldump [arguments] >file_name

  # 如果要备份所有的数据库
  mysqldump --all-database >dump.sql

  # 如果要备份指定的数据库
  mysqldump --database db1 db2 db3 >dump.sql
  ```

* 重要参数：

  * --single-transaction：在备份开始前，先执行START TRANSACTION命令。只对InnoDB有效
  * --lock-tables(-l)：在备份中，依次锁住每个架构下的所有表。和--single-transaction互斥
  * --lock-all-tables：在备份中，对所有架构中的所有表上锁
  * --all-drop-database ：在CREATE DATABASE前先运行DROP DATABASE
  * --master-data [=value]：通过该参数产生的备份转存文件主要用来建立一个replication
  * —master-data：会自动忽略—lock-tables选项
  * —events（-E）：备份时间调度器
  * —routines（-R）：备份存储过程和函数
  * —triggers：备份触发器
  * —hex-blob：将BINARY、VARBINARY、BLOG和BIT类型备份为十六进制的格式
  * —tab=path（-T path）：缠身TAB分隔的数据文件
  * —where='where_condition'（-w 'where_condition'）：导出给定条件的数据

* 注意：

  * 不能导出视图

8.3.2 SELECT…INTO OUTFILE

* 导出一张表中的数据

```mysql
SELECT [column 1],[column 2]...
INTO
OUTFILE 'file_name'		 #导出的文件，所在路径的权限必须是mysql:mysql
[{FIELDS |COLUMNS}]
[TERMINATED BY 'string']    			 #每个列的分隔符，默认'\t'
[
  [OPTIONALLY] ENCLOSED BY 'char']		 #对于字符串的包含符，默认''
  [ESCAPED BY 'char']				    #转义符，默认'\\'
 ]
 [
   LINES
   [STARTING BY 'string']				#每行的开始符号，默认''
   [TERMINATED BY 'string']				#每行的结束符号，默认'\n'
 ]
 FROM TABLE WHERE ...
```

8.3.3 逻辑备份的恢复

```mysql
mysql -uroot -p<test_backup.sql

source /home/mysql/test_backup.sql
```

8.3.4 LOAD DATA INFILE

```mysql
LOAD DATA INTO TABLE a IGNORE 1 LINES INFILE 'home/mysql/a.txt'
```

8.4 二进制日志备份与恢复

```shell
[mysqld]
log-bin = mysql-bin
sync_binlog = 1
innodb_support_xa = 1
```

* mysqlbinlog [options] log_file...

---

8.5 热备

8.5.1 ibbackup

* 工作原理：
  * 记录备份开始时，InnoDB存储引擎重做日志文件检查点的LSN
  * 复制共享表空间文件以及堵路表空间文件
  * 记录复制完表空间文件后，InnoDB存储引擎重做日志文件检查点的LSN
  * 复制在备份时产生的重做日志
* 优点：
  * 在线备份，不阻塞任何的SQL语句
  * 备份性能好，备份的是指是复制数据库文件和重做日志文件
  * 支持压缩备份
  * 跨平台支持
* 恢复步骤：
  * 恢复表空间文件
  * 应用重做日志文件

8.5.2 XtraBackup

---

8.6 快照备份

* MySQL数据库本身并不支持快照功能，因此快照备份是指通过文件系统支持的快照功能对数据库进行备份

---

8.7 复制

* replication的工作原理：
  * 主服务器（master）把数据更改记录到二进制日志（binlog）中
  * 从服务器（slave）把主服务器的二进制日志复制到自己的中继日志（relay log）中
  * 从服务器重做中级日志中的日志，把更改应用到自己的数据库上，以达到数据的最终一致性
* 复制可以用来作为备份，但功能不仅限于备份，其主要功能如下：
  * 数据分布
  * 读取的负载平衡
  * 数据库备份
  * 高可用性和故障转译

